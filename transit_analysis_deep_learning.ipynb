{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Final TESS Transit Classification — Optimized for Extreme Class Imbalance\n",
        "\n",
        "This notebook converts and expands the provided Python script into a fully documented, didactic, and **step-by-step** workflow.\n",
        "We train a 1D CNN to classify TESS light curves into *transit* (planet candidate) vs *non-transit* under **severe class imbalance**.\n",
        "\n",
        "**Key strategies covered:**\n",
        "\n",
        "- **Balanced augmentation** (equal samples per class) to mitigate imbalance during training.  \n",
        "- **Focal loss** (tunable `gamma` and `alpha`) to emphasize hard examples and rare positives.  \n",
        "- **Threshold optimization** using **Youden’s J** from the ROC curve (don’t use the default 0.5).  \n",
        "- **Simplified CNN architecture** to reduce overfitting.  \n",
        "- **AUC-centric monitoring** with early stopping and LR scheduling.\n",
        "\n",
        "> **What you’ll learn**\n",
        ">\n",
        "> 1. Why balanced training batches help under extreme imbalance.  \n",
        "> 2. How focal loss reshapes the gradient to focus on hard/rare samples.  \n",
        "> 3. How to pick a **data-driven** decision threshold that best trades off TPR/FPR.  \n",
        "> 4. How to evaluate with AUC-ROC rather than accuracy (which can be misleading).  \n",
        "> 5. How to visualize confusion matrices and sample light curves with predictions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "370aefef",
      "metadata": {},
      "source": [
        "## 1. Prerequisites & Data\n",
        "\n",
        "**Dependencies** (install if needed):\n",
        "\n",
        "```bash\n",
        "pip install numpy pandas scikit-learn matplotlib tensorflow\n",
        "```\n",
        "\n",
        "> We intentionally avoid additional plotting libraries to keep dependencies compact.  \n",
        "> If you already have a working scientific Python/TensorFlow stack, you can skip installations.\n",
        "\n",
        "**Expected dataset**: a CSV file named **`tess_data.csv`** in the working directory with:\n",
        "\n",
        "- **Light-curve samples**: `flux_0000, flux_0001, ..., flux_0999` (or up to `n_bins-1`)  \n",
        "- **Flux uncertainties**: `flux_err_0000, ..., flux_err_0999`  \n",
        "- **Label**: `label` (0 = Non-Planet, 1 = Planet)  \n",
        "- **Metadata** (used for plots/titles): `toi_name, tic, disp, period_d, t0_bjd, dur_hr, sector`\n",
        "\n",
        "You can change the filename or number of bins via parameters in the **Data Loading** section.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Environment Setup\n",
        "\n",
        "Set up imports, suppress noisy warnings, and fix seeds for reproducibility.  \n",
        "(Exact reproducibility on GPUs may still vary across hardware/driver versions.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9739f714",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/root/anaconda3/envs/comp_astro_25/bin/python\n",
            "Requirement already satisfied: tensorflow==2.20.0 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (2.20.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (2.3.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (0.7.0)\n",
            "Requirement already satisfied: google_pasta>=0.1.1 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (18.1.1)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (25.0)\n",
            "Requirement already satisfied: protobuf>=5.28.0 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (6.33.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (2.32.5)\n",
            "Requirement already satisfied: setuptools in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (80.9.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (3.2.0)\n",
            "Requirement already satisfied: typing_extensions>=3.6.6 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.20.0 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (2.20.0)\n",
            "Requirement already satisfied: keras>=3.10.0 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (3.12.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (2.2.5)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (3.15.1)\n",
            "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (0.5.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.20.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.20.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.20.0) (2.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.20.0) (2025.11.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow==2.20.0) (3.10)\n",
            "Requirement already satisfied: pillow in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow==2.20.0) (11.3.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow==2.20.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow==2.20.0) (3.1.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.20.0) (0.45.1)\n",
            "Requirement already satisfied: rich in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from keras>=3.10.0->tensorflow==2.20.0) (14.2.0)\n",
            "Requirement already satisfied: namex in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from keras>=3.10.0->tensorflow==2.20.0) (0.1.0)\n",
            "Requirement already satisfied: optree in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from keras>=3.10.0->tensorflow==2.20.0) (0.18.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow==2.20.0) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from rich->keras>=3.10.0->tensorflow==2.20.0) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from rich->keras>=3.10.0->tensorflow==2.20.0) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow==2.20.0) (0.1.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.executable)  # just to see which python the notebook uses\n",
        "\n",
        "# Install TF 2.20.0 for THIS interpreter\n",
        "!{sys.executable} -m pip install \"tensorflow==2.20.0\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "883a4745",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting working directory to:  /ca25/comp_astro_25\n",
            "None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-15 19:21:30.767712: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2026-02-15 19:21:30.832972: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-02-15 19:21:32.505526: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2026-02-15 19:21:37.097924: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-02-15 19:21:37.103930: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF version: 2.20.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-15 19:21:38.001950: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'import torch\\n\\nif torch.cuda.is_available():\\n    device = torch.device(\"cuda\")\\n    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\\nelse:\\n    device = torch.device(\"cpu\")\\n    print(\"Using CPU (no GPU available).\")\\n\\nprint(\"PyTorch version:\", torch.__version__)\\n'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "    import IPython\n",
        "    working_directory = \"/\".join(\n",
        "            IPython.extract_module_locals()[1][\"__vsc_ipynb_file__\"].split(\"/\")[:-1]\n",
        "        )\n",
        "    print(\"Setting working directory to: \", working_directory)\n",
        "    print(os.chdir(working_directory))\n",
        "except Exception as e:\n",
        "    print(\"It was impossible to set your directory as the current one because of the following message\")\n",
        "    print(e)\n",
        "    print(\"The working directory is: \", os.getcwd())\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score, roc_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import tensorflow as tf   #i hidden this because my current vs code in not installing tensor flow, instaed i installed pytorch \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "import tensorflow.keras.backend as K\n",
        "# i imported this code \n",
        "'''import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "# Reproducibility\n",
        "np.random.seed(42)\n",
        "#tf.random.set_seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"FINAL TESS CLASSIFICATION\")\n",
        "print(\"=\"*70)'''\n",
        "\n",
        " #Optional: make TF less eager to pre-allocate all GPU memory (if using GPU)\n",
        "try:\n",
        "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "    for gpu in gpus:\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    if gpus:\n",
        "        print(f\"Enabled memory growth for {len(gpus)} GPU(s).\")\n",
        "except Exception as e:\n",
        "    print(\"GPU setup note:\", e)\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "'''import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Using CPU (no GPU available).\")\n",
        "\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7201e4a1",
      "metadata": {},
      "source": [
        "## 3. Focal Loss (for severe imbalance)\n",
        "\n",
        "**Why focal loss?** With extreme imbalance, the model can get “lazy”—it learns to do well by focusing on the majority class.  \n",
        "Focal loss down-weights *easy* examples and concentrates gradient on *hard* ones by adding a modulating factor \\((1 - p_t)^\\gamma\\).  \n",
        "We also use class weighting via \\(\\alpha\\) to up-weight the rare positive class.\n",
        "\n",
        "- **`gamma`** (focusing parameter): higher values put more emphasis on hard examples.  \n",
        "- **`alpha`** (class weight): weight for positive class (1); negative class gets \\(1 - \\alpha\\).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a2de8e26",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def focal_loss(gamma=2.5, alpha=0.75):\n",
        "    \"\"\"Focal loss optimized for severe imbalance (binary).\"\"\"\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        epsilon = K.epsilon()\n",
        "        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
        "        \n",
        "        pt = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n",
        "        alpha_factor = tf.where(tf.equal(y_true, 1), alpha, 1 - alpha)\n",
        "        focal_weight = alpha_factor * K.pow(1 - pt, gamma)\n",
        "        bce = -K.log(pt)\n",
        "        return K.mean(focal_weight * bce)\n",
        "    return focal_loss_fixed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85ae786d",
      "metadata": {},
      "source": [
        "## 4. Balanced Augmentation\n",
        "\n",
        "We **balance the training set** to a fixed number of samples per class.  \n",
        "If a class has too few samples, we create augmented variants (noise, scale, shift, combo).  \n",
        "This prevents the model from being swamped by the majority class during training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "24800de1",
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_balanced_dataset(X, y, samples_per_class=400):\n",
        "    \"\"\"Create a perfectly balanced dataset via lightweight augmentations.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"CREATING BALANCED DATASET\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    X_class0 = X[y == 0]\n",
        "    X_class1 = X[y == 1]\n",
        "    \n",
        "    print(f\"Original - Class 0: {len(X_class0)}, Class 1: {len(X_class1)}\")\n",
        "    \n",
        "    def augment_to_target(X_orig, n_target):\n",
        "        if len(X_orig) >= n_target:\n",
        "            idx = np.random.choice(len(X_orig), n_target, replace=False)\n",
        "            return X_orig[idx]\n",
        "        \n",
        "        X_result = [X_orig]\n",
        "        while len(np.vstack(X_result)) < n_target:\n",
        "            # number we still need (cap to avoid oversampling too big chunks)\n",
        "            n_needed = n_target - len(np.vstack(X_result))\n",
        "            idx = np.random.choice(len(X_orig), min(len(X_orig), n_needed))\n",
        "            \n",
        "            aug_type = np.random.rand()\n",
        "            if aug_type < 0.25:\n",
        "                # Additive Gaussian noise\n",
        "                X_aug = X_orig[idx] + np.random.normal(0, 0.01, (len(idx), X_orig.shape[1]))\n",
        "            elif aug_type < 0.5:\n",
        "                # Multiplicative scaling\n",
        "                scale = 1.0 + np.random.uniform(-0.03, 0.03, (len(idx), 1))\n",
        "                X_aug = X_orig[idx] * scale\n",
        "            elif aug_type < 0.75:\n",
        "                # Circular shift (time shift)\n",
        "                shifts = np.random.randint(-20, 20, len(idx))\n",
        "                X_aug = np.array([np.roll(X_orig[i], s) for i, s in zip(idx, shifts)])\n",
        "            else:\n",
        "                # Mild combo: small scale + small noise\n",
        "                X_aug = X_orig[idx] * (1.0 + np.random.uniform(-0.02, 0.02, (len(idx), 1)))\n",
        "                X_aug += np.random.normal(0, 0.008, X_aug.shape)\n",
        "            \n",
        "            X_result.append(X_aug)\n",
        "        \n",
        "        X_final = np.vstack(X_result)\n",
        "        return X_final[:n_target]\n",
        "    \n",
        "    X0_bal = augment_to_target(X_class0, samples_per_class)\n",
        "    X1_bal = augment_to_target(X_class1, samples_per_class)\n",
        "    \n",
        "    print(f\"Balanced - Class 0: {len(X0_bal)}, Class 1: {len(X1_bal)}\")\n",
        "    \n",
        "    X_balanced = np.vstack([X0_bal, X1_bal])\n",
        "    y_balanced = np.concatenate([np.zeros(samples_per_class), np.ones(samples_per_class)])\n",
        "    \n",
        "    # Shuffle\n",
        "    idx = np.arange(len(X_balanced))\n",
        "    np.random.shuffle(idx)\n",
        "    \n",
        "    return X_balanced[idx], y_balanced[idx]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34555fb8",
      "metadata": {},
      "source": [
        "## 5. Data Loading, Splitting & Standardization\n",
        "\n",
        "We split **before** augmentation (to avoid leakage), then **balance only the training split**.  \n",
        "We standardize the flux (zero mean / unit variance) using statistics from the training set only.\n",
        "\n",
        "**Notes**\n",
        "\n",
        "- Error bars `X_err` are **not** standardized (kept in their original scale).  \n",
        "- We keep the **test metadata** to produce nicer titles in the sample light-curve plots.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "45df1a84",
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data(csv_path='tess_data.csv', n_bins=1000):\n",
        "    \"\"\"Load CSV, split, balance train set, and standardize features.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"LOADING DATA\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    df = pd.read_csv(csv_path)\n",
        "    print(f\"Dataset: {df.shape[0]} samples\")\n",
        "    \n",
        "    flux_cols = [f'flux_{i:04d}' for i in range(n_bins)]\n",
        "    flux_err_cols = [f'flux_err_{i:04d}' for i in range(n_bins)]\n",
        "    X = df[flux_cols].values\n",
        "    X_err = df[flux_err_cols].values\n",
        "    y = df['label'].values\n",
        "    \n",
        "    metadata_cols = ['toi_name', 'tic', 'label', 'disp', 'period_d', 't0_bjd', 'dur_hr', 'sector']\n",
        "    metadata = df[metadata_cols]\n",
        "    \n",
        "    print(\"\\nOriginal distribution:\")\n",
        "    print(f\"  Class 0: {(y==0).sum()}, Class 1: {(y==1).sum()}\")\n",
        "    if (y==0).sum() > 0:\n",
        "        print(f\"  Ratio: {(y==1).sum() / (y==0).sum():.2f}:1\")\n",
        "    \n",
        "    # Train/test split (keep errors aligned; stratify to preserve class ratio)\n",
        "    X_train, X_test, y_train, y_test, X_err_train, X_err_test, idx_train, idx_test = train_test_split(\n",
        "        X, y, X_err, np.arange(len(y)),\n",
        "        test_size=0.2,\n",
        "        random_state=42,\n",
        "        stratify=y\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nInitial split - Train: {len(X_train)}, Test: {len(X_test)}\")\n",
        "    \n",
        "    # Balance training set\n",
        "    X_train, y_train = create_balanced_dataset(X_train, y_train, samples_per_class=350)\n",
        "    \n",
        "    # Standardize (fit on train, apply to test)\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STANDARDIZATION\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "    \n",
        "    print(f\"Train: mean={X_train.mean():.6f}, std={X_train.std():.6f}\")\n",
        "    print(f\"Test:  mean={X_test.mean():.6f}, std={X_test.std():.6f}\")\n",
        "    \n",
        "    # Reshape for Conv1D: (samples, timesteps, channels)\n",
        "    X_train = X_train.reshape(-1, n_bins, 1)\n",
        "    X_test = X_test.reshape(-1, n_bins, 1)\n",
        "    \n",
        "    metadata_test = metadata.iloc[idx_test].reset_index(drop=True)\n",
        "    \n",
        "    print(f\"\\nFinal - X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
        "    print(f\"Train dist: 0={( y_train==0).sum()}, 1={(y_train==1).sum()}\")\n",
        "    \n",
        "    # Return standardized test for model input, but also return the standardized\n",
        "    # copy (X_test_orig) so we can inverse-transform for plotting with error bars.\n",
        "    return X_train, X_test, y_train, y_test, metadata_test, X_test.copy(), X_err_test, scaler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0e4e6b5",
      "metadata": {},
      "source": [
        "## 6. A Simpler 1D CNN (to curb overfitting)\n",
        "\n",
        "A compact ConvNet with **BatchNorm**, **Dropout**, and **Global Average Pooling** is often enough for\n",
        "noisy, small-ish 1D signals. We also add mild L2 on the dense layers. The goal is a strong baseline\n",
        "that generalizes well, not a gigantic model that memorizes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c42e5a33",
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_simple_cnn(n_bins=1000):\n",
        "    \"\"\"Simpler CNN to prevent overfitting on small datasets.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"BUILDING SIMPLIFIED CNN\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(n_bins, 1)),\n",
        "        \n",
        "        # Feature extraction\n",
        "        layers.Conv1D(64, kernel_size=3, padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling1D(2),\n",
        "        layers.Dropout(0.3),\n",
        "        \n",
        "        layers.Conv1D(128, kernel_size=3, padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling1D(2),\n",
        "        layers.Dropout(0.3),\n",
        "        \n",
        "        layers.Conv1D(256, kernel_size=3, padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.GlobalAveragePooling1D(),\n",
        "        layers.Dropout(0.4),\n",
        "        \n",
        "        # Classification head\n",
        "        layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.Dropout(0.2),\n",
        "        \n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n",
        "        loss=focal_loss(gamma=2.5, alpha=0.75),\n",
        "        metrics=['accuracy',\n",
        "                 keras.metrics.Precision(name='precision'),\n",
        "                 keras.metrics.Recall(name='recall'),\n",
        "                 keras.metrics.AUC(name='auc')]\n",
        "    )\n",
        "    \n",
        "    model.summary()\n",
        "    print(\"\\nUsing Focal Loss (gamma=2.5, alpha=0.75)\")\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3b197223",
      "metadata": {},
      "outputs": [],
      "source": [
        "# assignmnet2 Task F\n",
        "# --- Extra CNN configurations for Assignment 2 Task F ---\n",
        "\n",
        "def build_cnn_config1(n_bins=1000):\n",
        "    \"\"\"\n",
        "    Config 1: Slightly smaller network, more dropout.\n",
        "    \"\"\"\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(n_bins, 1)),\n",
        "\n",
        "        layers.Conv1D(32, 5, padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling1D(2),\n",
        "        layers.Dropout(0.4),\n",
        "\n",
        "        layers.Conv1D(64, 5, padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling1D(2),\n",
        "        layers.Dropout(0.4),\n",
        "\n",
        "        layers.GlobalAveragePooling1D(),\n",
        "\n",
        "        layers.Dense(128, activation='relu',\n",
        "                     kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Dense(64, activation='relu',\n",
        "                     kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n",
        "        loss=focal_loss(gamma=2.5, alpha=0.75),\n",
        "        metrics=['accuracy',\n",
        "                 keras.metrics.Precision(name='precision'),\n",
        "                 keras.metrics.Recall(name='recall'),\n",
        "                 keras.metrics.AUC(name='auc')]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "def build_cnn_config2(n_bins=1000):\n",
        "    \"\"\"\n",
        "    Config 2: Deeper network (extra Conv1D), slightly different dropout.\n",
        "    \"\"\"\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(n_bins, 1)),\n",
        "\n",
        "        layers.Conv1D(64, 3, padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling1D(2),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Conv1D(128, 3, padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling1D(2),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Conv1D(256, 3, padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling1D(2),\n",
        "        layers.Dropout(0.4),\n",
        "\n",
        "        layers.GlobalAveragePooling1D(),\n",
        "\n",
        "        layers.Dense(256, activation='relu',\n",
        "                     kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Dense(128, activation='relu',\n",
        "                     kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
        "        loss=focal_loss(gamma=2.0, alpha=0.75),\n",
        "        metrics=['accuracy',\n",
        "                 keras.metrics.Precision(name='precision'),\n",
        "                 keras.metrics.Recall(name='recall'),\n",
        "                 keras.metrics.AUC(name='auc')]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "def build_cnn_config3(n_bins=1000):\n",
        "    \"\"\"\n",
        "    Config 3: Same depth but narrower dense layers + stronger regularization.\n",
        "    \"\"\"\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(n_bins, 1)),\n",
        "\n",
        "        layers.Conv1D(64, 3, padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling1D(2),\n",
        "        layers.Dropout(0.4),\n",
        "\n",
        "        layers.Conv1D(128, 3, padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling1D(2),\n",
        "        layers.Dropout(0.4),\n",
        "\n",
        "        layers.GlobalAveragePooling1D(),\n",
        "\n",
        "        layers.Dense(128, activation='relu',\n",
        "                     kernel_regularizer=regularizers.l2(0.002)),\n",
        "        layers.Dropout(0.4),\n",
        "\n",
        "        layers.Dense(64, activation='relu',\n",
        "                     kernel_regularizer=regularizers.l2(0.002)),\n",
        "        layers.Dropout(0.4),\n",
        "\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n",
        "        loss=focal_loss(gamma=3.0, alpha=0.8),\n",
        "        metrics=['accuracy',\n",
        "                 keras.metrics.Precision(name='precision'),\n",
        "                 keras.metrics.Recall(name='recall'),\n",
        "                 keras.metrics.AUC(name='auc')]\n",
        "    )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28417447",
      "metadata": {},
      "source": [
        "## 7. Training with AUC Monitoring, Early Stopping & LR Scheduling\n",
        "\n",
        "We monitor **validation AUC** (not accuracy) and:\n",
        "\n",
        "- **EarlyStopping** on `val_auc` with patience to stop when progress stalls.  \n",
        "- **ReduceLROnPlateau** to gently lower the LR when AUC plateaus.  \n",
        "- **ModelCheckpoint** to persist the best model by AUC.\n",
        "\n",
        "> Tip: If your dataset is *very* small, increase dropout and/or reduce dense layers further.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "799553e8",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, X_train, y_train, X_val, y_val, epochs=100):\n",
        "    \"\"\"Train the model with AUC-centric callbacks.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"TRAINING\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    callbacks = [\n",
        "        EarlyStopping(\n",
        "            monitor='val_auc',\n",
        "            patience=20,\n",
        "            restore_best_weights=True,\n",
        "            mode='max',\n",
        "            verbose=1\n",
        "        ),\n",
        "        ReduceLROnPlateau(\n",
        "            monitor='val_auc',\n",
        "            factor=0.5,\n",
        "            patience=8,\n",
        "            min_lr=1e-7,\n",
        "            mode='max',\n",
        "            verbose=1\n",
        "        ),\n",
        "        ModelCheckpoint(\n",
        "            'best_model_final.keras',\n",
        "            monitor='val_auc',\n",
        "            save_best_only=True,\n",
        "            mode='max',\n",
        "            verbose=1\n",
        "        )\n",
        "    ]\n",
        "    \n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=epochs,\n",
        "        batch_size=32,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "    return history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2fd997b",
      "metadata": {},
      "source": [
        "## 8. Evaluation with **Optimal Threshold** (don’t default to 0.5)\n",
        "\n",
        "The default threshold (0.5) is rarely optimal with imbalanced data.  \n",
        "We compute ROC, then choose the threshold that maximizes **Youden’s J** (\\(\\mathrm{TPR} - \\mathrm{FPR}\\)).\n",
        "We report both the default and the optimal settings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b85e7698",
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_with_optimal_threshold(model, X_test, y_test):\n",
        "    \"\"\"Find an optimal threshold from ROC (Youden's J) and evaluate.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"THRESHOLD OPTIMIZATION & EVALUATION\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    y_pred_proba = model.predict(X_test, verbose=0).flatten()\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "    \n",
        "    # Youden's J statistic\n",
        "    j_scores = tpr - fpr\n",
        "    optimal_idx = np.argmax(j_scores)\n",
        "    optimal_threshold = thresholds[optimal_idx]\n",
        "    \n",
        "    print(f\"\\nOptimal threshold: {optimal_threshold:.4f} (default=0.5)\")\n",
        "    print(f\"  At this threshold: TPR={tpr[optimal_idx]:.4f}, FPR={fpr[optimal_idx]:.4f}\")\n",
        "    \n",
        "    # Predictions with optimal vs default thresholds\n",
        "    y_pred_optimal = (y_pred_proba >= optimal_threshold).astype(int)\n",
        "    y_pred_default = (y_pred_proba >= 0.5).astype(int)\n",
        "    \n",
        "    # Metrics\n",
        "    acc_optimal = accuracy_score(y_test, y_pred_optimal)\n",
        "    acc_default = accuracy_score(y_test, y_pred_default)\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    \n",
        "    print(\"\\nResults:\")\n",
        "    print(f\"  AUC-ROC: {auc:.4f}\")\n",
        "    print(f\"  Accuracy (default threshold=0.5): {acc_default:.4f} ({acc_default*100:.2f}%)\")\n",
        "    print(f\"  Accuracy (optimal threshold={optimal_threshold:.4f}): {acc_optimal:.4f} ({acc_optimal*100:.2f}%)\")\n",
        "    \n",
        "    print(\"\\nWith optimal threshold:\")\n",
        "    print(classification_report(y_test, y_pred_optimal,\n",
        "                                target_names=['Non-Planet', 'Planet'],\n",
        "                                digits=4,\n",
        "                                zero_division=0))\n",
        "    \n",
        "    print(\"\\nPrediction distribution (optimal threshold):\")\n",
        "    print(f\"  Predicted 0: {(y_pred_optimal == 0).sum()}\")\n",
        "    print(f\"  Predicted 1: {(y_pred_optimal == 1).sum()}\")\n",
        "    print(\"True distribution:\")\n",
        "    print(f\"  True 0: {(y_test == 0).sum()}\")\n",
        "    print(f\"  True 1: {(y_test == 1).sum()}\")\n",
        "    \n",
        "    return y_pred_optimal, y_pred_proba, optimal_threshold\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e1529af",
      "metadata": {},
      "source": [
        "## 9. Visualization (Matplotlib-only)\n",
        "\n",
        "We save:\n",
        "- **Confusion matrix** (`confusion_matrix_final.png`) with counts and percentages.  \n",
        "- **Training curves** (`training_history_final.png`).  \n",
        "- **Sample light curves with predictions** (`sample_lightcurves_predictions.png`).\n",
        "\n",
        "> We use **Matplotlib** exclusively to minimize dependencies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7ce2d06d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_lightcurves_with_predictions(X_test_orig, X_err_test, y_test, y_pred, y_pred_proba, \n",
        "                                       metadata_test, scaler, threshold, n_samples=6,\n",
        "                                       save_path='sample_lightcurves_predictions.png'):\n",
        "    \"\"\"Plot light curves with error bars and prediction info; save to file.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"PLOTTING LIGHTCURVES WITH PREDICTIONS (n={n_samples})\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    n_samples = min(n_samples, len(X_test_orig))\n",
        "    \n",
        "    # Select diverse samples: correct/incorrect for both classes\n",
        "    correct_planet = np.where((y_test == 1) & (y_pred == 1))[0]\n",
        "    incorrect_planet = np.where((y_test == 1) & (y_pred == 0))[0]\n",
        "    correct_nonplanet = np.where((y_test == 0) & (y_pred == 0))[0]\n",
        "    incorrect_nonplanet = np.where((y_test == 0) & (y_pred == 1))[0]\n",
        "    \n",
        "    selected_idx = []\n",
        "    per_category = max(1, n_samples // 4)\n",
        "    \n",
        "    for idx_list in [correct_planet, incorrect_planet, correct_nonplanet, incorrect_nonplanet]:\n",
        "        if len(idx_list) > 0:\n",
        "            n_select = min(per_category, len(idx_list))\n",
        "            selected_idx.extend(np.random.choice(idx_list, n_select, replace=False))\n",
        "    \n",
        "    while len(selected_idx) < n_samples:\n",
        "        remaining = list(set(range(len(y_test))) - set(selected_idx))\n",
        "        if remaining:\n",
        "            selected_idx.append(np.random.choice(remaining))\n",
        "        else:\n",
        "            break\n",
        "    \n",
        "    selected_idx = np.array(selected_idx[:n_samples])\n",
        "    \n",
        "    # Figure layout\n",
        "    n_cols = 2\n",
        "    n_rows = (n_samples + n_cols - 1) // n_cols\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 4*n_rows))\n",
        "    if n_samples == 1:\n",
        "        axes = np.array([axes])\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for plot_i, idx in enumerate(selected_idx):\n",
        "        ax = axes[plot_i]\n",
        "        \n",
        "        # Inverse transform to original scale for plotting\n",
        "        flux_norm = X_test_orig[idx].flatten()\n",
        "        flux_err = X_err_test[idx]\n",
        "        flux_original = scaler.inverse_transform(flux_norm.reshape(1, -1)).flatten()\n",
        "        \n",
        "        time_bins = np.arange(len(flux_original))\n",
        "        \n",
        "        # Metadata\n",
        "        toi_name = metadata_test.loc[idx, 'toi_name']\n",
        "        tic = metadata_test.loc[idx, 'tic']\n",
        "        disp = metadata_test.loc[idx, 'disp']\n",
        "        sector = metadata_test.loc[idx, 'sector']\n",
        "        \n",
        "        true_label = y_test[idx]\n",
        "        pred_label = y_pred[idx]\n",
        "        pred_prob = y_pred_proba[idx]\n",
        "        \n",
        "        is_correct = (true_label == pred_label)\n",
        "        true_str = 'Transit' if true_label == 1 else 'Non-Transit'\n",
        "        pred_str = 'Transit' if pred_label == 1 else 'Non-Transit'\n",
        "        \n",
        "        # Errorbar plot\n",
        "        ax.errorbar(time_bins, flux_original, yerr=flux_err, fmt='o', markersize=2,\n",
        "                    ecolor='gray', elinewidth=0.5, capsize=0, alpha=0.6, label='Data')\n",
        "        \n",
        "        # Baseline median\n",
        "        baseline = np.median(flux_original)\n",
        "        ax.axhline(baseline, linestyle='--', linewidth=1, alpha=0.7, label='Baseline')\n",
        "        \n",
        "        ax.set_xlabel('Time Bin', fontsize=10, fontweight='bold')\n",
        "        ax.set_ylabel('Flux (original scale)', fontsize=10, fontweight='bold')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.legend(loc='upper right', fontsize=8)\n",
        "        \n",
        "        status_symbol = '✓' if is_correct else '✗'\n",
        "        color = 'green' if is_correct else 'red'\n",
        "        title = (f'TOI {toi_name} (TIC {tic}, {disp}) - TESS Sector {sector}\\n'\n",
        "                 f'True: {true_str} | Pred: {pred_str} (p={pred_prob:.3f}) {status_symbol}')\n",
        "        ax.set_title(title, fontsize=10, fontweight='bold', color=color, pad=10)\n",
        "        \n",
        "        for spine in ax.spines.values():\n",
        "            spine.set_edgecolor(color)\n",
        "            spine.set_linewidth(2.0)\n",
        "    \n",
        "    # Hide unused axes\n",
        "    for j in range(n_samples, len(axes)):\n",
        "        axes[j].axis('off')\n",
        "    \n",
        "    plt.suptitle(f'Sample Light-curve Predictions (Threshold={threshold:.3f})',\n",
        "                 fontsize=14, fontweight='bold', y=0.995)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"Saved: {save_path}\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def plot_all(y_test, y_pred, y_pred_proba, history, metadata_test, X_test, threshold,\n",
        "             X_test_orig=None, X_err_test=None, scaler=None):\n",
        "    \"\"\"Create and save confusion matrix and training curves. Optionally plot light curves.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"VISUALIZATIONS\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    # Confusion matrix (Matplotlib-only)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap='Blues')\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    ax.set(xticks=np.arange(2),\n",
        "           yticks=np.arange(2),\n",
        "           xticklabels=['Non-Planet', 'Planet'],\n",
        "           yticklabels=['Non-Planet', 'Planet'],\n",
        "           xlabel='Predicted', ylabel='True',\n",
        "           title=f'Confusion Matrix (threshold={threshold:.3f})')\n",
        "    \n",
        "    # Add counts and percentages\n",
        "    total = cm.sum()\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            count = cm[i, j]\n",
        "            pct = (count / total * 100) if total > 0 else 0.0\n",
        "            ax.text(j, i, f\"{count}\\n({pct:.1f}%)\", ha='center', va='center', color='black', fontsize=10)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('confusion_matrix_final.png', dpi=300)\n",
        "    print(\"Saved: confusion_matrix_final.png\")\n",
        "    plt.close()\n",
        "    \n",
        "    # Training history\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    metrics = [('loss', 'Loss'), ('accuracy', 'Accuracy'),\n",
        "               ('auc', 'AUC'), ('recall', 'Recall')]\n",
        "    \n",
        "    for idx, (metric, title) in enumerate(metrics):\n",
        "        ax = axes[idx // 2, idx % 2]\n",
        "        if metric in history.history and f'val_{metric}' in history.history:\n",
        "            ax.plot(history.history[metric], label='Train', linewidth=2)\n",
        "            ax.plot(history.history[f'val_{metric}'], label='Val', linewidth=2)\n",
        "            ax.set_xlabel('Epoch')\n",
        "            ax.set_ylabel(title)\n",
        "            ax.set_title(f'{title} vs Epoch', fontweight='bold')\n",
        "            ax.legend()\n",
        "            ax.grid(alpha=0.3)\n",
        "    \n",
        "    plt.suptitle('Training History - Final Model', fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_history_final.png', dpi=300)\n",
        "    print(\"Saved: training_history_final.png\")\n",
        "    plt.close()\n",
        "    \n",
        "    # Optional: light-curve panel\n",
        "    if X_test_orig is not None and X_err_test is not None and scaler is not None:\n",
        "        plot_lightcurves_with_predictions(X_test_orig, X_err_test, y_test, y_pred, \n",
        "                                          y_pred_proba, metadata_test, scaler, threshold, n_samples=6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b561a755",
      "metadata": {},
      "source": [
        "## 10. Run the Pipeline\n",
        "\n",
        "You can run the following cells **step by step**, or use the **end-to-end** cell.\n",
        "\n",
        "> If your CSV isn’t called `tess_data.csv`, change `CSV_PATH` below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "053ea574",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Path to your dataset\n",
        "CSV_PATH = 'tess_data.csv'   # <- change me if needed\n",
        "N_BINS = 1000                # number of flux bins/columns per sample\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "bdfd93e1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "LOADING DATA\n",
            "======================================================================\n",
            "Dataset: 944 samples\n",
            "\n",
            "Original distribution:\n",
            "  Class 0: 472, Class 1: 472\n",
            "  Ratio: 1.00:1\n",
            "\n",
            "Initial split - Train: 755, Test: 189\n",
            "\n",
            "======================================================================\n",
            "CREATING BALANCED DATASET\n",
            "======================================================================\n",
            "Original - Class 0: 377, Class 1: 378\n",
            "Balanced - Class 0: 350, Class 1: 350\n",
            "\n",
            "======================================================================\n",
            "STANDARDIZATION\n",
            "======================================================================\n",
            "Train: mean=0.000000, std=1.000000\n",
            "Test:  mean=-0.002305, std=0.461477\n",
            "\n",
            "Final - X_train: (700, 1000, 1), X_test: (189, 1000, 1)\n",
            "Train dist: 0=350, 1=350\n"
          ]
        }
      ],
      "source": [
        "# 1) Load and prepare data\n",
        "X_train, X_test, y_train, y_test, metadata_test, X_test_orig, X_err_test, scaler = load_data(\n",
        "    csv_path=CSV_PATH, n_bins=N_BINS\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8e5abe27",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "BUILDING SIMPLIFIED CNN\n",
            "======================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m24,704\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │        \u001b[38;5;34m98,560\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">421,249</span> (1.61 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m421,249\u001b[0m (1.61 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">420,353</span> (1.60 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m420,353\u001b[0m (1.60 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Using Focal Loss (gamma=2.5, alpha=0.75)\n"
          ]
        }
      ],
      "source": [
        "# 2) Build model\n",
        "model = build_simple_cnn(n_bins=N_BINS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "109ebc2b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "TRAINING CONFIGURATION: CNN_default\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "BUILDING SIMPLIFIED CNN\n",
            "======================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m24,704\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │        \u001b[38;5;34m98,560\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">421,249</span> (1.61 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m421,249\u001b[0m (1.61 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">420,353</span> (1.60 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m420,353\u001b[0m (1.60 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Using Focal Loss (gamma=2.5, alpha=0.75)\n",
            "\n",
            "======================================================================\n",
            "TRAINING\n",
            "======================================================================\n",
            "Epoch 1/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.5034 - auc: 0.4798 - loss: 0.8727 - precision: 0.5045 - recall: 0.9022\n",
            "Epoch 1: val_auc improved from None to 0.54737, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 239ms/step - accuracy: 0.5057 - auc: 0.4920 - loss: 0.8370 - precision: 0.5031 - recall: 0.9371 - val_accuracy: 0.5185 - val_auc: 0.5474 - val_loss: 0.7627 - val_precision: 0.5081 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.5157 - auc: 0.5555 - loss: 0.7338 - precision: 0.4999 - recall: 0.9796\n",
            "Epoch 2: val_auc improved from 0.54737 to 0.65622, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 190ms/step - accuracy: 0.5229 - auc: 0.5787 - loss: 0.7079 - precision: 0.5120 - recall: 0.9771 - val_accuracy: 0.4974 - val_auc: 0.6562 - val_loss: 0.6516 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.5048 - auc: 0.6192 - loss: 0.6319 - precision: 0.4933 - recall: 0.9743\n",
            "Epoch 3: val_auc improved from 0.65622 to 0.66848, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 197ms/step - accuracy: 0.5171 - auc: 0.6130 - loss: 0.6106 - precision: 0.5090 - recall: 0.9743 - val_accuracy: 0.4974 - val_auc: 0.6685 - val_loss: 0.5657 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.5157 - auc: 0.6969 - loss: 0.5451 - precision: 0.5046 - recall: 0.9730\n",
            "Epoch 4: val_auc did not improve from 0.66848\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 165ms/step - accuracy: 0.5186 - auc: 0.6632 - loss: 0.5284 - precision: 0.5098 - recall: 0.9657 - val_accuracy: 0.4974 - val_auc: 0.5833 - val_loss: 0.4973 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.5157 - auc: 0.6577 - loss: 0.4818 - precision: 0.5093 - recall: 0.9480\n",
            "Epoch 5: val_auc did not improve from 0.66848\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 181ms/step - accuracy: 0.5286 - auc: 0.7031 - loss: 0.4644 - precision: 0.5154 - recall: 0.9571 - val_accuracy: 0.4974 - val_auc: 0.5878 - val_loss: 0.4387 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.6017 - auc: 0.7327 - loss: 0.4182 - precision: 0.5696 - recall: 0.9860\n",
            "Epoch 6: val_auc did not improve from 0.66848\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - accuracy: 0.5857 - auc: 0.7425 - loss: 0.4056 - precision: 0.5481 - recall: 0.9771 - val_accuracy: 0.4974 - val_auc: 0.6314 - val_loss: 0.3890 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.6060 - auc: 0.7669 - loss: 0.3675 - precision: 0.5751 - recall: 0.9117\n",
            "Epoch 7: val_auc improved from 0.66848 to 0.70168, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - accuracy: 0.5886 - auc: 0.7491 - loss: 0.3583 - precision: 0.5529 - recall: 0.9257 - val_accuracy: 0.4974 - val_auc: 0.7017 - val_loss: 0.3427 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.6011 - auc: 0.7343 - loss: 0.3273 - precision: 0.5692 - recall: 0.9657\n",
            "Epoch 8: val_auc did not improve from 0.70168\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - accuracy: 0.6229 - auc: 0.7013 - loss: 0.3208 - precision: 0.5788 - recall: 0.9029 - val_accuracy: 0.4974 - val_auc: 0.6686 - val_loss: 0.3050 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.5975 - auc: 0.7840 - loss: 0.2895 - precision: 0.5518 - recall: 0.9889\n",
            "Epoch 9: val_auc did not improve from 0.70168\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - accuracy: 0.5614 - auc: 0.7492 - loss: 0.2829 - precision: 0.5335 - recall: 0.9771 - val_accuracy: 0.4974 - val_auc: 0.6527 - val_loss: 0.2719 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.5581 - auc: 0.7919 - loss: 0.2575 - precision: 0.5359 - recall: 0.9752\n",
            "Epoch 10: val_auc improved from 0.70168 to 0.72139, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 183ms/step - accuracy: 0.5771 - auc: 0.7598 - loss: 0.2520 - precision: 0.5433 - recall: 0.9686 - val_accuracy: 0.4974 - val_auc: 0.7214 - val_loss: 0.2446 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.5792 - auc: 0.7593 - loss: 0.2316 - precision: 0.5402 - recall: 0.9662\n",
            "Epoch 11: val_auc did not improve from 0.72139\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 173ms/step - accuracy: 0.6071 - auc: 0.7585 - loss: 0.2263 - precision: 0.5635 - recall: 0.9514 - val_accuracy: 0.4974 - val_auc: 0.6416 - val_loss: 0.2225 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.5850 - auc: 0.7665 - loss: 0.2083 - precision: 0.5483 - recall: 0.9833\n",
            "Epoch 12: val_auc improved from 0.72139 to 0.78404, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 204ms/step - accuracy: 0.5900 - auc: 0.7761 - loss: 0.2028 - precision: 0.5509 - recall: 0.9743 - val_accuracy: 0.4974 - val_auc: 0.7840 - val_loss: 0.1981 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.6580 - auc: 0.8034 - loss: 0.1857 - precision: 0.5950 - recall: 0.9647\n",
            "Epoch 13: val_auc did not improve from 0.78404\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 189ms/step - accuracy: 0.6557 - auc: 0.7984 - loss: 0.1821 - precision: 0.5978 - recall: 0.9514 - val_accuracy: 0.4974 - val_auc: 0.7493 - val_loss: 0.1826 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.6258 - auc: 0.8093 - loss: 0.1686 - precision: 0.5762 - recall: 0.9409\n",
            "Epoch 14: val_auc did not improve from 0.78404\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 174ms/step - accuracy: 0.6671 - auc: 0.8100 - loss: 0.1646 - precision: 0.6093 - recall: 0.9314 - val_accuracy: 0.5238 - val_auc: 0.7191 - val_loss: 0.1666 - val_precision: 0.5109 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.6831 - auc: 0.8257 - loss: 0.1519 - precision: 0.6220 - recall: 0.9430\n",
            "Epoch 15: val_auc improved from 0.78404 to 0.78931, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - accuracy: 0.6657 - auc: 0.8167 - loss: 0.1497 - precision: 0.6086 - recall: 0.9286 - val_accuracy: 0.5238 - val_auc: 0.7893 - val_loss: 0.1523 - val_precision: 0.5109 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.6779 - auc: 0.8011 - loss: 0.1410 - precision: 0.6206 - recall: 0.9260\n",
            "Epoch 16: val_auc did not improve from 0.78931\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 171ms/step - accuracy: 0.6700 - auc: 0.7924 - loss: 0.1391 - precision: 0.6116 - recall: 0.9314 - val_accuracy: 0.5291 - val_auc: 0.5937 - val_loss: 0.1403 - val_precision: 0.5137 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.5868 - auc: 0.7698 - loss: 0.1313 - precision: 0.5536 - recall: 0.9498\n",
            "Epoch 17: val_auc did not improve from 0.78931\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 187ms/step - accuracy: 0.6171 - auc: 0.8011 - loss: 0.1269 - precision: 0.5704 - recall: 0.9486 - val_accuracy: 0.7619 - val_auc: 0.7095 - val_loss: 0.1382 - val_precision: 0.7634 - val_recall: 0.7553 - learning_rate: 5.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.6791 - auc: 0.8038 - loss: 0.1195 - precision: 0.6289 - recall: 0.8942\n",
            "Epoch 18: val_auc did not improve from 0.78931\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 204ms/step - accuracy: 0.6729 - auc: 0.8003 - loss: 0.1171 - precision: 0.6179 - recall: 0.9057 - val_accuracy: 0.5397 - val_auc: 0.7844 - val_loss: 0.1286 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.6100 - auc: 0.7854 - loss: 0.1129 - precision: 0.5582 - recall: 0.8956\n",
            "Epoch 19: val_auc improved from 0.78931 to 0.82055, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 196ms/step - accuracy: 0.6600 - auc: 0.8168 - loss: 0.1080 - precision: 0.6029 - recall: 0.9371 - val_accuracy: 0.5661 - val_auc: 0.8205 - val_loss: 0.1089 - val_precision: 0.5341 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.7100 - auc: 0.8475 - loss: 0.0995 - precision: 0.6465 - recall: 0.9361\n",
            "Epoch 20: val_auc did not improve from 0.82055\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 189ms/step - accuracy: 0.7100 - auc: 0.8174 - loss: 0.0999 - precision: 0.6491 - recall: 0.9143 - val_accuracy: 0.5714 - val_auc: 0.4618 - val_loss: 0.1139 - val_precision: 0.5371 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.7077 - auc: 0.8305 - loss: 0.0934 - precision: 0.6508 - recall: 0.9536\n",
            "Epoch 21: val_auc did not improve from 0.82055\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - accuracy: 0.7129 - auc: 0.8309 - loss: 0.0922 - precision: 0.6493 - recall: 0.9257 - val_accuracy: 0.5608 - val_auc: 0.8200 - val_loss: 0.1006 - val_precision: 0.5311 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.7205 - auc: 0.8315 - loss: 0.0882 - precision: 0.6607 - recall: 0.9258\n",
            "Epoch 22: val_auc did not improve from 0.82055\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - accuracy: 0.6943 - auc: 0.8170 - loss: 0.0877 - precision: 0.6308 - recall: 0.9371 - val_accuracy: 0.5661 - val_auc: 0.6077 - val_loss: 0.1092 - val_precision: 0.5341 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.6921 - auc: 0.8214 - loss: 0.0841 - precision: 0.6247 - recall: 0.9205\n",
            "Epoch 23: val_auc did not improve from 0.82055\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - accuracy: 0.6800 - auc: 0.8070 - loss: 0.0838 - precision: 0.6207 - recall: 0.9257 - val_accuracy: 0.5767 - val_auc: 0.7838 - val_loss: 0.0865 - val_precision: 0.5402 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.6459 - auc: 0.7765 - loss: 0.0829 - precision: 0.5947 - recall: 0.9353\n",
            "Epoch 24: val_auc did not improve from 0.82055\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 145ms/step - accuracy: 0.6657 - auc: 0.7947 - loss: 0.0801 - precision: 0.6062 - recall: 0.9457 - val_accuracy: 0.5556 - val_auc: 0.6622 - val_loss: 0.0961 - val_precision: 0.5281 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.6759 - auc: 0.8006 - loss: 0.0766 - precision: 0.6124 - recall: 0.9364\n",
            "Epoch 25: val_auc improved from 0.82055 to 0.83080, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 189ms/step - accuracy: 0.6714 - auc: 0.8166 - loss: 0.0745 - precision: 0.6119 - recall: 0.9371 - val_accuracy: 0.5608 - val_auc: 0.8308 - val_loss: 0.0842 - val_precision: 0.5311 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.6856 - auc: 0.8085 - loss: 0.0730 - precision: 0.6354 - recall: 0.8949\n",
            "Epoch 26: val_auc improved from 0.83080 to 0.84994, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 187ms/step - accuracy: 0.6571 - auc: 0.8115 - loss: 0.0715 - precision: 0.6038 - recall: 0.9143 - val_accuracy: 0.5714 - val_auc: 0.8499 - val_loss: 0.0731 - val_precision: 0.5380 - val_recall: 0.9787 - learning_rate: 5.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.7414 - auc: 0.8449 - loss: 0.0668 - precision: 0.6691 - recall: 0.9579\n",
            "Epoch 27: val_auc did not improve from 0.84994\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - accuracy: 0.7229 - auc: 0.8282 - loss: 0.0675 - precision: 0.6554 - recall: 0.9400 - val_accuracy: 0.5608 - val_auc: 0.6115 - val_loss: 0.0886 - val_precision: 0.5311 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.6905 - auc: 0.8160 - loss: 0.0680 - precision: 0.6265 - recall: 0.9380\n",
            "Epoch 28: val_auc did not improve from 0.84994\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 181ms/step - accuracy: 0.6743 - auc: 0.7992 - loss: 0.0678 - precision: 0.6142 - recall: 0.9371 - val_accuracy: 0.5767 - val_auc: 0.6312 - val_loss: 0.0735 - val_precision: 0.5402 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.6697 - auc: 0.8541 - loss: 0.0620 - precision: 0.5990 - recall: 0.9716\n",
            "Epoch 29: val_auc improved from 0.84994 to 0.88359, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 203ms/step - accuracy: 0.6957 - auc: 0.8479 - loss: 0.0610 - precision: 0.6290 - recall: 0.9543 - val_accuracy: 0.5767 - val_auc: 0.8836 - val_loss: 0.0616 - val_precision: 0.5417 - val_recall: 0.9681 - learning_rate: 5.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.6930 - auc: 0.8062 - loss: 0.0627 - precision: 0.6233 - recall: 0.8623\n",
            "Epoch 30: val_auc did not improve from 0.88359\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 185ms/step - accuracy: 0.7114 - auc: 0.8285 - loss: 0.0601 - precision: 0.6555 - recall: 0.8914 - val_accuracy: 0.5767 - val_auc: 0.7817 - val_loss: 0.0746 - val_precision: 0.5402 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.7222 - auc: 0.8479 - loss: 0.0571 - precision: 0.6514 - recall: 0.9371\n",
            "Epoch 31: val_auc did not improve from 0.88359\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 170ms/step - accuracy: 0.7271 - auc: 0.8409 - loss: 0.0569 - precision: 0.6600 - recall: 0.9371 - val_accuracy: 0.5767 - val_auc: 0.8610 - val_loss: 0.0606 - val_precision: 0.5412 - val_recall: 0.9787 - learning_rate: 5.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.6830 - auc: 0.7872 - loss: 0.0599 - precision: 0.6131 - recall: 0.9308\n",
            "Epoch 32: val_auc did not improve from 0.88359\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 175ms/step - accuracy: 0.7271 - auc: 0.8250 - loss: 0.0566 - precision: 0.6632 - recall: 0.9229 - val_accuracy: 0.5661 - val_auc: 0.4498 - val_loss: 0.0755 - val_precision: 0.5341 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.6486 - auc: 0.8249 - loss: 0.0562 - precision: 0.5926 - recall: 0.9485\n",
            "Epoch 33: val_auc did not improve from 0.88359\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - accuracy: 0.6771 - auc: 0.8367 - loss: 0.0548 - precision: 0.6161 - recall: 0.9400 - val_accuracy: 0.5979 - val_auc: 0.8569 - val_loss: 0.0892 - val_precision: 0.8462 - val_recall: 0.2340 - learning_rate: 5.0000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.7034 - auc: 0.8022 - loss: 0.0566 - precision: 0.6496 - recall: 0.8605\n",
            "Epoch 34: val_auc did not improve from 0.88359\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 196ms/step - accuracy: 0.6786 - auc: 0.7973 - loss: 0.0562 - precision: 0.6263 - recall: 0.8857 - val_accuracy: 0.8307 - val_auc: 0.8760 - val_loss: 0.0614 - val_precision: 0.7981 - val_recall: 0.8830 - learning_rate: 5.0000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.6839 - auc: 0.8355 - loss: 0.0526 - precision: 0.6236 - recall: 0.9263\n",
            "Epoch 35: val_auc did not improve from 0.88359\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 190ms/step - accuracy: 0.6957 - auc: 0.8353 - loss: 0.0520 - precision: 0.6330 - recall: 0.9314 - val_accuracy: 0.6931 - val_auc: 0.8663 - val_loss: 0.0583 - val_precision: 0.6364 - val_recall: 0.8936 - learning_rate: 5.0000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.7313 - auc: 0.8507 - loss: 0.0498 - precision: 0.6789 - recall: 0.9338\n",
            "Epoch 36: val_auc did not improve from 0.88359\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 170ms/step - accuracy: 0.7214 - auc: 0.8408 - loss: 0.0502 - precision: 0.6591 - recall: 0.9171 - val_accuracy: 0.5661 - val_auc: 0.7960 - val_loss: 0.0647 - val_precision: 0.5341 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.6738 - auc: 0.8205 - loss: 0.0527 - precision: 0.6148 - recall: 0.8814\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 37: val_auc did not improve from 0.88359\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 185ms/step - accuracy: 0.6957 - auc: 0.8348 - loss: 0.0507 - precision: 0.6367 - recall: 0.9114 - val_accuracy: 0.5820 - val_auc: 0.8826 - val_loss: 0.0514 - val_precision: 0.5449 - val_recall: 0.9681 - learning_rate: 5.0000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.6863 - auc: 0.8270 - loss: 0.0498 - precision: 0.6289 - recall: 0.9554\n",
            "Epoch 38: val_auc improved from 0.88359 to 0.89194, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 189ms/step - accuracy: 0.7157 - auc: 0.8414 - loss: 0.0483 - precision: 0.6477 - recall: 0.9457 - val_accuracy: 0.8254 - val_auc: 0.8919 - val_loss: 0.0553 - val_precision: 0.8765 - val_recall: 0.7553 - learning_rate: 2.5000e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.7488 - auc: 0.8484 - loss: 0.0471 - precision: 0.6910 - recall: 0.9345\n",
            "Epoch 39: val_auc did not improve from 0.89194\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 165ms/step - accuracy: 0.7314 - auc: 0.8455 - loss: 0.0477 - precision: 0.6716 - recall: 0.9057 - val_accuracy: 0.5661 - val_auc: 0.7105 - val_loss: 0.0745 - val_precision: 0.5341 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.7165 - auc: 0.8884 - loss: 0.0445 - precision: 0.6396 - recall: 0.9599\n",
            "Epoch 40: val_auc did not improve from 0.89194\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 187ms/step - accuracy: 0.7243 - auc: 0.8486 - loss: 0.0467 - precision: 0.6592 - recall: 0.9286 - val_accuracy: 0.5661 - val_auc: 0.7801 - val_loss: 0.0738 - val_precision: 0.5341 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.7435 - auc: 0.8766 - loss: 0.0445 - precision: 0.6675 - recall: 0.9570\n",
            "Epoch 41: val_auc did not improve from 0.89194\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 181ms/step - accuracy: 0.7243 - auc: 0.8433 - loss: 0.0471 - precision: 0.6586 - recall: 0.9314 - val_accuracy: 0.5608 - val_auc: 0.7219 - val_loss: 0.0776 - val_precision: 0.5311 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.7417 - auc: 0.8588 - loss: 0.0449 - precision: 0.6632 - recall: 0.9648\n",
            "Epoch 42: val_auc did not improve from 0.89194\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 188ms/step - accuracy: 0.7343 - auc: 0.8495 - loss: 0.0459 - precision: 0.6608 - recall: 0.9629 - val_accuracy: 0.5873 - val_auc: 0.8910 - val_loss: 0.0492 - val_precision: 0.5465 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.7069 - auc: 0.8165 - loss: 0.0486 - precision: 0.6609 - recall: 0.9105\n",
            "Epoch 43: val_auc did not improve from 0.89194\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - accuracy: 0.6786 - auc: 0.8176 - loss: 0.0484 - precision: 0.6200 - recall: 0.9229 - val_accuracy: 0.5926 - val_auc: 0.8898 - val_loss: 0.0471 - val_precision: 0.5497 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.6994 - auc: 0.8216 - loss: 0.0477 - precision: 0.6427 - recall: 0.9312\n",
            "Epoch 44: val_auc did not improve from 0.89194\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 180ms/step - accuracy: 0.6957 - auc: 0.8273 - loss: 0.0469 - precision: 0.6310 - recall: 0.9429 - val_accuracy: 0.8466 - val_auc: 0.8777 - val_loss: 0.0529 - val_precision: 0.8736 - val_recall: 0.8085 - learning_rate: 2.5000e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.7504 - auc: 0.8419 - loss: 0.0456 - precision: 0.6798 - recall: 0.9573\n",
            "Epoch 45: val_auc did not improve from 0.89194\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 193ms/step - accuracy: 0.7457 - auc: 0.8462 - loss: 0.0449 - precision: 0.6741 - recall: 0.9514 - val_accuracy: 0.5608 - val_auc: 0.8911 - val_loss: 0.0713 - val_precision: 0.5311 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.7517 - auc: 0.8569 - loss: 0.0443 - precision: 0.6848 - recall: 0.9378\n",
            "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 46: val_auc did not improve from 0.89194\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - accuracy: 0.7343 - auc: 0.8544 - loss: 0.0443 - precision: 0.6660 - recall: 0.9400 - val_accuracy: 0.5820 - val_auc: 0.8586 - val_loss: 0.0583 - val_precision: 0.5434 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.7435 - auc: 0.8780 - loss: 0.0423 - precision: 0.6676 - recall: 0.9362\n",
            "Epoch 47: val_auc did not improve from 0.89194\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - accuracy: 0.7486 - auc: 0.8502 - loss: 0.0445 - precision: 0.6859 - recall: 0.9171 - val_accuracy: 0.5661 - val_auc: 0.8501 - val_loss: 0.0745 - val_precision: 0.5341 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.6607 - auc: 0.8480 - loss: 0.0475 - precision: 0.5915 - recall: 0.9348\n",
            "Epoch 48: val_auc did not improve from 0.89194\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 169ms/step - accuracy: 0.6986 - auc: 0.8491 - loss: 0.0454 - precision: 0.6329 - recall: 0.9457 - val_accuracy: 0.5661 - val_auc: 0.8323 - val_loss: 0.0705 - val_precision: 0.5341 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.7342 - auc: 0.8514 - loss: 0.0444 - precision: 0.6614 - recall: 0.9122\n",
            "Epoch 49: val_auc did not improve from 0.89194\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 175ms/step - accuracy: 0.7414 - auc: 0.8482 - loss: 0.0443 - precision: 0.6779 - recall: 0.9200 - val_accuracy: 0.5714 - val_auc: 0.8014 - val_loss: 0.0665 - val_precision: 0.5371 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.7328 - auc: 0.8713 - loss: 0.0423 - precision: 0.6565 - recall: 0.9600\n",
            "Epoch 50: val_auc did not improve from 0.89194\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 196ms/step - accuracy: 0.7529 - auc: 0.8694 - loss: 0.0420 - precision: 0.6802 - recall: 0.9543 - val_accuracy: 0.5873 - val_auc: 0.8774 - val_loss: 0.0500 - val_precision: 0.5465 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Restoring model weights from the end of the best epoch: 38.\n",
            "\n",
            "======================================================================\n",
            "THRESHOLD OPTIMIZATION & EVALUATION\n",
            "======================================================================\n",
            "\n",
            "Optimal threshold: 0.4702 (default=0.5)\n",
            "  At this threshold: TPR=0.9043, FPR=0.1684\n",
            "\n",
            "Results:\n",
            "  AUC-ROC: 0.8912\n",
            "  Accuracy (default threshold=0.5): 0.8254 (82.54%)\n",
            "  Accuracy (optimal threshold=0.4702): 0.8677 (86.77%)\n",
            "\n",
            "With optimal threshold:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Non-Planet     0.8977    0.8316    0.8634        95\n",
            "      Planet     0.8416    0.9043    0.8718        94\n",
            "\n",
            "    accuracy                         0.8677       189\n",
            "   macro avg     0.8697    0.8679    0.8676       189\n",
            "weighted avg     0.8698    0.8677    0.8676       189\n",
            "\n",
            "\n",
            "Prediction distribution (optimal threshold):\n",
            "  Predicted 0: 88\n",
            "  Predicted 1: 101\n",
            "True distribution:\n",
            "  True 0: 95\n",
            "  True 1: 94\n",
            "\n",
            "Confusion matrix (optimal threshold):\n",
            "[[79 16]\n",
            " [ 9 85]]\n",
            "Precision (optimal threshold): 0.8416\n",
            "\n",
            "======================================================================\n",
            "VISUALIZATIONS\n",
            "======================================================================\n",
            "Saved: confusion_matrix_final.png\n",
            "Saved: training_history_final.png\n",
            "\n",
            "======================================================================\n",
            "PLOTTING LIGHTCURVES WITH PREDICTIONS (n=6)\n",
            "======================================================================\n",
            "Saved: sample_lightcurves_predictions.png\n",
            "\n",
            "======================================================================\n",
            "TRAINING CONFIGURATION: CNN_config1\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "TRAINING\n",
            "======================================================================\n",
            "Epoch 1/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5139 - auc: 0.5287 - loss: 0.2247 - precision: 0.5107 - recall: 0.6901\n",
            "Epoch 1: val_auc improved from None to 0.50202, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - accuracy: 0.5157 - auc: 0.5184 - loss: 0.2181 - precision: 0.5093 - recall: 0.8571 - val_accuracy: 0.5503 - val_auc: 0.5020 - val_loss: 0.2081 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5331 - auc: 0.4934 - loss: 0.2042 - precision: 0.5127 - recall: 0.9849\n",
            "Epoch 2: val_auc improved from 0.50202 to 0.52413, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.5329 - auc: 0.4836 - loss: 0.2026 - precision: 0.5174 - recall: 0.9771 - val_accuracy: 0.5397 - val_auc: 0.5241 - val_loss: 0.1924 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5075 - auc: 0.5396 - loss: 0.1896 - precision: 0.4968 - recall: 1.0000\n",
            "Epoch 3: val_auc improved from 0.52413 to 0.53746, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - accuracy: 0.5271 - auc: 0.5583 - loss: 0.1848 - precision: 0.5140 - recall: 1.0000 - val_accuracy: 0.5450 - val_auc: 0.5375 - val_loss: 0.1794 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5464 - auc: 0.5312 - loss: 0.1775 - precision: 0.5264 - recall: 0.9622\n",
            "Epoch 4: val_auc improved from 0.53746 to 0.56366, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 0.5343 - auc: 0.5545 - loss: 0.1753 - precision: 0.5184 - recall: 0.9657 - val_accuracy: 0.5397 - val_auc: 0.5637 - val_loss: 0.1706 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5074 - auc: 0.5515 - loss: 0.1708 - precision: 0.4978 - recall: 0.9971\n",
            "Epoch 5: val_auc improved from 0.56366 to 0.56892, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5243 - auc: 0.5906 - loss: 0.1657 - precision: 0.5126 - recall: 0.9886 - val_accuracy: 0.5397 - val_auc: 0.5689 - val_loss: 0.1609 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5528 - auc: 0.6081 - loss: 0.1527 - precision: 0.5317 - recall: 0.9950\n",
            "Epoch 6: val_auc improved from 0.56892 to 0.74457, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.5400 - auc: 0.5897 - loss: 0.1515 - precision: 0.5210 - recall: 0.9914 - val_accuracy: 0.5397 - val_auc: 0.7446 - val_loss: 0.1538 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5452 - auc: 0.5998 - loss: 0.1462 - precision: 0.5265 - recall: 0.9797\n",
            "Epoch 7: val_auc did not improve from 0.74457\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.5371 - auc: 0.6323 - loss: 0.1431 - precision: 0.5196 - recall: 0.9857 - val_accuracy: 0.5397 - val_auc: 0.5749 - val_loss: 0.1480 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5256 - auc: 0.6203 - loss: 0.1378 - precision: 0.5095 - recall: 0.9941\n",
            "Epoch 8: val_auc did not improve from 0.74457\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.5371 - auc: 0.6105 - loss: 0.1362 - precision: 0.5194 - recall: 0.9943 - val_accuracy: 0.5397 - val_auc: 0.6751 - val_loss: 0.1408 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5123 - auc: 0.6215 - loss: 0.1338 - precision: 0.5006 - recall: 0.9704\n",
            "Epoch 9: val_auc did not improve from 0.74457\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.5329 - auc: 0.6375 - loss: 0.1310 - precision: 0.5173 - recall: 0.9829 - val_accuracy: 0.5450 - val_auc: 0.5764 - val_loss: 0.1357 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5500 - auc: 0.6584 - loss: 0.1256 - precision: 0.5323 - recall: 0.9913\n",
            "Epoch 10: val_auc did not improve from 0.74457\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.5357 - auc: 0.6431 - loss: 0.1242 - precision: 0.5188 - recall: 0.9857 - val_accuracy: 0.5450 - val_auc: 0.6184 - val_loss: 0.1307 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5229 - auc: 0.6470 - loss: 0.1203 - precision: 0.5149 - recall: 0.9797\n",
            "Epoch 11: val_auc did not improve from 0.74457\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.5314 - auc: 0.6522 - loss: 0.1195 - precision: 0.5165 - recall: 0.9857 - val_accuracy: 0.5450 - val_auc: 0.6375 - val_loss: 0.1259 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5204 - auc: 0.6741 - loss: 0.1150 - precision: 0.5079 - recall: 0.9976\n",
            "Epoch 12: val_auc did not improve from 0.74457\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.5243 - auc: 0.6516 - loss: 0.1141 - precision: 0.5125 - recall: 0.9943 - val_accuracy: 0.5450 - val_auc: 0.6646 - val_loss: 0.1212 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5413 - auc: 0.6984 - loss: 0.1099 - precision: 0.5271 - recall: 0.9922\n",
            "Epoch 13: val_auc did not improve from 0.74457\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.5400 - auc: 0.6843 - loss: 0.1089 - precision: 0.5210 - recall: 0.9943 - val_accuracy: 0.7407 - val_auc: 0.6292 - val_loss: 0.1191 - val_precision: 0.7848 - val_recall: 0.6596 - learning_rate: 5.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5299 - auc: 0.6890 - loss: 0.1083 - precision: 0.5213 - recall: 0.9852\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 14: val_auc did not improve from 0.74457\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.5386 - auc: 0.7084 - loss: 0.1054 - precision: 0.5202 - recall: 0.9914 - val_accuracy: 0.7090 - val_auc: 0.6340 - val_loss: 0.1157 - val_precision: 0.8095 - val_recall: 0.5426 - learning_rate: 5.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.5349 - auc: 0.6946 - loss: 0.1039 - precision: 0.5187 - recall: 0.9862\n",
            "Epoch 15: val_auc did not improve from 0.74457\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.5400 - auc: 0.6848 - loss: 0.1032 - precision: 0.5210 - recall: 0.9914 - val_accuracy: 0.6138 - val_auc: 0.6811 - val_loss: 0.1138 - val_precision: 0.5660 - val_recall: 0.9574 - learning_rate: 2.5000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5267 - auc: 0.6925 - loss: 0.1019 - precision: 0.5098 - recall: 0.9894\n",
            "Epoch 16: val_auc did not improve from 0.74457\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.5286 - auc: 0.6753 - loss: 0.1025 - precision: 0.5149 - recall: 0.9886 - val_accuracy: 0.5661 - val_auc: 0.7032 - val_loss: 0.1120 - val_precision: 0.5349 - val_recall: 0.9787 - learning_rate: 2.5000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5268 - auc: 0.7253 - loss: 0.0991 - precision: 0.5105 - recall: 0.9960\n",
            "Epoch 17: val_auc did not improve from 0.74457\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.5429 - auc: 0.6699 - loss: 0.0997 - precision: 0.5225 - recall: 0.9971 - val_accuracy: 0.5608 - val_auc: 0.7127 - val_loss: 0.1104 - val_precision: 0.5314 - val_recall: 0.9894 - learning_rate: 2.5000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5216 - auc: 0.6913 - loss: 0.0995 - precision: 0.5016 - recall: 0.9914\n",
            "Epoch 18: val_auc did not improve from 0.74457\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.5357 - auc: 0.6973 - loss: 0.0984 - precision: 0.5187 - recall: 0.9914 - val_accuracy: 0.5608 - val_auc: 0.6784 - val_loss: 0.1080 - val_precision: 0.5311 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5317 - auc: 0.7039 - loss: 0.0960 - precision: 0.5110 - recall: 0.9982\n",
            "Epoch 19: val_auc improved from 0.74457 to 0.74647, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5386 - auc: 0.6826 - loss: 0.0964 - precision: 0.5202 - recall: 0.9914 - val_accuracy: 0.5767 - val_auc: 0.7465 - val_loss: 0.1073 - val_precision: 0.5412 - val_recall: 0.9787 - learning_rate: 2.5000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5461 - auc: 0.6966 - loss: 0.0963 - precision: 0.5224 - recall: 0.9893\n",
            "Epoch 20: val_auc improved from 0.74647 to 0.83880, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5400 - auc: 0.7050 - loss: 0.0958 - precision: 0.5210 - recall: 0.9914 - val_accuracy: 0.5608 - val_auc: 0.8388 - val_loss: 0.1055 - val_precision: 0.5314 - val_recall: 0.9894 - learning_rate: 2.5000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5427 - auc: 0.7047 - loss: 0.0962 - precision: 0.5295 - recall: 0.9827\n",
            "Epoch 21: val_auc did not improve from 0.83880\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.5343 - auc: 0.6943 - loss: 0.0950 - precision: 0.5180 - recall: 0.9857 - val_accuracy: 0.5556 - val_auc: 0.7872 - val_loss: 0.1042 - val_precision: 0.5287 - val_recall: 0.9787 - learning_rate: 2.5000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5384 - auc: 0.7396 - loss: 0.0923 - precision: 0.5246 - recall: 0.9983\n",
            "Epoch 22: val_auc did not improve from 0.83880\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.5357 - auc: 0.7200 - loss: 0.0923 - precision: 0.5186 - recall: 0.9943 - val_accuracy: 0.6243 - val_auc: 0.7712 - val_loss: 0.1026 - val_precision: 0.5706 - val_recall: 0.9894 - learning_rate: 2.5000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5045 - auc: 0.6985 - loss: 0.0926 - precision: 0.4890 - recall: 0.9818\n",
            "Epoch 23: val_auc did not improve from 0.83880\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.5314 - auc: 0.6858 - loss: 0.0924 - precision: 0.5165 - recall: 0.9857 - val_accuracy: 0.5714 - val_auc: 0.8145 - val_loss: 0.1011 - val_precision: 0.5371 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5233 - auc: 0.7200 - loss: 0.0917 - precision: 0.5053 - recall: 0.9841\n",
            "Epoch 24: val_auc did not improve from 0.83880\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.5314 - auc: 0.7200 - loss: 0.0906 - precision: 0.5164 - recall: 0.9886 - val_accuracy: 0.5661 - val_auc: 0.7270 - val_loss: 0.0995 - val_precision: 0.5341 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5507 - auc: 0.7204 - loss: 0.0889 - precision: 0.5321 - recall: 0.9925\n",
            "Epoch 25: val_auc improved from 0.83880 to 0.85106, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.5414 - auc: 0.7142 - loss: 0.0888 - precision: 0.5217 - recall: 0.9971 - val_accuracy: 0.7196 - val_auc: 0.8511 - val_loss: 0.0997 - val_precision: 0.8475 - val_recall: 0.5319 - learning_rate: 2.5000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5339 - auc: 0.6924 - loss: 0.0877 - precision: 0.5113 - recall: 0.9978\n",
            "Epoch 26: val_auc did not improve from 0.85106\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - accuracy: 0.5386 - auc: 0.7140 - loss: 0.0875 - precision: 0.5202 - recall: 0.9914 - val_accuracy: 0.7196 - val_auc: 0.8389 - val_loss: 0.0989 - val_precision: 0.8727 - val_recall: 0.5106 - learning_rate: 2.5000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5264 - auc: 0.7157 - loss: 0.0868 - precision: 0.5026 - recall: 0.9960\n",
            "Epoch 27: val_auc did not improve from 0.85106\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.5414 - auc: 0.7188 - loss: 0.0858 - precision: 0.5218 - recall: 0.9914 - val_accuracy: 0.7196 - val_auc: 0.8017 - val_loss: 0.0978 - val_precision: 0.8596 - val_recall: 0.5213 - learning_rate: 2.5000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.5447 - auc: 0.7379 - loss: 0.0853 - precision: 0.5245 - recall: 0.9990\n",
            "Epoch 28: val_auc did not improve from 0.85106\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.5443 - auc: 0.7116 - loss: 0.0856 - precision: 0.5233 - recall: 0.9943 - val_accuracy: 0.6931 - val_auc: 0.7841 - val_loss: 0.0967 - val_precision: 0.8750 - val_recall: 0.4468 - learning_rate: 2.5000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5391 - auc: 0.6933 - loss: 0.0854 - precision: 0.5220 - recall: 0.9911\n",
            "Epoch 29: val_auc did not improve from 0.85106\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.5357 - auc: 0.6957 - loss: 0.0855 - precision: 0.5187 - recall: 0.9914 - val_accuracy: 0.6984 - val_auc: 0.8059 - val_loss: 0.0941 - val_precision: 0.6276 - val_recall: 0.9681 - learning_rate: 2.5000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5283 - auc: 0.6831 - loss: 0.0852 - precision: 0.5111 - recall: 0.9890\n",
            "Epoch 30: val_auc did not improve from 0.85106\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.5400 - auc: 0.7292 - loss: 0.0831 - precision: 0.5210 - recall: 0.9943 - val_accuracy: 0.7831 - val_auc: 0.7945 - val_loss: 0.0931 - val_precision: 0.7265 - val_recall: 0.9043 - learning_rate: 2.5000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.5291 - auc: 0.7030 - loss: 0.0832 - precision: 0.5106 - recall: 0.9935\n",
            "Epoch 31: val_auc did not improve from 0.85106\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.5429 - auc: 0.7295 - loss: 0.0821 - precision: 0.5225 - recall: 0.9971 - val_accuracy: 0.5714 - val_auc: 0.8313 - val_loss: 0.0903 - val_precision: 0.5380 - val_recall: 0.9787 - learning_rate: 2.5000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5262 - auc: 0.7042 - loss: 0.0817 - precision: 0.5022 - recall: 0.9912\n",
            "Epoch 32: val_auc did not improve from 0.85106\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.5414 - auc: 0.6958 - loss: 0.0822 - precision: 0.5219 - recall: 0.9886 - val_accuracy: 0.7249 - val_auc: 0.8333 - val_loss: 0.0905 - val_precision: 0.6522 - val_recall: 0.9574 - learning_rate: 2.5000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.5417 - auc: 0.6918 - loss: 0.0835 - precision: 0.5355 - recall: 0.9797\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 33: val_auc did not improve from 0.85106\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5257 - auc: 0.6835 - loss: 0.0830 - precision: 0.5133 - recall: 0.9914 - val_accuracy: 0.5608 - val_auc: 0.8434 - val_loss: 0.0883 - val_precision: 0.5314 - val_recall: 0.9894 - learning_rate: 2.5000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.4945 - auc: 0.7199 - loss: 0.0820 - precision: 0.4803 - recall: 0.9948\n",
            "Epoch 34: val_auc did not improve from 0.85106\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.5300 - auc: 0.7300 - loss: 0.0810 - precision: 0.5156 - recall: 0.9914 - val_accuracy: 0.5820 - val_auc: 0.8443 - val_loss: 0.0888 - val_precision: 0.5444 - val_recall: 0.9787 - learning_rate: 1.2500e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5083 - auc: 0.7590 - loss: 0.0789 - precision: 0.4885 - recall: 0.9972\n",
            "Epoch 35: val_auc did not improve from 0.85106\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.5414 - auc: 0.7443 - loss: 0.0790 - precision: 0.5217 - recall: 0.9943 - val_accuracy: 0.7249 - val_auc: 0.7991 - val_loss: 0.0903 - val_precision: 0.8500 - val_recall: 0.5426 - learning_rate: 1.2500e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5159 - auc: 0.6826 - loss: 0.0812 - precision: 0.4998 - recall: 0.9925\n",
            "Epoch 36: val_auc did not improve from 0.85106\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.5371 - auc: 0.7274 - loss: 0.0795 - precision: 0.5195 - recall: 0.9914 - val_accuracy: 0.7778 - val_auc: 0.8050 - val_loss: 0.0885 - val_precision: 0.7241 - val_recall: 0.8936 - learning_rate: 1.2500e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5424 - auc: 0.7669 - loss: 0.0777 - precision: 0.5232 - recall: 0.9958\n",
            "Epoch 37: val_auc did not improve from 0.85106\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.5414 - auc: 0.7470 - loss: 0.0784 - precision: 0.5218 - recall: 0.9914 - val_accuracy: 0.6455 - val_auc: 0.7839 - val_loss: 0.0910 - val_precision: 0.9091 - val_recall: 0.3191 - learning_rate: 1.2500e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5442 - auc: 0.7078 - loss: 0.0793 - precision: 0.5279 - recall: 0.9962\n",
            "Epoch 38: val_auc did not improve from 0.85106\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.5414 - auc: 0.7341 - loss: 0.0788 - precision: 0.5217 - recall: 0.9943 - val_accuracy: 0.6349 - val_auc: 0.7757 - val_loss: 0.0908 - val_precision: 0.9032 - val_recall: 0.2979 - learning_rate: 1.2500e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5385 - auc: 0.7270 - loss: 0.0777 - precision: 0.5127 - recall: 0.9994\n",
            "Epoch 39: val_auc did not improve from 0.85106\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.5400 - auc: 0.7543 - loss: 0.0767 - precision: 0.5209 - recall: 0.9971 - val_accuracy: 0.5979 - val_auc: 0.7692 - val_loss: 0.0917 - val_precision: 0.9091 - val_recall: 0.2128 - learning_rate: 1.2500e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5315 - auc: 0.7674 - loss: 0.0760 - precision: 0.5114 - recall: 0.9956\n",
            "Epoch 40: val_auc did not improve from 0.85106\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.5457 - auc: 0.7277 - loss: 0.0776 - precision: 0.5241 - recall: 0.9943 - val_accuracy: 0.6190 - val_auc: 0.8384 - val_loss: 0.0905 - val_precision: 0.8929 - val_recall: 0.2660 - learning_rate: 1.2500e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5384 - auc: 0.7361 - loss: 0.0765 - precision: 0.5142 - recall: 0.9977\n",
            "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 41: val_auc did not improve from 0.85106\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.5471 - auc: 0.7344 - loss: 0.0766 - precision: 0.5250 - recall: 0.9914 - val_accuracy: 0.6190 - val_auc: 0.8048 - val_loss: 0.0905 - val_precision: 0.9231 - val_recall: 0.2553 - learning_rate: 1.2500e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5335 - auc: 0.7501 - loss: 0.0768 - precision: 0.5210 - recall: 0.9889\n",
            "Epoch 42: val_auc did not improve from 0.85106\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.5414 - auc: 0.7439 - loss: 0.0765 - precision: 0.5219 - recall: 0.9886 - val_accuracy: 0.6190 - val_auc: 0.8041 - val_loss: 0.0900 - val_precision: 0.8929 - val_recall: 0.2660 - learning_rate: 6.2500e-05\n",
            "Epoch 43/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5634 - auc: 0.7687 - loss: 0.0750 - precision: 0.5439 - recall: 0.9969\n",
            "Epoch 43: val_auc did not improve from 0.85106\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.5429 - auc: 0.7548 - loss: 0.0756 - precision: 0.5226 - recall: 0.9914 - val_accuracy: 0.6243 - val_auc: 0.7826 - val_loss: 0.0900 - val_precision: 0.9259 - val_recall: 0.2660 - learning_rate: 6.2500e-05\n",
            "Epoch 44/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5688 - auc: 0.7670 - loss: 0.0750 - precision: 0.5437 - recall: 0.9896\n",
            "Epoch 44: val_auc did not improve from 0.85106\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.5557 - auc: 0.7604 - loss: 0.0752 - precision: 0.5297 - recall: 0.9943 - val_accuracy: 0.6032 - val_auc: 0.7675 - val_loss: 0.0904 - val_precision: 0.9130 - val_recall: 0.2234 - learning_rate: 6.2500e-05\n",
            "Epoch 45/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5419 - auc: 0.7597 - loss: 0.0749 - precision: 0.5216 - recall: 0.9960\n",
            "Epoch 45: val_auc did not improve from 0.85106\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.5414 - auc: 0.7759 - loss: 0.0743 - precision: 0.5217 - recall: 0.9971 - val_accuracy: 0.6032 - val_auc: 0.7720 - val_loss: 0.0902 - val_precision: 0.9130 - val_recall: 0.2234 - learning_rate: 6.2500e-05\n",
            "Epoch 45: early stopping\n",
            "Restoring model weights from the end of the best epoch: 25.\n",
            "\n",
            "======================================================================\n",
            "THRESHOLD OPTIMIZATION & EVALUATION\n",
            "======================================================================\n",
            "\n",
            "Optimal threshold: 0.4977 (default=0.5)\n",
            "  At this threshold: TPR=0.9043, FPR=0.2211\n",
            "\n",
            "Results:\n",
            "  AUC-ROC: 0.8829\n",
            "  Accuracy (default threshold=0.5): 0.7196 (71.96%)\n",
            "  Accuracy (optimal threshold=0.4977): 0.8413 (84.13%)\n",
            "\n",
            "With optimal threshold:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Non-Planet     0.8916    0.7789    0.8315        95\n",
            "      Planet     0.8019    0.9043    0.8500        94\n",
            "\n",
            "    accuracy                         0.8413       189\n",
            "   macro avg     0.8467    0.8416    0.8407       189\n",
            "weighted avg     0.8470    0.8413    0.8407       189\n",
            "\n",
            "\n",
            "Prediction distribution (optimal threshold):\n",
            "  Predicted 0: 83\n",
            "  Predicted 1: 106\n",
            "True distribution:\n",
            "  True 0: 95\n",
            "  True 1: 94\n",
            "\n",
            "Confusion matrix (optimal threshold):\n",
            "[[74 21]\n",
            " [ 9 85]]\n",
            "Precision (optimal threshold): 0.8019\n",
            "\n",
            "======================================================================\n",
            "VISUALIZATIONS\n",
            "======================================================================\n",
            "Saved: confusion_matrix_final.png\n",
            "Saved: training_history_final.png\n",
            "\n",
            "======================================================================\n",
            "PLOTTING LIGHTCURVES WITH PREDICTIONS (n=6)\n",
            "======================================================================\n",
            "Saved: sample_lightcurves_predictions.png\n",
            "\n",
            "======================================================================\n",
            "TRAINING CONFIGURATION: CNN_config2\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "TRAINING\n",
            "======================================================================\n",
            "Epoch 1/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.4864 - auc: 0.4277 - loss: 0.5195 - precision: 0.4881 - recall: 0.8893\n",
            "Epoch 1: val_auc improved from None to 0.55829, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 217ms/step - accuracy: 0.5057 - auc: 0.4754 - loss: 0.5071 - precision: 0.5031 - recall: 0.9314 - val_accuracy: 0.5238 - val_auc: 0.5583 - val_loss: 0.4825 - val_precision: 0.5109 - val_recall: 1.0000 - learning_rate: 3.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.5142 - auc: 0.5635 - loss: 0.4696 - precision: 0.5041 - recall: 0.9749\n",
            "Epoch 2: val_auc improved from 0.55829 to 0.55946, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 179ms/step - accuracy: 0.5229 - auc: 0.5727 - loss: 0.4651 - precision: 0.5120 - recall: 0.9714 - val_accuracy: 0.5344 - val_auc: 0.5595 - val_loss: 0.4599 - val_precision: 0.5165 - val_recall: 1.0000 - learning_rate: 3.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.5615 - auc: 0.6035 - loss: 0.4501 - precision: 0.5510 - recall: 0.9679\n",
            "Epoch 3: val_auc did not improve from 0.55946\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 185ms/step - accuracy: 0.5314 - auc: 0.6037 - loss: 0.4452 - precision: 0.5167 - recall: 0.9743 - val_accuracy: 0.5344 - val_auc: 0.5017 - val_loss: 0.4384 - val_precision: 0.5165 - val_recall: 1.0000 - learning_rate: 3.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.5401 - auc: 0.6415 - loss: 0.4353 - precision: 0.5148 - recall: 0.9519\n",
            "Epoch 4: val_auc did not improve from 0.55946\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 189ms/step - accuracy: 0.5286 - auc: 0.6188 - loss: 0.4371 - precision: 0.5158 - recall: 0.9343 - val_accuracy: 0.5238 - val_auc: 0.4767 - val_loss: 0.4165 - val_precision: 0.5109 - val_recall: 1.0000 - learning_rate: 3.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.5044 - auc: 0.6459 - loss: 0.4090 - precision: 0.4969 - recall: 0.9896\n",
            "Epoch 5: val_auc did not improve from 0.55946\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 201ms/step - accuracy: 0.5271 - auc: 0.6311 - loss: 0.4084 - precision: 0.5142 - recall: 0.9857 - val_accuracy: 0.5238 - val_auc: 0.5188 - val_loss: 0.3950 - val_precision: 0.5109 - val_recall: 1.0000 - learning_rate: 3.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.5420 - auc: 0.6747 - loss: 0.3902 - precision: 0.5084 - recall: 0.9560\n",
            "Epoch 6: val_auc improved from 0.55946 to 0.59910, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 199ms/step - accuracy: 0.5557 - auc: 0.6723 - loss: 0.3859 - precision: 0.5309 - recall: 0.9571 - val_accuracy: 0.5238 - val_auc: 0.5991 - val_loss: 0.3777 - val_precision: 0.5109 - val_recall: 1.0000 - learning_rate: 3.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.5273 - auc: 0.6936 - loss: 0.3718 - precision: 0.5133 - recall: 0.9917\n",
            "Epoch 7: val_auc did not improve from 0.59910\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 198ms/step - accuracy: 0.5414 - auc: 0.6938 - loss: 0.3682 - precision: 0.5219 - recall: 0.9886 - val_accuracy: 0.5397 - val_auc: 0.5374 - val_loss: 0.3640 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 3.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.5398 - auc: 0.7398 - loss: 0.3546 - precision: 0.5148 - recall: 0.9400\n",
            "Epoch 8: val_auc did not improve from 0.59910\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 185ms/step - accuracy: 0.5371 - auc: 0.6934 - loss: 0.3583 - precision: 0.5206 - recall: 0.9400 - val_accuracy: 0.5079 - val_auc: 0.5551 - val_loss: 0.3500 - val_precision: 0.5027 - val_recall: 1.0000 - learning_rate: 3.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.5456 - auc: 0.6600 - loss: 0.3529 - precision: 0.5290 - recall: 0.9699\n",
            "Epoch 9: val_auc improved from 0.59910 to 0.61646, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 174ms/step - accuracy: 0.5586 - auc: 0.6751 - loss: 0.3462 - precision: 0.5323 - recall: 0.9657 - val_accuracy: 0.5450 - val_auc: 0.6165 - val_loss: 0.3369 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 3.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.5694 - auc: 0.7212 - loss: 0.3301 - precision: 0.5331 - recall: 0.9608\n",
            "Epoch 10: val_auc improved from 0.61646 to 0.78908, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 186ms/step - accuracy: 0.5843 - auc: 0.7367 - loss: 0.3261 - precision: 0.5486 - recall: 0.9514 - val_accuracy: 0.5503 - val_auc: 0.7891 - val_loss: 0.3259 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 3.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.5473 - auc: 0.7185 - loss: 0.3220 - precision: 0.5292 - recall: 0.9643\n",
            "Epoch 11: val_auc improved from 0.78908 to 0.79748, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - accuracy: 0.5614 - auc: 0.7163 - loss: 0.3192 - precision: 0.5343 - recall: 0.9571 - val_accuracy: 0.5503 - val_auc: 0.7975 - val_loss: 0.3145 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 3.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.6192 - auc: 0.7585 - loss: 0.3077 - precision: 0.5762 - recall: 0.9591\n",
            "Epoch 12: val_auc improved from 0.79748 to 0.84177, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 205ms/step - accuracy: 0.6000 - auc: 0.7296 - loss: 0.3091 - precision: 0.5606 - recall: 0.9257 - val_accuracy: 0.5450 - val_auc: 0.8418 - val_loss: 0.3078 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 3.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.5397 - auc: 0.6808 - loss: 0.3027 - precision: 0.5199 - recall: 0.9711\n",
            "Epoch 13: val_auc did not improve from 0.84177\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 185ms/step - accuracy: 0.5614 - auc: 0.7040 - loss: 0.2988 - precision: 0.5340 - recall: 0.9657 - val_accuracy: 0.5503 - val_auc: 0.8047 - val_loss: 0.2965 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 3.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.5869 - auc: 0.7804 - loss: 0.2860 - precision: 0.5460 - recall: 0.9758\n",
            "Epoch 14: val_auc did not improve from 0.84177\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 175ms/step - accuracy: 0.5757 - auc: 0.7484 - loss: 0.2870 - precision: 0.5413 - recall: 0.9914 - val_accuracy: 0.5503 - val_auc: 0.7967 - val_loss: 0.2862 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 3.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.6214 - auc: 0.7308 - loss: 0.2853 - precision: 0.5751 - recall: 0.9111\n",
            "Epoch 15: val_auc did not improve from 0.84177\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 199ms/step - accuracy: 0.6100 - auc: 0.7101 - loss: 0.2824 - precision: 0.5672 - recall: 0.9286 - val_accuracy: 0.5503 - val_auc: 0.7718 - val_loss: 0.2802 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 3.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.5779 - auc: 0.7949 - loss: 0.2699 - precision: 0.5368 - recall: 0.9703\n",
            "Epoch 16: val_auc did not improve from 0.84177\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 174ms/step - accuracy: 0.5871 - auc: 0.7836 - loss: 0.2686 - precision: 0.5498 - recall: 0.9629 - val_accuracy: 0.5503 - val_auc: 0.7459 - val_loss: 0.2768 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 3.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.6177 - auc: 0.7564 - loss: 0.2648 - precision: 0.5689 - recall: 0.9630\n",
            "Epoch 17: val_auc did not improve from 0.84177\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 183ms/step - accuracy: 0.6043 - auc: 0.7732 - loss: 0.2618 - precision: 0.5618 - recall: 0.9486 - val_accuracy: 0.5503 - val_auc: 0.7025 - val_loss: 0.2748 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 3.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.6299 - auc: 0.7636 - loss: 0.2565 - precision: 0.5791 - recall: 0.9596\n",
            "Epoch 18: val_auc did not improve from 0.84177\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 204ms/step - accuracy: 0.6543 - auc: 0.7787 - loss: 0.2544 - precision: 0.5978 - recall: 0.9429 - val_accuracy: 0.5556 - val_auc: 0.7924 - val_loss: 0.2564 - val_precision: 0.5281 - val_recall: 1.0000 - learning_rate: 3.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.6089 - auc: 0.8051 - loss: 0.2471 - precision: 0.5556 - recall: 0.9597\n",
            "Epoch 19: val_auc did not improve from 0.84177\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 203ms/step - accuracy: 0.6200 - auc: 0.7952 - loss: 0.2468 - precision: 0.5722 - recall: 0.9514 - val_accuracy: 0.5661 - val_auc: 0.7879 - val_loss: 0.2494 - val_precision: 0.5341 - val_recall: 1.0000 - learning_rate: 3.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.6302 - auc: 0.7660 - loss: 0.2432 - precision: 0.5809 - recall: 0.9578\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
            "\n",
            "Epoch 20: val_auc did not improve from 0.84177\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - accuracy: 0.6343 - auc: 0.7766 - loss: 0.2407 - precision: 0.5813 - recall: 0.9600 - val_accuracy: 0.5556 - val_auc: 0.7671 - val_loss: 0.2505 - val_precision: 0.5281 - val_recall: 1.0000 - learning_rate: 3.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.6296 - auc: 0.7726 - loss: 0.2378 - precision: 0.5715 - recall: 0.9285\n",
            "Epoch 21: val_auc did not improve from 0.84177\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 184ms/step - accuracy: 0.6500 - auc: 0.7832 - loss: 0.2363 - precision: 0.5946 - recall: 0.9429 - val_accuracy: 0.5661 - val_auc: 0.7703 - val_loss: 0.2467 - val_precision: 0.5341 - val_recall: 1.0000 - learning_rate: 1.5000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.6461 - auc: 0.7901 - loss: 0.2328 - precision: 0.5923 - recall: 0.9658\n",
            "Epoch 22: val_auc did not improve from 0.84177\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 190ms/step - accuracy: 0.6400 - auc: 0.7931 - loss: 0.2319 - precision: 0.5848 - recall: 0.9657 - val_accuracy: 0.5661 - val_auc: 0.7705 - val_loss: 0.2475 - val_precision: 0.5341 - val_recall: 1.0000 - learning_rate: 1.5000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.6552 - auc: 0.8080 - loss: 0.2278 - precision: 0.5959 - recall: 0.9428\n",
            "Epoch 23: val_auc did not improve from 0.84177\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 197ms/step - accuracy: 0.6657 - auc: 0.7948 - loss: 0.2289 - precision: 0.6086 - recall: 0.9286 - val_accuracy: 0.5714 - val_auc: 0.7731 - val_loss: 0.2444 - val_precision: 0.5371 - val_recall: 1.0000 - learning_rate: 1.5000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.5948 - auc: 0.7785 - loss: 0.2283 - precision: 0.5414 - recall: 0.9329\n",
            "Epoch 24: val_auc did not improve from 0.84177\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 184ms/step - accuracy: 0.6114 - auc: 0.7644 - loss: 0.2286 - precision: 0.5672 - recall: 0.9400 - val_accuracy: 0.5661 - val_auc: 0.7708 - val_loss: 0.2372 - val_precision: 0.5341 - val_recall: 1.0000 - learning_rate: 1.5000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.6518 - auc: 0.7875 - loss: 0.2245 - precision: 0.5877 - recall: 0.9605\n",
            "Epoch 25: val_auc did not improve from 0.84177\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 196ms/step - accuracy: 0.6486 - auc: 0.7748 - loss: 0.2253 - precision: 0.5942 - recall: 0.9371 - val_accuracy: 0.5714 - val_auc: 0.7830 - val_loss: 0.2364 - val_precision: 0.5371 - val_recall: 1.0000 - learning_rate: 1.5000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.6153 - auc: 0.7730 - loss: 0.2249 - precision: 0.5687 - recall: 0.9280\n",
            "Epoch 26: val_auc did not improve from 0.84177\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 207ms/step - accuracy: 0.6086 - auc: 0.7531 - loss: 0.2262 - precision: 0.5667 - recall: 0.9229 - val_accuracy: 0.5661 - val_auc: 0.7326 - val_loss: 0.2407 - val_precision: 0.5345 - val_recall: 0.9894 - learning_rate: 1.5000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.6492 - auc: 0.7782 - loss: 0.2190 - precision: 0.5957 - recall: 0.9788\n",
            "Epoch 27: val_auc did not improve from 0.84177\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 182ms/step - accuracy: 0.6600 - auc: 0.7895 - loss: 0.2180 - precision: 0.6007 - recall: 0.9543 - val_accuracy: 0.5714 - val_auc: 0.8251 - val_loss: 0.2240 - val_precision: 0.5371 - val_recall: 1.0000 - learning_rate: 1.5000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.6186 - auc: 0.7916 - loss: 0.2152 - precision: 0.5672 - recall: 0.9685\n",
            "Epoch 28: val_auc improved from 0.84177 to 0.84625, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - accuracy: 0.6500 - auc: 0.8044 - loss: 0.2135 - precision: 0.5933 - recall: 0.9543 - val_accuracy: 0.5714 - val_auc: 0.8462 - val_loss: 0.2230 - val_precision: 0.5371 - val_recall: 1.0000 - learning_rate: 1.5000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.6073 - auc: 0.7913 - loss: 0.2136 - precision: 0.5602 - recall: 0.9707\n",
            "Epoch 29: val_auc improved from 0.84625 to 0.84759, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - accuracy: 0.6443 - auc: 0.8121 - loss: 0.2110 - precision: 0.5875 - recall: 0.9686 - val_accuracy: 0.5714 - val_auc: 0.8476 - val_loss: 0.2164 - val_precision: 0.5371 - val_recall: 1.0000 - learning_rate: 1.5000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.6944 - auc: 0.8085 - loss: 0.2089 - precision: 0.6315 - recall: 0.9691\n",
            "Epoch 30: val_auc did not improve from 0.84759\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 179ms/step - accuracy: 0.6557 - auc: 0.8006 - loss: 0.2093 - precision: 0.5965 - recall: 0.9629 - val_accuracy: 0.5661 - val_auc: 0.7336 - val_loss: 0.2255 - val_precision: 0.5345 - val_recall: 0.9894 - learning_rate: 1.5000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.6788 - auc: 0.7949 - loss: 0.2104 - precision: 0.6176 - recall: 0.9368\n",
            "Epoch 31: val_auc did not improve from 0.84759\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 199ms/step - accuracy: 0.6871 - auc: 0.8086 - loss: 0.2064 - precision: 0.6234 - recall: 0.9457 - val_accuracy: 0.5714 - val_auc: 0.7786 - val_loss: 0.2180 - val_precision: 0.5371 - val_recall: 1.0000 - learning_rate: 1.5000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.6474 - auc: 0.8257 - loss: 0.2022 - precision: 0.6018 - recall: 0.9446\n",
            "Epoch 32: val_auc did not improve from 0.84759\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 185ms/step - accuracy: 0.6314 - auc: 0.7861 - loss: 0.2057 - precision: 0.5810 - recall: 0.9429 - val_accuracy: 0.5714 - val_auc: 0.8270 - val_loss: 0.2102 - val_precision: 0.5371 - val_recall: 1.0000 - learning_rate: 1.5000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.7191 - auc: 0.8201 - loss: 0.2010 - precision: 0.6633 - recall: 0.9356\n",
            "Epoch 33: val_auc did not improve from 0.84759\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 172ms/step - accuracy: 0.6757 - auc: 0.7913 - loss: 0.2022 - precision: 0.6133 - recall: 0.9514 - val_accuracy: 0.5714 - val_auc: 0.7618 - val_loss: 0.2150 - val_precision: 0.5371 - val_recall: 1.0000 - learning_rate: 1.5000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.6372 - auc: 0.7988 - loss: 0.2010 - precision: 0.5775 - recall: 0.9414\n",
            "Epoch 34: val_auc did not improve from 0.84759\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 180ms/step - accuracy: 0.6443 - auc: 0.7900 - loss: 0.2013 - precision: 0.5907 - recall: 0.9400 - val_accuracy: 0.5661 - val_auc: 0.7372 - val_loss: 0.2136 - val_precision: 0.5345 - val_recall: 0.9894 - learning_rate: 1.5000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.7054 - auc: 0.8239 - loss: 0.1950 - precision: 0.6600 - recall: 0.9378\n",
            "Epoch 35: val_auc improved from 0.84759 to 0.88012, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 196ms/step - accuracy: 0.6700 - auc: 0.8189 - loss: 0.1947 - precision: 0.6068 - recall: 0.9657 - val_accuracy: 0.5661 - val_auc: 0.8801 - val_loss: 0.1995 - val_precision: 0.5341 - val_recall: 1.0000 - learning_rate: 1.5000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.6920 - auc: 0.7847 - loss: 0.1986 - precision: 0.6290 - recall: 0.8752\n",
            "Epoch 36: val_auc did not improve from 0.88012\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 187ms/step - accuracy: 0.6871 - auc: 0.7865 - loss: 0.1969 - precision: 0.6292 - recall: 0.9114 - val_accuracy: 0.5661 - val_auc: 0.7310 - val_loss: 0.2203 - val_precision: 0.5341 - val_recall: 1.0000 - learning_rate: 1.5000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.6432 - auc: 0.8254 - loss: 0.1909 - precision: 0.5850 - recall: 0.9727\n",
            "Epoch 37: val_auc did not improve from 0.88012\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 206ms/step - accuracy: 0.6629 - auc: 0.8094 - loss: 0.1921 - precision: 0.6071 - recall: 0.9229 - val_accuracy: 0.5608 - val_auc: 0.7865 - val_loss: 0.2152 - val_precision: 0.5311 - val_recall: 1.0000 - learning_rate: 1.5000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.6379 - auc: 0.8128 - loss: 0.1893 - precision: 0.5849 - recall: 0.9611\n",
            "Epoch 38: val_auc did not improve from 0.88012\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 180ms/step - accuracy: 0.6286 - auc: 0.7903 - loss: 0.1907 - precision: 0.5784 - recall: 0.9486 - val_accuracy: 0.5714 - val_auc: 0.8554 - val_loss: 0.1950 - val_precision: 0.5371 - val_recall: 1.0000 - learning_rate: 1.5000e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7391 - auc: 0.8293 - loss: 0.1857 - precision: 0.6859 - recall: 0.9447\n",
            "Epoch 39: val_auc did not improve from 0.88012\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - accuracy: 0.6829 - auc: 0.7944 - loss: 0.1888 - precision: 0.6203 - recall: 0.9429 - val_accuracy: 0.5608 - val_auc: 0.8666 - val_loss: 0.1940 - val_precision: 0.5311 - val_recall: 1.0000 - learning_rate: 1.5000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.6489 - auc: 0.7842 - loss: 0.1875 - precision: 0.5931 - recall: 0.9361\n",
            "Epoch 40: val_auc did not improve from 0.88012\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 206ms/step - accuracy: 0.6629 - auc: 0.7958 - loss: 0.1860 - precision: 0.6036 - recall: 0.9486 - val_accuracy: 0.5661 - val_auc: 0.7580 - val_loss: 0.2074 - val_precision: 0.5341 - val_recall: 1.0000 - learning_rate: 1.5000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.6737 - auc: 0.8270 - loss: 0.1815 - precision: 0.6129 - recall: 0.9644\n",
            "Epoch 41: val_auc did not improve from 0.88012\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 196ms/step - accuracy: 0.6814 - auc: 0.8299 - loss: 0.1807 - precision: 0.6174 - recall: 0.9543 - val_accuracy: 0.5714 - val_auc: 0.7876 - val_loss: 0.2015 - val_precision: 0.5371 - val_recall: 1.0000 - learning_rate: 1.5000e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.6355 - auc: 0.7823 - loss: 0.1844 - precision: 0.5846 - recall: 0.9400\n",
            "Epoch 42: val_auc did not improve from 0.88012\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 201ms/step - accuracy: 0.6600 - auc: 0.8043 - loss: 0.1810 - precision: 0.6011 - recall: 0.9514 - val_accuracy: 0.5714 - val_auc: 0.8139 - val_loss: 0.2011 - val_precision: 0.5371 - val_recall: 1.0000 - learning_rate: 1.5000e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.6910 - auc: 0.8148 - loss: 0.1816 - precision: 0.6273 - recall: 0.9204\n",
            "Epoch 43: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
            "\n",
            "Epoch 43: val_auc did not improve from 0.88012\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 183ms/step - accuracy: 0.6843 - auc: 0.8102 - loss: 0.1793 - precision: 0.6238 - recall: 0.9286 - val_accuracy: 0.5714 - val_auc: 0.7749 - val_loss: 0.2112 - val_precision: 0.5371 - val_recall: 1.0000 - learning_rate: 1.5000e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.6520 - auc: 0.8018 - loss: 0.1784 - precision: 0.5935 - recall: 0.9192\n",
            "Epoch 44: val_auc did not improve from 0.88012\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 181ms/step - accuracy: 0.6529 - auc: 0.7866 - loss: 0.1794 - precision: 0.6027 - recall: 0.8971 - val_accuracy: 0.5661 - val_auc: 0.7573 - val_loss: 0.2085 - val_precision: 0.5341 - val_recall: 1.0000 - learning_rate: 7.5000e-05\n",
            "Epoch 45/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.6461 - auc: 0.7851 - loss: 0.1782 - precision: 0.6082 - recall: 0.9494\n",
            "Epoch 45: val_auc did not improve from 0.88012\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 170ms/step - accuracy: 0.6271 - auc: 0.8110 - loss: 0.1762 - precision: 0.5753 - recall: 0.9714 - val_accuracy: 0.5714 - val_auc: 0.8193 - val_loss: 0.1924 - val_precision: 0.5371 - val_recall: 1.0000 - learning_rate: 7.5000e-05\n",
            "Epoch 46/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.6744 - auc: 0.7608 - loss: 0.1807 - precision: 0.6217 - recall: 0.8897\n",
            "Epoch 46: val_auc did not improve from 0.88012\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - accuracy: 0.6600 - auc: 0.7742 - loss: 0.1784 - precision: 0.6069 - recall: 0.9086 - val_accuracy: 0.5714 - val_auc: 0.8267 - val_loss: 0.1893 - val_precision: 0.5371 - val_recall: 1.0000 - learning_rate: 7.5000e-05\n",
            "Epoch 47/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.7060 - auc: 0.8346 - loss: 0.1714 - precision: 0.6420 - recall: 0.9362\n",
            "Epoch 47: val_auc did not improve from 0.88012\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 181ms/step - accuracy: 0.6743 - auc: 0.8261 - loss: 0.1720 - precision: 0.6142 - recall: 0.9371 - val_accuracy: 0.5661 - val_auc: 0.8128 - val_loss: 0.1945 - val_precision: 0.5341 - val_recall: 1.0000 - learning_rate: 7.5000e-05\n",
            "Epoch 48/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.6957 - auc: 0.8238 - loss: 0.1720 - precision: 0.6504 - recall: 0.9232\n",
            "Epoch 48: val_auc did not improve from 0.88012\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 193ms/step - accuracy: 0.6429 - auc: 0.8030 - loss: 0.1733 - precision: 0.5899 - recall: 0.9371 - val_accuracy: 0.5661 - val_auc: 0.8075 - val_loss: 0.1924 - val_precision: 0.5341 - val_recall: 1.0000 - learning_rate: 7.5000e-05\n",
            "Epoch 49/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.6856 - auc: 0.8053 - loss: 0.1719 - precision: 0.6163 - recall: 0.9614\n",
            "Epoch 49: val_auc did not improve from 0.88012\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 167ms/step - accuracy: 0.6786 - auc: 0.8133 - loss: 0.1712 - precision: 0.6151 - recall: 0.9543 - val_accuracy: 0.5661 - val_auc: 0.8097 - val_loss: 0.1896 - val_precision: 0.5341 - val_recall: 1.0000 - learning_rate: 7.5000e-05\n",
            "Epoch 50/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.6625 - auc: 0.8061 - loss: 0.1714 - precision: 0.6062 - recall: 0.9329\n",
            "Epoch 50: val_auc did not improve from 0.88012\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 184ms/step - accuracy: 0.6829 - auc: 0.8270 - loss: 0.1688 - precision: 0.6203 - recall: 0.9429 - val_accuracy: 0.5661 - val_auc: 0.8223 - val_loss: 0.1896 - val_precision: 0.5341 - val_recall: 1.0000 - learning_rate: 7.5000e-05\n",
            "Restoring model weights from the end of the best epoch: 35.\n",
            "\n",
            "======================================================================\n",
            "THRESHOLD OPTIMIZATION & EVALUATION\n",
            "======================================================================\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7997dafa04c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "\n",
            "Optimal threshold: 0.6400 (default=0.5)\n",
            "  At this threshold: TPR=0.8511, FPR=0.1263\n",
            "\n",
            "Results:\n",
            "  AUC-ROC: 0.8837\n",
            "  Accuracy (default threshold=0.5): 0.5661 (56.61%)\n",
            "  Accuracy (optimal threshold=0.6400): 0.8624 (86.24%)\n",
            "\n",
            "With optimal threshold:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Non-Planet     0.8557    0.8737    0.8646        95\n",
            "      Planet     0.8696    0.8511    0.8602        94\n",
            "\n",
            "    accuracy                         0.8624       189\n",
            "   macro avg     0.8626    0.8624    0.8624       189\n",
            "weighted avg     0.8626    0.8624    0.8624       189\n",
            "\n",
            "\n",
            "Prediction distribution (optimal threshold):\n",
            "  Predicted 0: 97\n",
            "  Predicted 1: 92\n",
            "True distribution:\n",
            "  True 0: 95\n",
            "  True 1: 94\n",
            "\n",
            "Confusion matrix (optimal threshold):\n",
            "[[83 12]\n",
            " [14 80]]\n",
            "Precision (optimal threshold): 0.8696\n",
            "\n",
            "======================================================================\n",
            "VISUALIZATIONS\n",
            "======================================================================\n",
            "Saved: confusion_matrix_final.png\n",
            "Saved: training_history_final.png\n",
            "\n",
            "======================================================================\n",
            "PLOTTING LIGHTCURVES WITH PREDICTIONS (n=6)\n",
            "======================================================================\n",
            "Saved: sample_lightcurves_predictions.png\n",
            "\n",
            "======================================================================\n",
            "TRAINING CONFIGURATION: CNN_config3\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "TRAINING\n",
            "======================================================================\n",
            "Epoch 1/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.5077 - auc: 0.5284 - loss: 0.4576 - precision: 0.5057 - recall: 0.7643\n",
            "Epoch 1: val_auc improved from None to 0.55941, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 0.5157 - auc: 0.5207 - loss: 0.4434 - precision: 0.5090 - recall: 0.8857 - val_accuracy: 0.5238 - val_auc: 0.5594 - val_loss: 0.4129 - val_precision: 0.5109 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.4880 - auc: 0.5271 - loss: 0.4007 - precision: 0.4771 - recall: 0.9494\n",
            "Epoch 2: val_auc did not improve from 0.55941\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - accuracy: 0.5043 - auc: 0.5173 - loss: 0.3901 - precision: 0.5023 - recall: 0.9314 - val_accuracy: 0.5132 - val_auc: 0.5456 - val_loss: 0.3687 - val_precision: 0.5054 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.5473 - auc: 0.5865 - loss: 0.3553 - precision: 0.5330 - recall: 0.9884\n",
            "Epoch 3: val_auc improved from 0.55941 to 0.57368, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - accuracy: 0.5243 - auc: 0.5909 - loss: 0.3469 - precision: 0.5126 - recall: 0.9857 - val_accuracy: 0.5026 - val_auc: 0.5737 - val_loss: 0.3302 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.5298 - auc: 0.5793 - loss: 0.3192 - precision: 0.5209 - recall: 0.9765\n",
            "Epoch 4: val_auc did not improve from 0.57368\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 116ms/step - accuracy: 0.5200 - auc: 0.5814 - loss: 0.3109 - precision: 0.5104 - recall: 0.9800 - val_accuracy: 0.4974 - val_auc: 0.5559 - val_loss: 0.2983 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.5284 - auc: 0.5945 - loss: 0.2859 - precision: 0.5228 - recall: 0.9847\n",
            "Epoch 5: val_auc did not improve from 0.57368\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - accuracy: 0.5114 - auc: 0.5753 - loss: 0.2800 - precision: 0.5059 - recall: 0.9800 - val_accuracy: 0.5079 - val_auc: 0.5522 - val_loss: 0.2705 - val_precision: 0.5027 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.5131 - auc: 0.6481 - loss: 0.2576 - precision: 0.5032 - recall: 0.9887\n",
            "Epoch 6: val_auc did not improve from 0.57368\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - accuracy: 0.5229 - auc: 0.6030 - loss: 0.2523 - precision: 0.5119 - recall: 0.9829 - val_accuracy: 0.5238 - val_auc: 0.5522 - val_loss: 0.2457 - val_precision: 0.5109 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.5480 - auc: 0.6198 - loss: 0.2334 - precision: 0.5323 - recall: 0.9756\n",
            "Epoch 7: val_auc did not improve from 0.57368\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - accuracy: 0.5314 - auc: 0.5949 - loss: 0.2289 - precision: 0.5166 - recall: 0.9800 - val_accuracy: 0.5238 - val_auc: 0.5639 - val_loss: 0.2234 - val_precision: 0.5109 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.5411 - auc: 0.6096 - loss: 0.2126 - precision: 0.5317 - recall: 0.9889\n",
            "Epoch 8: val_auc did not improve from 0.57368\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 0.5214 - auc: 0.6212 - loss: 0.2082 - precision: 0.5111 - recall: 0.9829 - val_accuracy: 0.5291 - val_auc: 0.5666 - val_loss: 0.2035 - val_precision: 0.5137 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.5114 - auc: 0.5726 - loss: 0.1951 - precision: 0.4930 - recall: 0.9883\n",
            "Epoch 9: val_auc did not improve from 0.57368\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - accuracy: 0.5371 - auc: 0.6051 - loss: 0.1901 - precision: 0.5195 - recall: 0.9914 - val_accuracy: 0.5238 - val_auc: 0.5666 - val_loss: 0.1868 - val_precision: 0.5109 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.5441 - auc: 0.6056 - loss: 0.1779 - precision: 0.5326 - recall: 0.9973\n",
            "Epoch 10: val_auc did not improve from 0.57368\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - accuracy: 0.5257 - auc: 0.6001 - loss: 0.1748 - precision: 0.5133 - recall: 0.9914 - val_accuracy: 0.5397 - val_auc: 0.5618 - val_loss: 0.1720 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5334 - auc: 0.6343 - loss: 0.1638 - precision: 0.5310 - recall: 0.9748\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 11: val_auc did not improve from 0.57368\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - accuracy: 0.5171 - auc: 0.6411 - loss: 0.1601 - precision: 0.5088 - recall: 0.9857 - val_accuracy: 0.5238 - val_auc: 0.5697 - val_loss: 0.1588 - val_precision: 0.5109 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.5148 - auc: 0.5857 - loss: 0.1525 - precision: 0.5034 - recall: 0.9954\n",
            "Epoch 12: val_auc improved from 0.57368 to 0.62654, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - accuracy: 0.5229 - auc: 0.5845 - loss: 0.1512 - precision: 0.5118 - recall: 0.9943 - val_accuracy: 0.5132 - val_auc: 0.6265 - val_loss: 0.1529 - val_precision: 0.5054 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.5070 - auc: 0.6507 - loss: 0.1454 - precision: 0.5004 - recall: 0.9985\n",
            "Epoch 13: val_auc did not improve from 0.62654\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - accuracy: 0.5100 - auc: 0.6449 - loss: 0.1446 - precision: 0.5051 - recall: 0.9971 - val_accuracy: 0.5079 - val_auc: 0.6028 - val_loss: 0.1473 - val_precision: 0.5027 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5252 - auc: 0.6730 - loss: 0.1395 - precision: 0.5140 - recall: 0.9950\n",
            "Epoch 14: val_auc improved from 0.62654 to 0.79149, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 0.5271 - auc: 0.6461 - loss: 0.1386 - precision: 0.5140 - recall: 0.9943 - val_accuracy: 0.5238 - val_auc: 0.7915 - val_loss: 0.1417 - val_precision: 0.5109 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.5669 - auc: 0.6771 - loss: 0.1337 - precision: 0.5557 - recall: 0.9889\n",
            "Epoch 15: val_auc did not improve from 0.79149\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 0.5243 - auc: 0.6529 - loss: 0.1334 - precision: 0.5126 - recall: 0.9857 - val_accuracy: 0.5238 - val_auc: 0.5669 - val_loss: 0.1365 - val_precision: 0.5109 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.5444 - auc: 0.6849 - loss: 0.1285 - precision: 0.5322 - recall: 0.9958\n",
            "Epoch 16: val_auc did not improve from 0.79149\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - accuracy: 0.5243 - auc: 0.6703 - loss: 0.1278 - precision: 0.5125 - recall: 0.9943 - val_accuracy: 0.5185 - val_auc: 0.5764 - val_loss: 0.1316 - val_precision: 0.5081 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.5302 - auc: 0.6732 - loss: 0.1241 - precision: 0.5117 - recall: 0.9979\n",
            "Epoch 17: val_auc did not improve from 0.79149\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - accuracy: 0.5229 - auc: 0.6740 - loss: 0.1236 - precision: 0.5118 - recall: 0.9914 - val_accuracy: 0.5291 - val_auc: 0.5760 - val_loss: 0.1269 - val_precision: 0.5137 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.5047 - auc: 0.6618 - loss: 0.1216 - precision: 0.5004 - recall: 0.9863\n",
            "Epoch 18: val_auc did not improve from 0.79149\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 0.5157 - auc: 0.6430 - loss: 0.1196 - precision: 0.5080 - recall: 0.9943 - val_accuracy: 0.5026 - val_auc: 0.5798 - val_loss: 0.1225 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.5104 - auc: 0.6612 - loss: 0.1160 - precision: 0.5028 - recall: 0.9954\n",
            "Epoch 19: val_auc did not improve from 0.79149\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - accuracy: 0.5186 - auc: 0.6402 - loss: 0.1151 - precision: 0.5095 - recall: 0.9943 - val_accuracy: 0.5397 - val_auc: 0.6134 - val_loss: 0.1180 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.5008 - auc: 0.6760 - loss: 0.1118 - precision: 0.4965 - recall: 0.9770\n",
            "Epoch 20: val_auc did not improve from 0.79149\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - accuracy: 0.5186 - auc: 0.6897 - loss: 0.1101 - precision: 0.5096 - recall: 0.9886 - val_accuracy: 0.5397 - val_auc: 0.5846 - val_loss: 0.1143 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.5206 - auc: 0.5914 - loss: 0.1090 - precision: 0.5160 - recall: 0.9946 \n",
            "Epoch 21: val_auc did not improve from 0.79149\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.5129 - auc: 0.6406 - loss: 0.1076 - precision: 0.5066 - recall: 0.9943 - val_accuracy: 0.5397 - val_auc: 0.6178 - val_loss: 0.1104 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5107 - auc: 0.7224 - loss: 0.1030 - precision: 0.5053 - recall: 0.9891\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 22: val_auc did not improve from 0.79149\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - accuracy: 0.5157 - auc: 0.7150 - loss: 0.1023 - precision: 0.5080 - recall: 0.9971 - val_accuracy: 0.5397 - val_auc: 0.6786 - val_loss: 0.1064 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5513 - auc: 0.6668 - loss: 0.1009 - precision: 0.5347 - recall: 1.0000\n",
            "Epoch 23: val_auc did not improve from 0.79149\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - accuracy: 0.5371 - auc: 0.6907 - loss: 0.0997 - precision: 0.5193 - recall: 1.0000 - val_accuracy: 0.5397 - val_auc: 0.7352 - val_loss: 0.1044 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5133 - auc: 0.6943 - loss: 0.0988 - precision: 0.5033 - recall: 0.9864\n",
            "Epoch 24: val_auc did not improve from 0.79149\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - accuracy: 0.5229 - auc: 0.6772 - loss: 0.0985 - precision: 0.5118 - recall: 0.9914 - val_accuracy: 0.5397 - val_auc: 0.6973 - val_loss: 0.1029 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5161 - auc: 0.6872 - loss: 0.0974 - precision: 0.5019 - recall: 0.9962\n",
            "Epoch 25: val_auc improved from 0.79149 to 0.82956, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 0.5300 - auc: 0.6957 - loss: 0.0968 - precision: 0.5156 - recall: 0.9943 - val_accuracy: 0.5397 - val_auc: 0.8296 - val_loss: 0.1006 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.4901 - auc: 0.6680 - loss: 0.0957 - precision: 0.4762 - recall: 1.0000\n",
            "Epoch 26: val_auc did not improve from 0.82956\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.5300 - auc: 0.6682 - loss: 0.0952 - precision: 0.5155 - recall: 1.0000 - val_accuracy: 0.5397 - val_auc: 0.7499 - val_loss: 0.0984 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5295 - auc: 0.6759 - loss: 0.0941 - precision: 0.5196 - recall: 0.9983\n",
            "Epoch 27: val_auc improved from 0.82956 to 0.84832, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 0.5243 - auc: 0.6664 - loss: 0.0945 - precision: 0.5125 - recall: 0.9971 - val_accuracy: 0.5397 - val_auc: 0.8483 - val_loss: 0.0962 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5220 - auc: 0.6790 - loss: 0.0924 - precision: 0.5095 - recall: 0.9987\n",
            "Epoch 28: val_auc did not improve from 0.84832\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - accuracy: 0.5286 - auc: 0.6583 - loss: 0.0924 - precision: 0.5147 - recall: 0.9971 - val_accuracy: 0.5397 - val_auc: 0.8378 - val_loss: 0.0941 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.5290 - auc: 0.6466 - loss: 0.0920 - precision: 0.5157 - recall: 0.9969\n",
            "Epoch 29: val_auc did not improve from 0.84832\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - accuracy: 0.5300 - auc: 0.6680 - loss: 0.0907 - precision: 0.5155 - recall: 0.9971 - val_accuracy: 0.5397 - val_auc: 0.7964 - val_loss: 0.0922 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.5183 - auc: 0.7117 - loss: 0.0884 - precision: 0.5048 - recall: 0.9905\n",
            "Epoch 30: val_auc did not improve from 0.84832\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - accuracy: 0.5257 - auc: 0.6797 - loss: 0.0889 - precision: 0.5133 - recall: 0.9914 - val_accuracy: 0.5397 - val_auc: 0.8302 - val_loss: 0.0909 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.4992 - auc: 0.6901 - loss: 0.0878 - precision: 0.4900 - recall: 0.9975\n",
            "Epoch 31: val_auc did not improve from 0.84832\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - accuracy: 0.5214 - auc: 0.6617 - loss: 0.0877 - precision: 0.5110 - recall: 0.9971 - val_accuracy: 0.5397 - val_auc: 0.8160 - val_loss: 0.0890 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.5327 - auc: 0.6615 - loss: 0.0864 - precision: 0.5153 - recall: 0.9978\n",
            "Epoch 32: val_auc did not improve from 0.84832\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - accuracy: 0.5343 - auc: 0.6670 - loss: 0.0859 - precision: 0.5178 - recall: 0.9971 - val_accuracy: 0.5397 - val_auc: 0.8194 - val_loss: 0.0880 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5417 - auc: 0.7151 - loss: 0.0841 - precision: 0.5306 - recall: 0.9917\n",
            "Epoch 33: val_auc did not improve from 0.84832\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - accuracy: 0.5214 - auc: 0.6998 - loss: 0.0842 - precision: 0.5110 - recall: 0.9914 - val_accuracy: 0.5397 - val_auc: 0.8391 - val_loss: 0.0858 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5382 - auc: 0.7309 - loss: 0.0825 - precision: 0.5217 - recall: 1.0000\n",
            "Epoch 34: val_auc did not improve from 0.84832\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - accuracy: 0.5271 - auc: 0.7212 - loss: 0.0825 - precision: 0.5140 - recall: 1.0000 - val_accuracy: 0.5397 - val_auc: 0.8197 - val_loss: 0.0841 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5033 - auc: 0.6397 - loss: 0.0832 - precision: 0.4944 - recall: 0.9920\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 35: val_auc did not improve from 0.84832\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 0.5243 - auc: 0.6690 - loss: 0.0822 - precision: 0.5125 - recall: 0.9971 - val_accuracy: 0.5397 - val_auc: 0.8387 - val_loss: 0.0830 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5234 - auc: 0.6875 - loss: 0.0804 - precision: 0.5112 - recall: 0.9993\n",
            "Epoch 36: val_auc did not improve from 0.84832\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - accuracy: 0.5229 - auc: 0.6854 - loss: 0.0805 - precision: 0.5117 - recall: 0.9971 - val_accuracy: 0.5397 - val_auc: 0.8267 - val_loss: 0.0825 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 37/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.5437 - auc: 0.7044 - loss: 0.0794 - precision: 0.5307 - recall: 1.0000\n",
            "Epoch 37: val_auc did not improve from 0.84832\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.5257 - auc: 0.6802 - loss: 0.0799 - precision: 0.5132 - recall: 1.0000 - val_accuracy: 0.5397 - val_auc: 0.8190 - val_loss: 0.0818 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 38/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5385 - auc: 0.6698 - loss: 0.0803 - precision: 0.5272 - recall: 0.9885\n",
            "Epoch 38: val_auc did not improve from 0.84832\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.5257 - auc: 0.6957 - loss: 0.0795 - precision: 0.5133 - recall: 0.9943 - val_accuracy: 0.5397 - val_auc: 0.8352 - val_loss: 0.0814 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 39/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5175 - auc: 0.6819 - loss: 0.0787 - precision: 0.5028 - recall: 1.0000\n",
            "Epoch 39: val_auc did not improve from 0.84832\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - accuracy: 0.5271 - auc: 0.7107 - loss: 0.0781 - precision: 0.5140 - recall: 1.0000 - val_accuracy: 0.5397 - val_auc: 0.8258 - val_loss: 0.0804 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 40/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.5253 - auc: 0.7264 - loss: 0.0775 - precision: 0.5105 - recall: 0.9924\n",
            "Epoch 40: val_auc did not improve from 0.84832\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - accuracy: 0.5271 - auc: 0.6972 - loss: 0.0778 - precision: 0.5141 - recall: 0.9914 - val_accuracy: 0.5397 - val_auc: 0.8286 - val_loss: 0.0793 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 41/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.5155 - auc: 0.6858 - loss: 0.0775 - precision: 0.4976 - recall: 0.9912\n",
            "Epoch 41: val_auc did not improve from 0.84832\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - accuracy: 0.5300 - auc: 0.6883 - loss: 0.0772 - precision: 0.5156 - recall: 0.9943 - val_accuracy: 0.5397 - val_auc: 0.8305 - val_loss: 0.0790 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 42/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5210 - auc: 0.7272 - loss: 0.0764 - precision: 0.5082 - recall: 0.9978\n",
            "Epoch 42: val_auc did not improve from 0.84832\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 97ms/step - accuracy: 0.5329 - auc: 0.7001 - loss: 0.0767 - precision: 0.5170 - recall: 0.9971 - val_accuracy: 0.5397 - val_auc: 0.8371 - val_loss: 0.0785 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 43/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5289 - auc: 0.6680 - loss: 0.0773 - precision: 0.5184 - recall: 0.9866\n",
            "Epoch 43: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\n",
            "Epoch 43: val_auc did not improve from 0.84832\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.5286 - auc: 0.7010 - loss: 0.0760 - precision: 0.5149 - recall: 0.9886 - val_accuracy: 0.5397 - val_auc: 0.8371 - val_loss: 0.0772 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 44/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5183 - auc: 0.6892 - loss: 0.0751 - precision: 0.5030 - recall: 0.9995\n",
            "Epoch 44: val_auc did not improve from 0.84832\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.5214 - auc: 0.6886 - loss: 0.0754 - precision: 0.5110 - recall: 0.9943 - val_accuracy: 0.5397 - val_auc: 0.8300 - val_loss: 0.0770 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 45/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5506 - auc: 0.7232 - loss: 0.0749 - precision: 0.5302 - recall: 0.9982\n",
            "Epoch 45: val_auc did not improve from 0.84832\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.5329 - auc: 0.7135 - loss: 0.0750 - precision: 0.5171 - recall: 0.9943 - val_accuracy: 0.5397 - val_auc: 0.8169 - val_loss: 0.0768 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 46/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5173 - auc: 0.6732 - loss: 0.0752 - precision: 0.5055 - recall: 1.0000\n",
            "Epoch 46: val_auc did not improve from 0.84832\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - accuracy: 0.5300 - auc: 0.6670 - loss: 0.0749 - precision: 0.5155 - recall: 1.0000 - val_accuracy: 0.5397 - val_auc: 0.8330 - val_loss: 0.0769 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 47/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5739 - auc: 0.6999 - loss: 0.0740 - precision: 0.5582 - recall: 0.9922\n",
            "Epoch 47: val_auc did not improve from 0.84832\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.5243 - auc: 0.6941 - loss: 0.0749 - precision: 0.5126 - recall: 0.9886 - val_accuracy: 0.5397 - val_auc: 0.8139 - val_loss: 0.0768 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 47: early stopping\n",
            "Restoring model weights from the end of the best epoch: 27.\n",
            "\n",
            "======================================================================\n",
            "THRESHOLD OPTIMIZATION & EVALUATION\n",
            "======================================================================\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7997088fb880> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "\n",
            "Optimal threshold: 0.5390 (default=0.5)\n",
            "  At this threshold: TPR=0.7660, FPR=0.1368\n",
            "\n",
            "Results:\n",
            "  AUC-ROC: 0.8732\n",
            "  Accuracy (default threshold=0.5): 0.5397 (53.97%)\n",
            "  Accuracy (optimal threshold=0.5390): 0.8148 (81.48%)\n",
            "\n",
            "With optimal threshold:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Non-Planet     0.7885    0.8632    0.8241        95\n",
            "      Planet     0.8471    0.7660    0.8045        94\n",
            "\n",
            "    accuracy                         0.8148       189\n",
            "   macro avg     0.8178    0.8146    0.8143       189\n",
            "weighted avg     0.8176    0.8148    0.8143       189\n",
            "\n",
            "\n",
            "Prediction distribution (optimal threshold):\n",
            "  Predicted 0: 104\n",
            "  Predicted 1: 85\n",
            "True distribution:\n",
            "  True 0: 95\n",
            "  True 1: 94\n",
            "\n",
            "Confusion matrix (optimal threshold):\n",
            "[[82 13]\n",
            " [22 72]]\n",
            "Precision (optimal threshold): 0.8471\n",
            "\n",
            "======================================================================\n",
            "VISUALIZATIONS\n",
            "======================================================================\n",
            "Saved: confusion_matrix_final.png\n",
            "Saved: training_history_final.png\n",
            "\n",
            "======================================================================\n",
            "PLOTTING LIGHTCURVES WITH PREDICTIONS (n=6)\n",
            "======================================================================\n",
            "Saved: sample_lightcurves_predictions.png\n"
          ]
        }
      ],
      "source": [
        "#task F\n",
        "from sklearn.metrics import confusion_matrix, precision_score\n",
        "\n",
        "EPOCHS = 50   # you can increase if you have time/GPU\n",
        "\n",
        "configs = [\n",
        "    (\"CNN_default\",    build_simple_cnn),\n",
        "    (\"CNN_config1\",    build_cnn_config1),\n",
        "    (\"CNN_config2\",    build_cnn_config2),\n",
        "    (\"CNN_config3\",    build_cnn_config3),\n",
        "]\n",
        "\n",
        "all_results = []\n",
        "\n",
        "for name, builder in configs:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"TRAINING CONFIGURATION: {name}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # 1) build model\n",
        "    model = builder(n_bins=N_BINS)\n",
        "\n",
        "    # 2) train\n",
        "    history = train_model(model, X_train, y_train, X_test, y_test, epochs=EPOCHS)\n",
        "\n",
        "    # 3) evaluate with optimal threshold (returns y_pred for that threshold)\n",
        "    y_pred_opt, y_proba_test, best_thresh = evaluate_with_optimal_threshold(\n",
        "        model, X_test, y_test\n",
        "    )\n",
        "\n",
        "    # 4) confusion matrix + precision at this optimal threshold\n",
        "    cm = confusion_matrix(y_test, y_pred_opt)\n",
        "    precision = precision_score(y_test, y_pred_opt, zero_division=0)\n",
        "\n",
        "    print(\"\\nConfusion matrix (optimal threshold):\")\n",
        "    print(cm)\n",
        "    print(f\"Precision (optimal threshold): {precision:.4f}\")\n",
        "\n",
        "    # Save for the text report\n",
        "    all_results.append((name, best_thresh, cm, precision))\n",
        "\n",
        "    # (Optional) save plots for this config\n",
        "    plot_all(\n",
        "        y_test, y_pred_opt, y_proba_test, history,\n",
        "        metadata_test, X_test, best_thresh,\n",
        "        X_test_orig=X_test_orig, X_err_test=X_err_test, scaler=scaler\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "9d20cabc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "TRAINING\n",
            "======================================================================\n",
            "Epoch 1/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5133 - auc: 0.6490 - loss: 0.0935 - precision: 0.5031 - recall: 0.9939\n",
            "Epoch 1: val_auc improved from None to 0.80218, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - accuracy: 0.5214 - auc: 0.6670 - loss: 0.0929 - precision: 0.5110 - recall: 0.9914 - val_accuracy: 0.5397 - val_auc: 0.8022 - val_loss: 0.0956 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 2/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.4914 - auc: 0.6342 - loss: 0.0932 - precision: 0.4807 - recall: 1.0000\n",
            "Epoch 2: val_auc improved from 0.80218 to 0.82777, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - accuracy: 0.5229 - auc: 0.6656 - loss: 0.0923 - precision: 0.5117 - recall: 1.0000 - val_accuracy: 0.5397 - val_auc: 0.8278 - val_loss: 0.0951 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 3/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5264 - auc: 0.6523 - loss: 0.0922 - precision: 0.5157 - recall: 0.9938\n",
            "Epoch 3: val_auc improved from 0.82777 to 0.84160, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 0.5271 - auc: 0.6567 - loss: 0.0918 - precision: 0.5140 - recall: 0.9971 - val_accuracy: 0.5397 - val_auc: 0.8416 - val_loss: 0.0941 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 4/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5281 - auc: 0.7046 - loss: 0.0905 - precision: 0.5194 - recall: 0.9880\n",
            "Epoch 4: val_auc did not improve from 0.84160\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.5214 - auc: 0.6899 - loss: 0.0906 - precision: 0.5110 - recall: 0.9943 - val_accuracy: 0.5397 - val_auc: 0.8276 - val_loss: 0.0932 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 5/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5290 - auc: 0.6797 - loss: 0.0901 - precision: 0.5153 - recall: 0.9983\n",
            "Epoch 5: val_auc did not improve from 0.84160\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - accuracy: 0.5300 - auc: 0.6836 - loss: 0.0900 - precision: 0.5155 - recall: 0.9971 - val_accuracy: 0.5397 - val_auc: 0.8250 - val_loss: 0.0926 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 6/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5563 - auc: 0.6751 - loss: 0.0898 - precision: 0.5423 - recall: 0.9994\n",
            "Epoch 6: val_auc did not improve from 0.84160\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - accuracy: 0.5271 - auc: 0.6863 - loss: 0.0896 - precision: 0.5140 - recall: 0.9971 - val_accuracy: 0.5397 - val_auc: 0.8190 - val_loss: 0.0920 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 7/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5109 - auc: 0.6227 - loss: 0.0903 - precision: 0.4943 - recall: 0.9987\n",
            "Epoch 7: val_auc did not improve from 0.84160\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - accuracy: 0.5300 - auc: 0.6561 - loss: 0.0895 - precision: 0.5155 - recall: 0.9971 - val_accuracy: 0.5397 - val_auc: 0.8240 - val_loss: 0.0913 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 8/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5466 - auc: 0.6667 - loss: 0.0887 - precision: 0.5353 - recall: 0.9940\n",
            "Epoch 8: val_auc improved from 0.84160 to 0.84401, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 0.5286 - auc: 0.6640 - loss: 0.0888 - precision: 0.5148 - recall: 0.9943 - val_accuracy: 0.5397 - val_auc: 0.8440 - val_loss: 0.0906 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 9/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.4770 - auc: 0.6715 - loss: 0.0891 - precision: 0.4676 - recall: 0.9900\n",
            "Epoch 9: val_auc did not improve from 0.84401\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.5171 - auc: 0.6755 - loss: 0.0885 - precision: 0.5088 - recall: 0.9914 - val_accuracy: 0.5397 - val_auc: 0.8303 - val_loss: 0.0902 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 10/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5373 - auc: 0.7088 - loss: 0.0874 - precision: 0.5257 - recall: 0.9910\n",
            "Epoch 10: val_auc improved from 0.84401 to 0.84602, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 0.5257 - auc: 0.6833 - loss: 0.0878 - precision: 0.5133 - recall: 0.9914 - val_accuracy: 0.5397 - val_auc: 0.8460 - val_loss: 0.0896 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 11/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5178 - auc: 0.6964 - loss: 0.0874 - precision: 0.5047 - recall: 0.9913\n",
            "Epoch 11: val_auc did not improve from 0.84602\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - accuracy: 0.5271 - auc: 0.6925 - loss: 0.0876 - precision: 0.5140 - recall: 0.9943 - val_accuracy: 0.5397 - val_auc: 0.8257 - val_loss: 0.0892 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 12/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5228 - auc: 0.6686 - loss: 0.0869 - precision: 0.5049 - recall: 0.9992\n",
            "Epoch 12: val_auc did not improve from 0.84602\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.5271 - auc: 0.6589 - loss: 0.0869 - precision: 0.5140 - recall: 0.9943 - val_accuracy: 0.5397 - val_auc: 0.8301 - val_loss: 0.0887 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 13/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.5344 - auc: 0.7268 - loss: 0.0853 - precision: 0.5206 - recall: 0.9984\n",
            "Epoch 13: val_auc did not improve from 0.84602\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.5271 - auc: 0.6906 - loss: 0.0861 - precision: 0.5140 - recall: 0.9943 - val_accuracy: 0.5397 - val_auc: 0.8306 - val_loss: 0.0882 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 14/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.5449 - auc: 0.6911 - loss: 0.0855 - precision: 0.5305 - recall: 1.0000\n",
            "Epoch 14: val_auc did not improve from 0.84602\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - accuracy: 0.5229 - auc: 0.6928 - loss: 0.0857 - precision: 0.5117 - recall: 1.0000 - val_accuracy: 0.5397 - val_auc: 0.8410 - val_loss: 0.0876 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 15/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.5205 - auc: 0.6688 - loss: 0.0858 - precision: 0.5072 - recall: 0.9986\n",
            "Epoch 15: val_auc did not improve from 0.84602\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 0.5229 - auc: 0.6809 - loss: 0.0857 - precision: 0.5117 - recall: 0.9971 - val_accuracy: 0.5397 - val_auc: 0.8292 - val_loss: 0.0872 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 16/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.5273 - auc: 0.6369 - loss: 0.0857 - precision: 0.5209 - recall: 0.9965\n",
            "Epoch 16: val_auc did not improve from 0.84602\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - accuracy: 0.5200 - auc: 0.6618 - loss: 0.0853 - precision: 0.5102 - recall: 0.9971 - val_accuracy: 0.5397 - val_auc: 0.8318 - val_loss: 0.0867 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 17/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.5522 - auc: 0.6956 - loss: 0.0843 - precision: 0.5358 - recall: 0.9949\n",
            "Epoch 17: val_auc did not improve from 0.84602\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 0.5271 - auc: 0.7024 - loss: 0.0843 - precision: 0.5140 - recall: 0.9943 - val_accuracy: 0.5397 - val_auc: 0.8013 - val_loss: 0.0859 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 18/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.5275 - auc: 0.6675 - loss: 0.0838 - precision: 0.5190 - recall: 0.9993\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\n",
            "Epoch 18: val_auc did not improve from 0.84602\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 0.5186 - auc: 0.6421 - loss: 0.0845 - precision: 0.5095 - recall: 0.9971 - val_accuracy: 0.5397 - val_auc: 0.8230 - val_loss: 0.0855 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 19/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.5348 - auc: 0.6977 - loss: 0.0826 - precision: 0.5181 - recall: 0.9964\n",
            "Epoch 19: val_auc did not improve from 0.84602\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - accuracy: 0.5286 - auc: 0.6709 - loss: 0.0833 - precision: 0.5147 - recall: 0.9971 - val_accuracy: 0.5397 - val_auc: 0.8236 - val_loss: 0.0854 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 20/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5180 - auc: 0.7068 - loss: 0.0828 - precision: 0.5081 - recall: 0.9964\n",
            "Epoch 20: val_auc did not improve from 0.84602\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - accuracy: 0.5229 - auc: 0.6890 - loss: 0.0830 - precision: 0.5117 - recall: 0.9971 - val_accuracy: 0.5397 - val_auc: 0.8339 - val_loss: 0.0852 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 21/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5217 - auc: 0.6954 - loss: 0.0827 - precision: 0.5106 - recall: 0.9981\n",
            "Epoch 21: val_auc did not improve from 0.84602\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - accuracy: 0.5257 - auc: 0.6948 - loss: 0.0825 - precision: 0.5132 - recall: 0.9971 - val_accuracy: 0.5397 - val_auc: 0.8214 - val_loss: 0.0849 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 22/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.5312 - auc: 0.6475 - loss: 0.0835 - precision: 0.5151 - recall: 0.9979\n",
            "Epoch 22: val_auc did not improve from 0.84602\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - accuracy: 0.5243 - auc: 0.6804 - loss: 0.0828 - precision: 0.5125 - recall: 0.9943 - val_accuracy: 0.5397 - val_auc: 0.8340 - val_loss: 0.0846 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 23/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.5530 - auc: 0.6965 - loss: 0.0823 - precision: 0.5338 - recall: 0.9999\n",
            "Epoch 23: val_auc did not improve from 0.84602\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.5357 - auc: 0.6817 - loss: 0.0826 - precision: 0.5186 - recall: 0.9971 - val_accuracy: 0.5397 - val_auc: 0.8320 - val_loss: 0.0844 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 24/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.5424 - auc: 0.6636 - loss: 0.0828 - precision: 0.5320 - recall: 1.0000\n",
            "Epoch 24: val_auc did not improve from 0.84602\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - accuracy: 0.5300 - auc: 0.6677 - loss: 0.0827 - precision: 0.5155 - recall: 1.0000 - val_accuracy: 0.5397 - val_auc: 0.8368 - val_loss: 0.0842 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 25/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.5210 - auc: 0.6569 - loss: 0.0830 - precision: 0.5106 - recall: 0.9960\n",
            "Epoch 25: val_auc did not improve from 0.84602\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - accuracy: 0.5286 - auc: 0.6751 - loss: 0.0822 - precision: 0.5147 - recall: 0.9971 - val_accuracy: 0.5397 - val_auc: 0.8361 - val_loss: 0.0839 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 26/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.5402 - auc: 0.7201 - loss: 0.0816 - precision: 0.5276 - recall: 0.9923\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "\n",
            "Epoch 26: val_auc did not improve from 0.84602\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 0.5271 - auc: 0.7018 - loss: 0.0817 - precision: 0.5140 - recall: 0.9943 - val_accuracy: 0.5397 - val_auc: 0.8427 - val_loss: 0.0836 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 27/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.4994 - auc: 0.7470 - loss: 0.0808 - precision: 0.4907 - recall: 0.9835\n",
            "Epoch 27: val_auc did not improve from 0.84602\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - accuracy: 0.5257 - auc: 0.7022 - loss: 0.0812 - precision: 0.5133 - recall: 0.9943 - val_accuracy: 0.5397 - val_auc: 0.8373 - val_loss: 0.0835 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 7.8125e-06\n",
            "Epoch 28/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.5151 - auc: 0.6574 - loss: 0.0824 - precision: 0.5044 - recall: 0.9898\n",
            "Epoch 28: val_auc did not improve from 0.84602\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - accuracy: 0.5200 - auc: 0.6735 - loss: 0.0819 - precision: 0.5103 - recall: 0.9914 - val_accuracy: 0.5397 - val_auc: 0.8457 - val_loss: 0.0835 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 7.8125e-06\n",
            "Epoch 29/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.5333 - auc: 0.6894 - loss: 0.0816 - precision: 0.5215 - recall: 0.9868\n",
            "Epoch 29: val_auc did not improve from 0.84602\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.5286 - auc: 0.6874 - loss: 0.0813 - precision: 0.5148 - recall: 0.9943 - val_accuracy: 0.5397 - val_auc: 0.8334 - val_loss: 0.0834 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 7.8125e-06\n",
            "Epoch 30/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.5440 - auc: 0.7066 - loss: 0.0806 - precision: 0.5251 - recall: 0.9966\n",
            "Epoch 30: val_auc did not improve from 0.84602\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - accuracy: 0.5286 - auc: 0.7034 - loss: 0.0810 - precision: 0.5148 - recall: 0.9943 - val_accuracy: 0.5397 - val_auc: 0.8352 - val_loss: 0.0833 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 7.8125e-06\n",
            "Epoch 30: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n"
          ]
        }
      ],
      "source": [
        "# 3) Train\n",
        "history = train_model(model, X_train, y_train, X_test, y_test, epochs=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "b0baecc6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "THRESHOLD OPTIMIZATION & EVALUATION\n",
            "======================================================================\n",
            "\n",
            "Optimal threshold: 0.5480 (default=0.5)\n",
            "  At this threshold: TPR=0.8511, FPR=0.2211\n",
            "\n",
            "Results:\n",
            "  AUC-ROC: 0.8701\n",
            "  Accuracy (default threshold=0.5): 0.5397 (53.97%)\n",
            "  Accuracy (optimal threshold=0.5480): 0.8148 (81.48%)\n",
            "\n",
            "With optimal threshold:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Non-Planet     0.8409    0.7789    0.8087        95\n",
            "      Planet     0.7921    0.8511    0.8205        94\n",
            "\n",
            "    accuracy                         0.8148       189\n",
            "   macro avg     0.8165    0.8150    0.8146       189\n",
            "weighted avg     0.8166    0.8148    0.8146       189\n",
            "\n",
            "\n",
            "Prediction distribution (optimal threshold):\n",
            "  Predicted 0: 88\n",
            "  Predicted 1: 101\n",
            "True distribution:\n",
            "  True 0: 95\n",
            "  True 1: 94\n"
          ]
        }
      ],
      "source": [
        "# 4) Evaluate with optimal threshold\n",
        "y_pred, y_pred_proba, threshold = evaluate_with_optimal_threshold(model, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "a6e0f6da",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "VISUALIZATIONS\n",
            "======================================================================\n",
            "Saved: confusion_matrix_final.png\n",
            "Saved: training_history_final.png\n",
            "\n",
            "======================================================================\n",
            "PLOTTING LIGHTCURVES WITH PREDICTIONS (n=6)\n",
            "======================================================================\n",
            "Saved: sample_lightcurves_predictions.png\n",
            "\n",
            "======================================================================\n",
            "TRAINING COMPLETE!\n",
            "======================================================================\n",
            "\n",
            "Key improvements:\n",
            "  ✓ Perfectly balanced training data\n",
            "  ✓ Focal loss for hard examples\n",
            "  ✓ Optimal threshold selection\n",
            "  ✓ AUC-focused optimization\n",
            "\n",
            "Files:\n",
            "  - tess_model_final.keras\n",
            "  - best_model_final.keras\n",
            "  - optimal_threshold.npy\n",
            "  - confusion_matrix_final.png\n",
            "  - training_history_final.png\n",
            "  - sample_lightcurves_predictions.png\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# 5) Visualize & save artifacts\n",
        "plot_all(y_test, y_pred, y_pred_proba, history, metadata_test, X_test, threshold,\n",
        "         X_test_orig=X_test_orig, X_err_test=X_err_test, scaler=scaler)\n",
        "\n",
        "# Persist model and threshold\n",
        "model.save('tess_model_final.keras')\n",
        "np.save('optimal_threshold.npy', threshold)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nKey improvements:\")\n",
        "print(\"  ✓ Perfectly balanced training data\")\n",
        "print(\"  ✓ Focal loss for hard examples\")\n",
        "print(\"  ✓ Optimal threshold selection\")\n",
        "print(\"  ✓ AUC-focused optimization\")\n",
        "print(\"\\nFiles:\")\n",
        "print(\"  - tess_model_final.keras\")\n",
        "print(\"  - best_model_final.keras\")\n",
        "print(\"  - optimal_threshold.npy\")\n",
        "print(\"  - confusion_matrix_final.png\")\n",
        "print(\"  - training_history_final.png\")\n",
        "print(\"  - sample_lightcurves_predictions.png\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "797e9d45",
      "metadata": {},
      "source": [
        "## 11. (Optional) One-Click: Run Everything\n",
        "\n",
        "This cell wraps all steps into a single function for convenience.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "42f938a4",
      "metadata": {},
      "outputs": [],
      "source": [
        "def main():\n",
        "    X_train, X_test, y_train, y_test, metadata_test, X_test_orig, X_err_test, scaler = load_data(\n",
        "        csv_path=CSV_PATH, n_bins=N_BINS\n",
        "    )\n",
        "    model = build_simple_cnn(n_bins=N_BINS)\n",
        "    history = train_model(model, X_train, y_train, X_test, y_test, epochs=200)\n",
        "    y_pred, y_pred_proba, threshold = evaluate_with_optimal_threshold(model, X_test, y_test)\n",
        "    plot_all(y_test, y_pred, y_pred_proba, history, metadata_test, X_test, threshold,\n",
        "             X_test_orig=X_test_orig, X_err_test=X_err_test, scaler=scaler)\n",
        "    model.save('tess_model_final.keras')\n",
        "    np.save('optimal_threshold.npy', threshold)\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"TRAINING COMPLETE!\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nKey improvements:\")\n",
        "    print(\"  ✓ Perfectly balanced training data\")\n",
        "    print(\"  ✓ Focal loss for hard examples\")\n",
        "    print(\"  ✓ Optimal threshold selection\")\n",
        "    print(\"  ✓ AUC-focused optimization\")\n",
        "    print(\"\\nFiles:\")\n",
        "    print(\"  - tess_model_final.keras\")\n",
        "    print(\"  - best_model_final.keras\")\n",
        "    print(\"  - optimal_threshold.npy\")\n",
        "    print(\"  - confusion_matrix_final.png\")\n",
        "    print(\"  - training_history_final.png\")\n",
        "    print(\"  - sample_lightcurves_predictions.png\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "# Uncomment to run end-to-end:\n",
        "# main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "58d6d86f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Report written to report_cnn_assignment2_taskF.txt\n"
          ]
        }
      ],
      "source": [
        "#task F\n",
        "report_path = \"report_cnn_assignment2_taskF.txt\"\n",
        "\n",
        "with open(report_path, \"w\") as f:\n",
        "    f.write(\"Assignment 2 – Task F: CNN configurations on tess_data.csv\\n\")\n",
        "    f.write(\"----------------------------------------------------------\\n\\n\")\n",
        "    for name, thresh, cm, prec in all_results:\n",
        "        f.write(f\"Model: {name}\\n\")\n",
        "        f.write(f\"Optimal threshold: {thresh:.4f}\\n\")\n",
        "        f.write(\"Confusion matrix (rows: true [0,1], cols: predicted [0,1]):\\n\")\n",
        "        f.write(str(cm) + \"\\n\")\n",
        "        f.write(f\"Precision (optimal threshold): {prec:.4f}\\n\")\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "print(f\"Report written to {report_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Interpreting Results & Next Steps\n",
        "\n",
        "- **AUC-ROC** is the primary score during training. Inspect training curves to ensure you’re not overfitting.  \n",
        "- **Confusion matrix** with counts and percentages helps quantify trade-offs at the **optimal threshold**.  \n",
        "- **False positives** vs **false negatives**: use domain needs to decide how to tune `alpha`/`gamma` in focal loss or to move the threshold.\n",
        "\n",
        "**Ideas to try next**\n",
        "\n",
        "- Add **class-dependent augmentations** (e.g., transit-like dips for positives).  \n",
        "- Calibrate probabilities (e.g., **Platt scaling**, **isotonic regression**) for better decision thresholds.  \n",
        "- Incorporate additional channels (centroid motion, background, etc.) into a **multi-input** model.  \n",
        "- Use **cross-validation** on the training set to measure variability across folds.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### Appendix: Notes on Data Schema\n",
        "\n",
        "- Ensure your CSV contains **exactly** `n_bins` columns named `flux_0000 .. flux_{n_bins-1:04d}` and matching `flux_err_*` columns.\n",
        "- Metadata columns are optional for training but used for prettier plots.\n",
        "\n",
        "### Troubleshooting\n",
        "\n",
        "- `ValueError: columns not found`: your CSV headers don’t match the expected names. Check `n_bins` and column prefixes.  \n",
        "- `CUDA out of memory`: reduce `batch_size`, or limit GPU memory; try the provided GPU memory-growth snippet.  \n",
        "- `AUC not improving`: try a bigger `samples_per_class`, more dropout, or adjust `gamma`/`alpha`.\n",
        "\n",
        "---\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Final_TESS_Transit_Classification.ipynb"
    },
    "kernelspec": {
      "display_name": "comp_astro_25",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
