{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Final TESS Transit Classification — Optimized for Extreme Class Imbalance\n",
        "\n",
        "This notebook converts and expands the provided Python script into a fully documented, didactic, and **step-by-step** workflow.\n",
        "We train a 1D CNN to classify TESS light curves into *transit* (planet candidate) vs *non-transit* under **severe class imbalance**.\n",
        "\n",
        "**Key strategies covered:**\n",
        "\n",
        "- **Balanced augmentation** (equal samples per class) to mitigate imbalance during training.  \n",
        "- **Focal loss** (tunable `gamma` and `alpha`) to emphasize hard examples and rare positives.  \n",
        "- **Threshold optimization** using **Youden’s J** from the ROC curve (don’t use the default 0.5).  \n",
        "- **Simplified CNN architecture** to reduce overfitting.  \n",
        "- **AUC-centric monitoring** with early stopping and LR scheduling.\n",
        "\n",
        "> **What you’ll learn**\n",
        ">\n",
        "> 1. Why balanced training batches help under extreme imbalance.  \n",
        "> 2. How focal loss reshapes the gradient to focus on hard/rare samples.  \n",
        "> 3. How to pick a **data-driven** decision threshold that best trades off TPR/FPR.  \n",
        "> 4. How to evaluate with AUC-ROC rather than accuracy (which can be misleading).  \n",
        "> 5. How to visualize confusion matrices and sample light curves with predictions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "370aefef",
      "metadata": {},
      "source": [
        "## 1. Prerequisites & Data\n",
        "\n",
        "**Dependencies** (install if needed):\n",
        "\n",
        "```bash\n",
        "pip install numpy pandas scikit-learn matplotlib tensorflow\n",
        "```\n",
        "\n",
        "> We intentionally avoid additional plotting libraries to keep dependencies compact.  \n",
        "> If you already have a working scientific Python/TensorFlow stack, you can skip installations.\n",
        "\n",
        "**Expected dataset**: a CSV file named **`tess_data.csv`** in the working directory with:\n",
        "\n",
        "- **Light-curve samples**: `flux_0000, flux_0001, ..., flux_0999` (or up to `n_bins-1`)  \n",
        "- **Flux uncertainties**: `flux_err_0000, ..., flux_err_0999`  \n",
        "- **Label**: `label` (0 = Non-Planet, 1 = Planet)  \n",
        "- **Metadata** (used for plots/titles): `toi_name, tic, disp, period_d, t0_bjd, dur_hr, sector`\n",
        "\n",
        "You can change the filename or number of bins via parameters in the **Data Loading** section.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Environment Setup\n",
        "\n",
        "Set up imports, suppress noisy warnings, and fix seeds for reproducibility.  \n",
        "(Exact reproducibility on GPUs may still vary across hardware/driver versions.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "9739f714",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/root/anaconda3/envs/comp_astro_25/bin/python\n",
            "Requirement already satisfied: tensorflow==2.20.0 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (2.20.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (2.3.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (0.7.0)\n",
            "Requirement already satisfied: google_pasta>=0.1.1 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (18.1.1)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (25.0)\n",
            "Requirement already satisfied: protobuf>=5.28.0 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (6.33.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (2.32.5)\n",
            "Requirement already satisfied: setuptools in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (80.9.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (3.2.0)\n",
            "Requirement already satisfied: typing_extensions>=3.6.6 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.20.0 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (2.20.0)\n",
            "Requirement already satisfied: keras>=3.10.0 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (3.12.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (2.2.5)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (3.15.1)\n",
            "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorflow==2.20.0) (0.5.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.20.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.20.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.20.0) (2.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow==2.20.0) (2025.11.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow==2.20.0) (3.10)\n",
            "Requirement already satisfied: pillow in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow==2.20.0) (11.3.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow==2.20.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow==2.20.0) (3.1.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.20.0) (0.45.1)\n",
            "Requirement already satisfied: rich in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from keras>=3.10.0->tensorflow==2.20.0) (14.2.0)\n",
            "Requirement already satisfied: namex in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from keras>=3.10.0->tensorflow==2.20.0) (0.1.0)\n",
            "Requirement already satisfied: optree in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from keras>=3.10.0->tensorflow==2.20.0) (0.18.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow==2.20.0) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from rich->keras>=3.10.0->tensorflow==2.20.0) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from rich->keras>=3.10.0->tensorflow==2.20.0) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /root/anaconda3/envs/comp_astro_25/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow==2.20.0) (0.1.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.executable)  # just to see which python the notebook uses\n",
        "\n",
        "# Install TF 2.20.0 for THIS interpreter\n",
        "!{sys.executable} -m pip install \"tensorflow==2.20.0\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "883a4745",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting working directory to:  /ca25/comp_astro_25\n",
            "None\n",
            "TF version: 2.20.0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'import torch\\n\\nif torch.cuda.is_available():\\n    device = torch.device(\"cuda\")\\n    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\\nelse:\\n    device = torch.device(\"cpu\")\\n    print(\"Using CPU (no GPU available).\")\\n\\nprint(\"PyTorch version:\", torch.__version__)\\n'"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "    import IPython\n",
        "    working_directory = \"/\".join(\n",
        "            IPython.extract_module_locals()[1][\"__vsc_ipynb_file__\"].split(\"/\")[:-1]\n",
        "        )\n",
        "    print(\"Setting working directory to: \", working_directory)\n",
        "    print(os.chdir(working_directory))\n",
        "except Exception as e:\n",
        "    print(\"It was impossible to set your directory as the current one because of the following message\")\n",
        "    print(e)\n",
        "    print(\"The working directory is: \", os.getcwd())\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score, roc_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import tensorflow as tf   #i hidden this because my current vs code in not installing tensor flow, instaed i installed pytorch \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "import tensorflow.keras.backend as K\n",
        "# i imported this code \n",
        "'''import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "# Reproducibility\n",
        "np.random.seed(42)\n",
        "#tf.random.set_seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"FINAL TESS CLASSIFICATION\")\n",
        "print(\"=\"*70)'''\n",
        "\n",
        " #Optional: make TF less eager to pre-allocate all GPU memory (if using GPU)\n",
        "try:\n",
        "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "    for gpu in gpus:\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    if gpus:\n",
        "        print(f\"Enabled memory growth for {len(gpus)} GPU(s).\")\n",
        "except Exception as e:\n",
        "    print(\"GPU setup note:\", e)\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "'''import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Using CPU (no GPU available).\")\n",
        "\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7201e4a1",
      "metadata": {},
      "source": [
        "## 3. Focal Loss (for severe imbalance)\n",
        "\n",
        "**Why focal loss?** With extreme imbalance, the model can get “lazy”—it learns to do well by focusing on the majority class.  \n",
        "Focal loss down-weights *easy* examples and concentrates gradient on *hard* ones by adding a modulating factor \\((1 - p_t)^\\gamma\\).  \n",
        "We also use class weighting via \\(\\alpha\\) to up-weight the rare positive class.\n",
        "\n",
        "- **`gamma`** (focusing parameter): higher values put more emphasis on hard examples.  \n",
        "- **`alpha`** (class weight): weight for positive class (1); negative class gets \\(1 - \\alpha\\).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "a2de8e26",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def focal_loss(gamma=2.5, alpha=0.75):\n",
        "    \"\"\"Focal loss optimized for severe imbalance (binary).\"\"\"\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        epsilon = K.epsilon()\n",
        "        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
        "        \n",
        "        pt = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n",
        "        alpha_factor = tf.where(tf.equal(y_true, 1), alpha, 1 - alpha)\n",
        "        focal_weight = alpha_factor * K.pow(1 - pt, gamma)\n",
        "        bce = -K.log(pt)\n",
        "        return K.mean(focal_weight * bce)\n",
        "    return focal_loss_fixed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85ae786d",
      "metadata": {},
      "source": [
        "## 4. Balanced Augmentation\n",
        "\n",
        "We **balance the training set** to a fixed number of samples per class.  \n",
        "If a class has too few samples, we create augmented variants (noise, scale, shift, combo).  \n",
        "This prevents the model from being swamped by the majority class during training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "24800de1",
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_balanced_dataset(X, y, samples_per_class=400):\n",
        "    \"\"\"Create a perfectly balanced dataset via lightweight augmentations.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"CREATING BALANCED DATASET\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    X_class0 = X[y == 0]\n",
        "    X_class1 = X[y == 1]\n",
        "    \n",
        "    print(f\"Original - Class 0: {len(X_class0)}, Class 1: {len(X_class1)}\")\n",
        "    \n",
        "    def augment_to_target(X_orig, n_target):\n",
        "        if len(X_orig) >= n_target:\n",
        "            idx = np.random.choice(len(X_orig), n_target, replace=False)\n",
        "            return X_orig[idx]\n",
        "        \n",
        "        X_result = [X_orig]\n",
        "        while len(np.vstack(X_result)) < n_target:\n",
        "            # number we still need (cap to avoid oversampling too big chunks)\n",
        "            n_needed = n_target - len(np.vstack(X_result))\n",
        "            idx = np.random.choice(len(X_orig), min(len(X_orig), n_needed))\n",
        "            \n",
        "            aug_type = np.random.rand()\n",
        "            if aug_type < 0.25:\n",
        "                # Additive Gaussian noise\n",
        "                X_aug = X_orig[idx] + np.random.normal(0, 0.01, (len(idx), X_orig.shape[1]))\n",
        "            elif aug_type < 0.5:\n",
        "                # Multiplicative scaling\n",
        "                scale = 1.0 + np.random.uniform(-0.03, 0.03, (len(idx), 1))\n",
        "                X_aug = X_orig[idx] * scale\n",
        "            elif aug_type < 0.75:\n",
        "                # Circular shift (time shift)\n",
        "                shifts = np.random.randint(-20, 20, len(idx))\n",
        "                X_aug = np.array([np.roll(X_orig[i], s) for i, s in zip(idx, shifts)])\n",
        "            else:\n",
        "                # Mild combo: small scale + small noise\n",
        "                X_aug = X_orig[idx] * (1.0 + np.random.uniform(-0.02, 0.02, (len(idx), 1)))\n",
        "                X_aug += np.random.normal(0, 0.008, X_aug.shape)\n",
        "            \n",
        "            X_result.append(X_aug)\n",
        "        \n",
        "        X_final = np.vstack(X_result)\n",
        "        return X_final[:n_target]\n",
        "    \n",
        "    X0_bal = augment_to_target(X_class0, samples_per_class)\n",
        "    X1_bal = augment_to_target(X_class1, samples_per_class)\n",
        "    \n",
        "    print(f\"Balanced - Class 0: {len(X0_bal)}, Class 1: {len(X1_bal)}\")\n",
        "    \n",
        "    X_balanced = np.vstack([X0_bal, X1_bal])\n",
        "    y_balanced = np.concatenate([np.zeros(samples_per_class), np.ones(samples_per_class)])\n",
        "    \n",
        "    # Shuffle\n",
        "    idx = np.arange(len(X_balanced))\n",
        "    np.random.shuffle(idx)\n",
        "    \n",
        "    return X_balanced[idx], y_balanced[idx]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34555fb8",
      "metadata": {},
      "source": [
        "## 5. Data Loading, Splitting & Standardization\n",
        "\n",
        "We split **before** augmentation (to avoid leakage), then **balance only the training split**.  \n",
        "We standardize the flux (zero mean / unit variance) using statistics from the training set only.\n",
        "\n",
        "**Notes**\n",
        "\n",
        "- Error bars `X_err` are **not** standardized (kept in their original scale).  \n",
        "- We keep the **test metadata** to produce nicer titles in the sample light-curve plots.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "45df1a84",
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data(csv_path='tess_data.csv', n_bins=1000):\n",
        "    \"\"\"Load CSV, split, balance train set, and standardize features.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"LOADING DATA\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    df = pd.read_csv(csv_path)\n",
        "    print(f\"Dataset: {df.shape[0]} samples\")\n",
        "    \n",
        "    flux_cols = [f'flux_{i:04d}' for i in range(n_bins)]\n",
        "    flux_err_cols = [f'flux_err_{i:04d}' for i in range(n_bins)]\n",
        "    X = df[flux_cols].values\n",
        "    X_err = df[flux_err_cols].values\n",
        "    y = df['label'].values\n",
        "    \n",
        "    metadata_cols = ['toi_name', 'tic', 'label', 'disp', 'period_d', 't0_bjd', 'dur_hr', 'sector']\n",
        "    metadata = df[metadata_cols]\n",
        "    \n",
        "    print(\"\\nOriginal distribution:\")\n",
        "    print(f\"  Class 0: {(y==0).sum()}, Class 1: {(y==1).sum()}\")\n",
        "    if (y==0).sum() > 0:\n",
        "        print(f\"  Ratio: {(y==1).sum() / (y==0).sum():.2f}:1\")\n",
        "    \n",
        "    # Train/test split (keep errors aligned; stratify to preserve class ratio)\n",
        "    X_train, X_test, y_train, y_test, X_err_train, X_err_test, idx_train, idx_test = train_test_split(\n",
        "        X, y, X_err, np.arange(len(y)),\n",
        "        test_size=0.2,\n",
        "        random_state=42,\n",
        "        stratify=y\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nInitial split - Train: {len(X_train)}, Test: {len(X_test)}\")\n",
        "    \n",
        "    # Balance training set\n",
        "    X_train, y_train = create_balanced_dataset(X_train, y_train, samples_per_class=350)\n",
        "    \n",
        "    # Standardize (fit on train, apply to test)\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STANDARDIZATION\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "    \n",
        "    print(f\"Train: mean={X_train.mean():.6f}, std={X_train.std():.6f}\")\n",
        "    print(f\"Test:  mean={X_test.mean():.6f}, std={X_test.std():.6f}\")\n",
        "    \n",
        "    # Reshape for Conv1D: (samples, timesteps, channels)\n",
        "    X_train = X_train.reshape(-1, n_bins, 1)\n",
        "    X_test = X_test.reshape(-1, n_bins, 1)\n",
        "    \n",
        "    metadata_test = metadata.iloc[idx_test].reset_index(drop=True)\n",
        "    \n",
        "    print(f\"\\nFinal - X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
        "    print(f\"Train dist: 0={( y_train==0).sum()}, 1={(y_train==1).sum()}\")\n",
        "    \n",
        "    # Return standardized test for model input, but also return the standardized\n",
        "    # copy (X_test_orig) so we can inverse-transform for plotting with error bars.\n",
        "    return X_train, X_test, y_train, y_test, metadata_test, X_test.copy(), X_err_test, scaler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0e4e6b5",
      "metadata": {},
      "source": [
        "## 6. A Simpler 1D CNN (to curb overfitting)\n",
        "\n",
        "A compact ConvNet with **BatchNorm**, **Dropout**, and **Global Average Pooling** is often enough for\n",
        "noisy, small-ish 1D signals. We also add mild L2 on the dense layers. The goal is a strong baseline\n",
        "that generalizes well, not a gigantic model that memorizes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "c42e5a33",
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_simple_cnn(n_bins=1000):\n",
        "    \"\"\"Simpler CNN to prevent overfitting on small datasets.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"BUILDING SIMPLIFIED CNN\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(n_bins, 1)),\n",
        "        \n",
        "        # Feature extraction\n",
        "        layers.Conv1D(64, kernel_size=3, padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling1D(2),\n",
        "        layers.Dropout(0.3),\n",
        "        \n",
        "        layers.Conv1D(128, kernel_size=3, padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling1D(2),\n",
        "        layers.Dropout(0.3),\n",
        "        \n",
        "        layers.Conv1D(256, kernel_size=3, padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.GlobalAveragePooling1D(),\n",
        "        layers.Dropout(0.4),\n",
        "        \n",
        "        # Classification head\n",
        "        layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.Dropout(0.2),\n",
        "        \n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n",
        "        loss=focal_loss(gamma=2.5, alpha=0.75),\n",
        "        metrics=['accuracy',\n",
        "                 keras.metrics.Precision(name='precision'),\n",
        "                 keras.metrics.Recall(name='recall'),\n",
        "                 keras.metrics.AUC(name='auc')]\n",
        "    )\n",
        "    \n",
        "    model.summary()\n",
        "    print(\"\\nUsing Focal Loss (gamma=2.5, alpha=0.75)\")\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "3b197223",
      "metadata": {},
      "outputs": [],
      "source": [
        "# assignmnet2 Task F\n",
        "# --- Extra CNN configurations for Assignment 2 Task F ---\n",
        "\n",
        "def build_cnn_config1(n_bins=1000):\n",
        "    \"\"\"\n",
        "    Config 1: Slightly smaller network, more dropout.\n",
        "    \"\"\"\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(n_bins, 1)),\n",
        "\n",
        "        layers.Conv1D(32, 5, padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling1D(2),\n",
        "        layers.Dropout(0.4),\n",
        "\n",
        "        layers.Conv1D(64, 5, padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling1D(2),\n",
        "        layers.Dropout(0.4),\n",
        "\n",
        "        layers.GlobalAveragePooling1D(),\n",
        "\n",
        "        layers.Dense(128, activation='relu',\n",
        "                     kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Dense(64, activation='relu',\n",
        "                     kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n",
        "        loss=focal_loss(gamma=2.5, alpha=0.75),\n",
        "        metrics=['accuracy',\n",
        "                 keras.metrics.Precision(name='precision'),\n",
        "                 keras.metrics.Recall(name='recall'),\n",
        "                 keras.metrics.AUC(name='auc')]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "def build_cnn_config2(n_bins=1000):\n",
        "    \"\"\"\n",
        "    Config 2: Deeper network (extra Conv1D), slightly different dropout.\n",
        "    \"\"\"\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(n_bins, 1)),\n",
        "\n",
        "        layers.Conv1D(64, 3, padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling1D(2),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Conv1D(128, 3, padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling1D(2),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Conv1D(256, 3, padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling1D(2),\n",
        "        layers.Dropout(0.4),\n",
        "\n",
        "        layers.GlobalAveragePooling1D(),\n",
        "\n",
        "        layers.Dense(256, activation='relu',\n",
        "                     kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Dense(128, activation='relu',\n",
        "                     kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.Dropout(0.3),\n",
        "\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
        "        loss=focal_loss(gamma=2.0, alpha=0.75),\n",
        "        metrics=['accuracy',\n",
        "                 keras.metrics.Precision(name='precision'),\n",
        "                 keras.metrics.Recall(name='recall'),\n",
        "                 keras.metrics.AUC(name='auc')]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "def build_cnn_config3(n_bins=1000):\n",
        "    \"\"\"\n",
        "    Config 3: Same depth but narrower dense layers + stronger regularization.\n",
        "    \"\"\"\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(n_bins, 1)),\n",
        "\n",
        "        layers.Conv1D(64, 3, padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling1D(2),\n",
        "        layers.Dropout(0.4),\n",
        "\n",
        "        layers.Conv1D(128, 3, padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling1D(2),\n",
        "        layers.Dropout(0.4),\n",
        "\n",
        "        layers.GlobalAveragePooling1D(),\n",
        "\n",
        "        layers.Dense(128, activation='relu',\n",
        "                     kernel_regularizer=regularizers.l2(0.002)),\n",
        "        layers.Dropout(0.4),\n",
        "\n",
        "        layers.Dense(64, activation='relu',\n",
        "                     kernel_regularizer=regularizers.l2(0.002)),\n",
        "        layers.Dropout(0.4),\n",
        "\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n",
        "        loss=focal_loss(gamma=3.0, alpha=0.8),\n",
        "        metrics=['accuracy',\n",
        "                 keras.metrics.Precision(name='precision'),\n",
        "                 keras.metrics.Recall(name='recall'),\n",
        "                 keras.metrics.AUC(name='auc')]\n",
        "    )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28417447",
      "metadata": {},
      "source": [
        "## 7. Training with AUC Monitoring, Early Stopping & LR Scheduling\n",
        "\n",
        "We monitor **validation AUC** (not accuracy) and:\n",
        "\n",
        "- **EarlyStopping** on `val_auc` with patience to stop when progress stalls.  \n",
        "- **ReduceLROnPlateau** to gently lower the LR when AUC plateaus.  \n",
        "- **ModelCheckpoint** to persist the best model by AUC.\n",
        "\n",
        "> Tip: If your dataset is *very* small, increase dropout and/or reduce dense layers further.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "799553e8",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, X_train, y_train, X_val, y_val, epochs=100):\n",
        "    \"\"\"Train the model with AUC-centric callbacks.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"TRAINING\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    callbacks = [\n",
        "        EarlyStopping(\n",
        "            monitor='val_auc',\n",
        "            patience=20,\n",
        "            restore_best_weights=True,\n",
        "            mode='max',\n",
        "            verbose=1\n",
        "        ),\n",
        "        ReduceLROnPlateau(\n",
        "            monitor='val_auc',\n",
        "            factor=0.5,\n",
        "            patience=8,\n",
        "            min_lr=1e-7,\n",
        "            mode='max',\n",
        "            verbose=1\n",
        "        ),\n",
        "        ModelCheckpoint(\n",
        "            'best_model_final.keras',\n",
        "            monitor='val_auc',\n",
        "            save_best_only=True,\n",
        "            mode='max',\n",
        "            verbose=1\n",
        "        )\n",
        "    ]\n",
        "    \n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=epochs,\n",
        "        batch_size=32,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "    return history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2fd997b",
      "metadata": {},
      "source": [
        "## 8. Evaluation with **Optimal Threshold** (don’t default to 0.5)\n",
        "\n",
        "The default threshold (0.5) is rarely optimal with imbalanced data.  \n",
        "We compute ROC, then choose the threshold that maximizes **Youden’s J** (\\(\\mathrm{TPR} - \\mathrm{FPR}\\)).\n",
        "We report both the default and the optimal settings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "b85e7698",
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_with_optimal_threshold(model, X_test, y_test):\n",
        "    \"\"\"Find an optimal threshold from ROC (Youden's J) and evaluate.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"THRESHOLD OPTIMIZATION & EVALUATION\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    y_pred_proba = model.predict(X_test, verbose=0).flatten()\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "    \n",
        "    # Youden's J statistic\n",
        "    j_scores = tpr - fpr\n",
        "    optimal_idx = np.argmax(j_scores)\n",
        "    optimal_threshold = thresholds[optimal_idx]\n",
        "    \n",
        "    print(f\"\\nOptimal threshold: {optimal_threshold:.4f} (default=0.5)\")\n",
        "    print(f\"  At this threshold: TPR={tpr[optimal_idx]:.4f}, FPR={fpr[optimal_idx]:.4f}\")\n",
        "    \n",
        "    # Predictions with optimal vs default thresholds\n",
        "    y_pred_optimal = (y_pred_proba >= optimal_threshold).astype(int)\n",
        "    y_pred_default = (y_pred_proba >= 0.5).astype(int)\n",
        "    \n",
        "    # Metrics\n",
        "    acc_optimal = accuracy_score(y_test, y_pred_optimal)\n",
        "    acc_default = accuracy_score(y_test, y_pred_default)\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    \n",
        "    print(\"\\nResults:\")\n",
        "    print(f\"  AUC-ROC: {auc:.4f}\")\n",
        "    print(f\"  Accuracy (default threshold=0.5): {acc_default:.4f} ({acc_default*100:.2f}%)\")\n",
        "    print(f\"  Accuracy (optimal threshold={optimal_threshold:.4f}): {acc_optimal:.4f} ({acc_optimal*100:.2f}%)\")\n",
        "    \n",
        "    print(\"\\nWith optimal threshold:\")\n",
        "    print(classification_report(y_test, y_pred_optimal,\n",
        "                                target_names=['Non-Planet', 'Planet'],\n",
        "                                digits=4,\n",
        "                                zero_division=0))\n",
        "    \n",
        "    print(\"\\nPrediction distribution (optimal threshold):\")\n",
        "    print(f\"  Predicted 0: {(y_pred_optimal == 0).sum()}\")\n",
        "    print(f\"  Predicted 1: {(y_pred_optimal == 1).sum()}\")\n",
        "    print(\"True distribution:\")\n",
        "    print(f\"  True 0: {(y_test == 0).sum()}\")\n",
        "    print(f\"  True 1: {(y_test == 1).sum()}\")\n",
        "    \n",
        "    return y_pred_optimal, y_pred_proba, optimal_threshold\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e1529af",
      "metadata": {},
      "source": [
        "## 9. Visualization (Matplotlib-only)\n",
        "\n",
        "We save:\n",
        "- **Confusion matrix** (`confusion_matrix_final.png`) with counts and percentages.  \n",
        "- **Training curves** (`training_history_final.png`).  \n",
        "- **Sample light curves with predictions** (`sample_lightcurves_predictions.png`).\n",
        "\n",
        "> We use **Matplotlib** exclusively to minimize dependencies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "7ce2d06d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_lightcurves_with_predictions(X_test_orig, X_err_test, y_test, y_pred, y_pred_proba, \n",
        "                                       metadata_test, scaler, threshold, n_samples=6,\n",
        "                                       save_path='sample_lightcurves_predictions.png'):\n",
        "    \"\"\"Plot light curves with error bars and prediction info; save to file.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"PLOTTING LIGHTCURVES WITH PREDICTIONS (n={n_samples})\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    n_samples = min(n_samples, len(X_test_orig))\n",
        "    \n",
        "    # Select diverse samples: correct/incorrect for both classes\n",
        "    correct_planet = np.where((y_test == 1) & (y_pred == 1))[0]\n",
        "    incorrect_planet = np.where((y_test == 1) & (y_pred == 0))[0]\n",
        "    correct_nonplanet = np.where((y_test == 0) & (y_pred == 0))[0]\n",
        "    incorrect_nonplanet = np.where((y_test == 0) & (y_pred == 1))[0]\n",
        "    \n",
        "    selected_idx = []\n",
        "    per_category = max(1, n_samples // 4)\n",
        "    \n",
        "    for idx_list in [correct_planet, incorrect_planet, correct_nonplanet, incorrect_nonplanet]:\n",
        "        if len(idx_list) > 0:\n",
        "            n_select = min(per_category, len(idx_list))\n",
        "            selected_idx.extend(np.random.choice(idx_list, n_select, replace=False))\n",
        "    \n",
        "    while len(selected_idx) < n_samples:\n",
        "        remaining = list(set(range(len(y_test))) - set(selected_idx))\n",
        "        if remaining:\n",
        "            selected_idx.append(np.random.choice(remaining))\n",
        "        else:\n",
        "            break\n",
        "    \n",
        "    selected_idx = np.array(selected_idx[:n_samples])\n",
        "    \n",
        "    # Figure layout\n",
        "    n_cols = 2\n",
        "    n_rows = (n_samples + n_cols - 1) // n_cols\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 4*n_rows))\n",
        "    if n_samples == 1:\n",
        "        axes = np.array([axes])\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for plot_i, idx in enumerate(selected_idx):\n",
        "        ax = axes[plot_i]\n",
        "        \n",
        "        # Inverse transform to original scale for plotting\n",
        "        flux_norm = X_test_orig[idx].flatten()\n",
        "        flux_err = X_err_test[idx]\n",
        "        flux_original = scaler.inverse_transform(flux_norm.reshape(1, -1)).flatten()\n",
        "        \n",
        "        time_bins = np.arange(len(flux_original))\n",
        "        \n",
        "        # Metadata\n",
        "        toi_name = metadata_test.loc[idx, 'toi_name']\n",
        "        tic = metadata_test.loc[idx, 'tic']\n",
        "        disp = metadata_test.loc[idx, 'disp']\n",
        "        sector = metadata_test.loc[idx, 'sector']\n",
        "        \n",
        "        true_label = y_test[idx]\n",
        "        pred_label = y_pred[idx]\n",
        "        pred_prob = y_pred_proba[idx]\n",
        "        \n",
        "        is_correct = (true_label == pred_label)\n",
        "        true_str = 'Transit' if true_label == 1 else 'Non-Transit'\n",
        "        pred_str = 'Transit' if pred_label == 1 else 'Non-Transit'\n",
        "        \n",
        "        # Errorbar plot\n",
        "        ax.errorbar(time_bins, flux_original, yerr=flux_err, fmt='o', markersize=2,\n",
        "                    ecolor='gray', elinewidth=0.5, capsize=0, alpha=0.6, label='Data')\n",
        "        \n",
        "        # Baseline median\n",
        "        baseline = np.median(flux_original)\n",
        "        ax.axhline(baseline, linestyle='--', linewidth=1, alpha=0.7, label='Baseline')\n",
        "        \n",
        "        ax.set_xlabel('Time Bin', fontsize=10, fontweight='bold')\n",
        "        ax.set_ylabel('Flux (original scale)', fontsize=10, fontweight='bold')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.legend(loc='upper right', fontsize=8)\n",
        "        \n",
        "        status_symbol = '✓' if is_correct else '✗'\n",
        "        color = 'green' if is_correct else 'red'\n",
        "        title = (f'TOI {toi_name} (TIC {tic}, {disp}) - TESS Sector {sector}\\n'\n",
        "                 f'True: {true_str} | Pred: {pred_str} (p={pred_prob:.3f}) {status_symbol}')\n",
        "        ax.set_title(title, fontsize=10, fontweight='bold', color=color, pad=10)\n",
        "        \n",
        "        for spine in ax.spines.values():\n",
        "            spine.set_edgecolor(color)\n",
        "            spine.set_linewidth(2.0)\n",
        "    \n",
        "    # Hide unused axes\n",
        "    for j in range(n_samples, len(axes)):\n",
        "        axes[j].axis('off')\n",
        "    \n",
        "    plt.suptitle(f'Sample Light-curve Predictions (Threshold={threshold:.3f})',\n",
        "                 fontsize=14, fontweight='bold', y=0.995)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"Saved: {save_path}\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def plot_all(y_test, y_pred, y_pred_proba, history, metadata_test, X_test, threshold,\n",
        "             X_test_orig=None, X_err_test=None, scaler=None):\n",
        "    \"\"\"Create and save confusion matrix and training curves. Optionally plot light curves.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"VISUALIZATIONS\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    # Confusion matrix (Matplotlib-only)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap='Blues')\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    ax.set(xticks=np.arange(2),\n",
        "           yticks=np.arange(2),\n",
        "           xticklabels=['Non-Planet', 'Planet'],\n",
        "           yticklabels=['Non-Planet', 'Planet'],\n",
        "           xlabel='Predicted', ylabel='True',\n",
        "           title=f'Confusion Matrix (threshold={threshold:.3f})')\n",
        "    \n",
        "    # Add counts and percentages\n",
        "    total = cm.sum()\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            count = cm[i, j]\n",
        "            pct = (count / total * 100) if total > 0 else 0.0\n",
        "            ax.text(j, i, f\"{count}\\n({pct:.1f}%)\", ha='center', va='center', color='black', fontsize=10)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('confusion_matrix_final.png', dpi=300)\n",
        "    print(\"Saved: confusion_matrix_final.png\")\n",
        "    plt.close()\n",
        "    \n",
        "    # Training history\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    metrics = [('loss', 'Loss'), ('accuracy', 'Accuracy'),\n",
        "               ('auc', 'AUC'), ('recall', 'Recall')]\n",
        "    \n",
        "    for idx, (metric, title) in enumerate(metrics):\n",
        "        ax = axes[idx // 2, idx % 2]\n",
        "        if metric in history.history and f'val_{metric}' in history.history:\n",
        "            ax.plot(history.history[metric], label='Train', linewidth=2)\n",
        "            ax.plot(history.history[f'val_{metric}'], label='Val', linewidth=2)\n",
        "            ax.set_xlabel('Epoch')\n",
        "            ax.set_ylabel(title)\n",
        "            ax.set_title(f'{title} vs Epoch', fontweight='bold')\n",
        "            ax.legend()\n",
        "            ax.grid(alpha=0.3)\n",
        "    \n",
        "    plt.suptitle('Training History - Final Model', fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_history_final.png', dpi=300)\n",
        "    print(\"Saved: training_history_final.png\")\n",
        "    plt.close()\n",
        "    \n",
        "    # Optional: light-curve panel\n",
        "    if X_test_orig is not None and X_err_test is not None and scaler is not None:\n",
        "        plot_lightcurves_with_predictions(X_test_orig, X_err_test, y_test, y_pred, \n",
        "                                          y_pred_proba, metadata_test, scaler, threshold, n_samples=6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b561a755",
      "metadata": {},
      "source": [
        "## 10. Run the Pipeline\n",
        "\n",
        "You can run the following cells **step by step**, or use the **end-to-end** cell.\n",
        "\n",
        "> If your CSV isn’t called `tess_data.csv`, change `CSV_PATH` below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "053ea574",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Path to your dataset\n",
        "CSV_PATH = 'tess_data.csv'   # <- change me if needed\n",
        "N_BINS = 1000                # number of flux bins/columns per sample\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "bdfd93e1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "LOADING DATA\n",
            "======================================================================\n",
            "Dataset: 944 samples\n",
            "\n",
            "Original distribution:\n",
            "  Class 0: 472, Class 1: 472\n",
            "  Ratio: 1.00:1\n",
            "\n",
            "Initial split - Train: 755, Test: 189\n",
            "\n",
            "======================================================================\n",
            "CREATING BALANCED DATASET\n",
            "======================================================================\n",
            "Original - Class 0: 377, Class 1: 378\n",
            "Balanced - Class 0: 350, Class 1: 350\n",
            "\n",
            "======================================================================\n",
            "STANDARDIZATION\n",
            "======================================================================\n",
            "Train: mean=0.000000, std=1.000000\n",
            "Test:  mean=-0.000624, std=0.428148\n",
            "\n",
            "Final - X_train: (700, 1000, 1), X_test: (189, 1000, 1)\n",
            "Train dist: 0=350, 1=350\n"
          ]
        }
      ],
      "source": [
        "# 1) Load and prepare data\n",
        "X_train, X_test, y_train, y_test, metadata_test, X_test_orig, X_err_test, scaler = load_data(\n",
        "    csv_path=CSV_PATH, n_bins=N_BINS\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "8e5abe27",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "BUILDING SIMPLIFIED CNN\n",
            "======================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m24,704\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │        \u001b[38;5;34m98,560\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">421,249</span> (1.61 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m421,249\u001b[0m (1.61 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">420,353</span> (1.60 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m420,353\u001b[0m (1.60 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Using Focal Loss (gamma=2.5, alpha=0.75)\n"
          ]
        }
      ],
      "source": [
        "# 2) Build model\n",
        "model = build_simple_cnn(n_bins=N_BINS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "109ebc2b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "TRAINING CONFIGURATION: CNN_default\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "BUILDING SIMPLIFIED CNN\n",
            "======================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_4 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m24,704\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_5 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │        \u001b[38;5;34m98,560\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d_2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">421,249</span> (1.61 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m421,249\u001b[0m (1.61 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">420,353</span> (1.60 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m420,353\u001b[0m (1.60 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Using Focal Loss (gamma=2.5, alpha=0.75)\n",
            "\n",
            "======================================================================\n",
            "TRAINING\n",
            "======================================================================\n",
            "Epoch 1/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.4541 - auc: 0.4090 - loss: 0.8798 - precision: 0.4618 - recall: 0.7680\n",
            "Epoch 1: val_auc improved from None to 0.54782, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - accuracy: 0.4886 - auc: 0.4157 - loss: 0.8456 - precision: 0.4937 - recall: 0.9000 - val_accuracy: 0.4974 - val_auc: 0.5478 - val_loss: 0.7695 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.4931 - auc: 0.5449 - loss: 0.7447 - precision: 0.4866 - recall: 0.9682\n",
            "Epoch 2: val_auc did not improve from 0.54782\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - accuracy: 0.5100 - auc: 0.5435 - loss: 0.7217 - precision: 0.5052 - recall: 0.9629 - val_accuracy: 0.4974 - val_auc: 0.5329 - val_loss: 0.6662 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.5149 - auc: 0.5703 - loss: 0.6464 - precision: 0.5055 - recall: 0.9802\n",
            "Epoch 3: val_auc did not improve from 0.54782\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - accuracy: 0.5186 - auc: 0.6032 - loss: 0.6250 - precision: 0.5097 - recall: 0.9714 - val_accuracy: 0.4974 - val_auc: 0.5211 - val_loss: 0.5823 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.5308 - auc: 0.6928 - loss: 0.5620 - precision: 0.5128 - recall: 0.9833\n",
            "Epoch 4: val_auc did not improve from 0.54782\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - accuracy: 0.5300 - auc: 0.6511 - loss: 0.5445 - precision: 0.5158 - recall: 0.9800 - val_accuracy: 0.4974 - val_auc: 0.5293 - val_loss: 0.5108 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.5237 - auc: 0.6664 - loss: 0.4909 - precision: 0.5148 - recall: 0.9367\n",
            "Epoch 5: val_auc did not improve from 0.54782\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 0.5257 - auc: 0.6498 - loss: 0.4764 - precision: 0.5139 - recall: 0.9514 - val_accuracy: 0.4974 - val_auc: 0.5361 - val_loss: 0.4572 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.5182 - auc: 0.6662 - loss: 0.4312 - precision: 0.5041 - recall: 0.9882\n",
            "Epoch 6: val_auc improved from 0.54782 to 0.73875, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - accuracy: 0.5243 - auc: 0.7017 - loss: 0.4179 - precision: 0.5127 - recall: 0.9800 - val_accuracy: 0.4974 - val_auc: 0.7387 - val_loss: 0.4081 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.5286 - auc: 0.7332 - loss: 0.3779 - precision: 0.5064 - recall: 0.9744\n",
            "Epoch 7: val_auc did not improve from 0.73875\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.5543 - auc: 0.7353 - loss: 0.3672 - precision: 0.5299 - recall: 0.9629 - val_accuracy: 0.4974 - val_auc: 0.6209 - val_loss: 0.3577 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.5737 - auc: 0.7840 - loss: 0.3323 - precision: 0.5405 - recall: 0.9869\n",
            "Epoch 8: val_auc did not improve from 0.73875\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - accuracy: 0.5671 - auc: 0.7651 - loss: 0.3241 - precision: 0.5371 - recall: 0.9714 - val_accuracy: 0.4974 - val_auc: 0.5339 - val_loss: 0.3173 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.5695 - auc: 0.7317 - loss: 0.2983 - precision: 0.5415 - recall: 0.9434\n",
            "Epoch 9: val_auc did not improve from 0.73875\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.5643 - auc: 0.7480 - loss: 0.2893 - precision: 0.5359 - recall: 0.9600 - val_accuracy: 0.4974 - val_auc: 0.5336 - val_loss: 0.2789 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.6063 - auc: 0.7660 - loss: 0.2645 - precision: 0.5737 - recall: 0.9401\n",
            "Epoch 10: val_auc did not improve from 0.73875\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - accuracy: 0.6000 - auc: 0.7742 - loss: 0.2572 - precision: 0.5583 - recall: 0.9571 - val_accuracy: 0.4974 - val_auc: 0.5857 - val_loss: 0.2510 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.6221 - auc: 0.7910 - loss: 0.2361 - precision: 0.5774 - recall: 0.9504 \n",
            "Epoch 11: val_auc did not improve from 0.73875\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.6229 - auc: 0.7766 - loss: 0.2307 - precision: 0.5747 - recall: 0.9457 - val_accuracy: 0.4974 - val_auc: 0.5799 - val_loss: 0.2266 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.6293 - auc: 0.8022 - loss: 0.2109 - precision: 0.5753 - recall: 0.9449\n",
            "Epoch 12: val_auc did not improve from 0.73875\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 116ms/step - accuracy: 0.6543 - auc: 0.7756 - loss: 0.2072 - precision: 0.5978 - recall: 0.9429 - val_accuracy: 0.5397 - val_auc: 0.5288 - val_loss: 0.2023 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.6134 - auc: 0.7617 - loss: 0.1918 - precision: 0.5744 - recall: 0.9594 \n",
            "Epoch 13: val_auc did not improve from 0.73875\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - accuracy: 0.6300 - auc: 0.7711 - loss: 0.1871 - precision: 0.5797 - recall: 0.9457 - val_accuracy: 0.5026 - val_auc: 0.5755 - val_loss: 0.2075 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 5.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.6211 - auc: 0.7502 - loss: 0.1754 - precision: 0.5787 - recall: 0.9621\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 14: val_auc did not improve from 0.73875\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.6086 - auc: 0.7517 - loss: 0.1717 - precision: 0.5635 - recall: 0.9629 - val_accuracy: 0.5132 - val_auc: 0.6395 - val_loss: 0.1856 - val_precision: 1.0000 - val_recall: 0.0213 - learning_rate: 5.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.6422 - auc: 0.8123 - loss: 0.1586 - precision: 0.5917 - recall: 0.9736\n",
            "Epoch 15: val_auc improved from 0.73875 to 0.77828, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 116ms/step - accuracy: 0.6271 - auc: 0.7896 - loss: 0.1581 - precision: 0.5763 - recall: 0.9600 - val_accuracy: 0.6772 - val_auc: 0.7783 - val_loss: 0.1715 - val_precision: 0.9231 - val_recall: 0.3830 - learning_rate: 2.5000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.6734 - auc: 0.8284 - loss: 0.1500 - precision: 0.6273 - recall: 0.9313\n",
            "Epoch 16: val_auc improved from 0.77828 to 0.78382, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.6429 - auc: 0.8068 - loss: 0.1498 - precision: 0.5890 - recall: 0.9457 - val_accuracy: 0.6296 - val_auc: 0.7838 - val_loss: 0.1654 - val_precision: 0.9286 - val_recall: 0.2766 - learning_rate: 2.5000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.6882 - auc: 0.8137 - loss: 0.1450 - precision: 0.6220 - recall: 0.8878\n",
            "Epoch 17: val_auc did not improve from 0.78382\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - accuracy: 0.6871 - auc: 0.7965 - loss: 0.1444 - precision: 0.6318 - recall: 0.8971 - val_accuracy: 0.5767 - val_auc: 0.5694 - val_loss: 0.1613 - val_precision: 0.8182 - val_recall: 0.1915 - learning_rate: 2.5000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.6202 - auc: 0.8127 - loss: 0.1382 - precision: 0.5692 - recall: 0.9818\n",
            "Epoch 18: val_auc did not improve from 0.78382\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - accuracy: 0.6386 - auc: 0.7999 - loss: 0.1373 - precision: 0.5832 - recall: 0.9714 - val_accuracy: 0.5026 - val_auc: 0.6690 - val_loss: 0.1856 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 2.5000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.6931 - auc: 0.7969 - loss: 0.1332 - precision: 0.6521 - recall: 0.9418 \n",
            "Epoch 19: val_auc did not improve from 0.78382\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 0.6443 - auc: 0.8082 - loss: 0.1310 - precision: 0.5884 - recall: 0.9600 - val_accuracy: 0.5026 - val_auc: 0.7693 - val_loss: 0.1821 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 2.5000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.7027 - auc: 0.7996 - loss: 0.1289 - precision: 0.6446 - recall: 0.8823\n",
            "Epoch 20: val_auc did not improve from 0.78382\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 0.6800 - auc: 0.7922 - loss: 0.1276 - precision: 0.6260 - recall: 0.8943 - val_accuracy: 0.5767 - val_auc: 0.6040 - val_loss: 0.1348 - val_precision: 0.5437 - val_recall: 0.9255 - learning_rate: 2.5000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.6540 - auc: 0.8127 - loss: 0.1214 - precision: 0.6046 - recall: 0.9621\n",
            "Epoch 21: val_auc improved from 0.78382 to 0.83561, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 116ms/step - accuracy: 0.6214 - auc: 0.8005 - loss: 0.1212 - precision: 0.5722 - recall: 0.9629 - val_accuracy: 0.6720 - val_auc: 0.8356 - val_loss: 0.1346 - val_precision: 0.8810 - val_recall: 0.3936 - learning_rate: 2.5000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.6584 - auc: 0.8046 - loss: 0.1174 - precision: 0.5955 - recall: 0.9359\n",
            "Epoch 22: val_auc did not improve from 0.83561\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.6871 - auc: 0.8059 - loss: 0.1161 - precision: 0.6302 - recall: 0.9057 - val_accuracy: 0.5291 - val_auc: 0.6406 - val_loss: 0.1311 - val_precision: 0.5229 - val_recall: 0.6064 - learning_rate: 2.5000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.6247 - auc: 0.7922 - loss: 0.1132 - precision: 0.5718 - recall: 0.9896\n",
            "Epoch 23: val_auc improved from 0.83561 to 0.83992, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - accuracy: 0.6529 - auc: 0.8037 - loss: 0.1109 - precision: 0.5937 - recall: 0.9686 - val_accuracy: 0.5873 - val_auc: 0.8399 - val_loss: 0.1165 - val_precision: 0.5506 - val_recall: 0.9255 - learning_rate: 2.5000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.6908 - auc: 0.8246 - loss: 0.1062 - precision: 0.6393 - recall: 0.9314\n",
            "Epoch 24: val_auc did not improve from 0.83992\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.6671 - auc: 0.8242 - loss: 0.1054 - precision: 0.6077 - recall: 0.9429 - val_accuracy: 0.5714 - val_auc: 0.7839 - val_loss: 0.1091 - val_precision: 0.5389 - val_recall: 0.9574 - learning_rate: 2.5000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7062 - auc: 0.8216 - loss: 0.1030 - precision: 0.6293 - recall: 0.9241\n",
            "Epoch 25: val_auc did not improve from 0.83992\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - accuracy: 0.6914 - auc: 0.8159 - loss: 0.1019 - precision: 0.6324 - recall: 0.9143 - val_accuracy: 0.5820 - val_auc: 0.5658 - val_loss: 0.1125 - val_precision: 0.5439 - val_recall: 0.9894 - learning_rate: 2.5000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.6840 - auc: 0.8364 - loss: 0.0980 - precision: 0.6261 - recall: 0.9478\n",
            "Epoch 26: val_auc did not improve from 0.83992\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - accuracy: 0.6900 - auc: 0.8155 - loss: 0.0983 - precision: 0.6301 - recall: 0.9200 - val_accuracy: 0.5767 - val_auc: 0.5288 - val_loss: 0.1090 - val_precision: 0.5417 - val_recall: 0.9681 - learning_rate: 2.5000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.6719 - auc: 0.8399 - loss: 0.0944 - precision: 0.6285 - recall: 0.9294\n",
            "Epoch 27: val_auc did not improve from 0.83992\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 0.6743 - auc: 0.8181 - loss: 0.0946 - precision: 0.6155 - recall: 0.9286 - val_accuracy: 0.5714 - val_auc: 0.7366 - val_loss: 0.0997 - val_precision: 0.5389 - val_recall: 0.9574 - learning_rate: 2.5000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.7011 - auc: 0.8128 - loss: 0.0926 - precision: 0.6403 - recall: 0.9231\n",
            "Epoch 28: val_auc did not improve from 0.83992\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - accuracy: 0.6786 - auc: 0.8010 - loss: 0.0924 - precision: 0.6195 - recall: 0.9257 - val_accuracy: 0.5767 - val_auc: 0.5994 - val_loss: 0.1014 - val_precision: 0.5402 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.6398 - auc: 0.8295 - loss: 0.0883 - precision: 0.5720 - recall: 0.9388\n",
            "Epoch 29: val_auc did not improve from 0.83992\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - accuracy: 0.6714 - auc: 0.8206 - loss: 0.0877 - precision: 0.6149 - recall: 0.9171 - val_accuracy: 0.5820 - val_auc: 0.5296 - val_loss: 0.1006 - val_precision: 0.5434 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.6842 - auc: 0.8414 - loss: 0.0843 - precision: 0.6204 - recall: 0.9682\n",
            "Epoch 30: val_auc did not improve from 0.83992\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - accuracy: 0.6929 - auc: 0.8252 - loss: 0.0845 - precision: 0.6281 - recall: 0.9457 - val_accuracy: 0.5767 - val_auc: 0.7727 - val_loss: 0.0931 - val_precision: 0.5402 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.7094 - auc: 0.8293 - loss: 0.0814 - precision: 0.6461 - recall: 0.9388\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 31: val_auc did not improve from 0.83992\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 0.6814 - auc: 0.8219 - loss: 0.0819 - precision: 0.6200 - recall: 0.9371 - val_accuracy: 0.5767 - val_auc: 0.6530 - val_loss: 0.0947 - val_precision: 0.5407 - val_recall: 0.9894 - learning_rate: 2.5000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.7339 - auc: 0.8442 - loss: 0.0784 - precision: 0.6728 - recall: 0.9536\n",
            "Epoch 32: val_auc improved from 0.83992 to 0.85050, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.7057 - auc: 0.8337 - loss: 0.0790 - precision: 0.6417 - recall: 0.9314 - val_accuracy: 0.5767 - val_auc: 0.8505 - val_loss: 0.0851 - val_precision: 0.5407 - val_recall: 0.9894 - learning_rate: 1.2500e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.6990 - auc: 0.8353 - loss: 0.0778 - precision: 0.6309 - recall: 0.9418\n",
            "Epoch 33: val_auc did not improve from 0.85050\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - accuracy: 0.7029 - auc: 0.8391 - loss: 0.0776 - precision: 0.6387 - recall: 0.9343 - val_accuracy: 0.5767 - val_auc: 0.7406 - val_loss: 0.0941 - val_precision: 0.5402 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.7027 - auc: 0.8307 - loss: 0.0768 - precision: 0.6382 - recall: 0.9433\n",
            "Epoch 34: val_auc did not improve from 0.85050\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - accuracy: 0.7100 - auc: 0.8309 - loss: 0.0766 - precision: 0.6467 - recall: 0.9257 - val_accuracy: 0.5714 - val_auc: 0.6702 - val_loss: 0.1032 - val_precision: 0.5371 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.7481 - auc: 0.8584 - loss: 0.0731 - precision: 0.6827 - recall: 0.9727\n",
            "Epoch 35: val_auc did not improve from 0.85050\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - accuracy: 0.6929 - auc: 0.8334 - loss: 0.0751 - precision: 0.6248 - recall: 0.9657 - val_accuracy: 0.5714 - val_auc: 0.5940 - val_loss: 0.0992 - val_precision: 0.5371 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.7376 - auc: 0.8429 - loss: 0.0739 - precision: 0.6749 - recall: 0.9086\n",
            "Epoch 36: val_auc did not improve from 0.85050\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - accuracy: 0.7229 - auc: 0.8217 - loss: 0.0754 - precision: 0.6632 - recall: 0.9057 - val_accuracy: 0.5714 - val_auc: 0.6798 - val_loss: 0.0929 - val_precision: 0.5371 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.7073 - auc: 0.8466 - loss: 0.0725 - precision: 0.6365 - recall: 0.9544\n",
            "Epoch 37: val_auc did not improve from 0.85050\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - accuracy: 0.7057 - auc: 0.8379 - loss: 0.0724 - precision: 0.6369 - recall: 0.9571 - val_accuracy: 0.5714 - val_auc: 0.7994 - val_loss: 0.0912 - val_precision: 0.5371 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.7101 - auc: 0.8500 - loss: 0.0711 - precision: 0.6474 - recall: 0.9059\n",
            "Epoch 38: val_auc did not improve from 0.85050\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.7057 - auc: 0.8345 - loss: 0.0720 - precision: 0.6434 - recall: 0.9229 - val_accuracy: 0.5767 - val_auc: 0.6442 - val_loss: 0.0959 - val_precision: 0.5402 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.7102 - auc: 0.8464 - loss: 0.0702 - precision: 0.6553 - recall: 0.9524\n",
            "Epoch 39: val_auc did not improve from 0.85050\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 0.7057 - auc: 0.8409 - loss: 0.0704 - precision: 0.6395 - recall: 0.9429 - val_accuracy: 0.5820 - val_auc: 0.7441 - val_loss: 0.0816 - val_precision: 0.5439 - val_recall: 0.9894 - learning_rate: 1.2500e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.7400 - auc: 0.8439 - loss: 0.0691 - precision: 0.6776 - recall: 0.9251\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 40: val_auc did not improve from 0.85050\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - accuracy: 0.7057 - auc: 0.8358 - loss: 0.0696 - precision: 0.6401 - recall: 0.9400 - val_accuracy: 0.5767 - val_auc: 0.6708 - val_loss: 0.0888 - val_precision: 0.5402 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.7543 - auc: 0.8498 - loss: 0.0686 - precision: 0.6871 - recall: 0.9404\n",
            "Epoch 41: val_auc did not improve from 0.85050\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.7329 - auc: 0.8539 - loss: 0.0676 - precision: 0.6646 - recall: 0.9400 - val_accuracy: 0.5820 - val_auc: 0.7741 - val_loss: 0.0863 - val_precision: 0.5434 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 42/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.7690 - auc: 0.8784 - loss: 0.0647 - precision: 0.6972 - recall: 0.9596\n",
            "Epoch 42: val_auc did not improve from 0.85050\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - accuracy: 0.7457 - auc: 0.8466 - loss: 0.0669 - precision: 0.6748 - recall: 0.9486 - val_accuracy: 0.5820 - val_auc: 0.7359 - val_loss: 0.0874 - val_precision: 0.5434 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 43/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.7262 - auc: 0.8580 - loss: 0.0668 - precision: 0.6601 - recall: 0.9343\n",
            "Epoch 43: val_auc did not improve from 0.85050\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - accuracy: 0.7171 - auc: 0.8434 - loss: 0.0675 - precision: 0.6538 - recall: 0.9229 - val_accuracy: 0.5820 - val_auc: 0.7126 - val_loss: 0.0882 - val_precision: 0.5434 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 44/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7161 - auc: 0.8232 - loss: 0.0689 - precision: 0.6463 - recall: 0.9234\n",
            "Epoch 44: val_auc did not improve from 0.85050\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 0.7143 - auc: 0.8287 - loss: 0.0681 - precision: 0.6512 - recall: 0.9229 - val_accuracy: 0.5873 - val_auc: 0.7111 - val_loss: 0.0857 - val_precision: 0.5465 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 45/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.7063 - auc: 0.8441 - loss: 0.0660 - precision: 0.6527 - recall: 0.9285\n",
            "Epoch 45: val_auc did not improve from 0.85050\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.6886 - auc: 0.8402 - loss: 0.0666 - precision: 0.6245 - recall: 0.9457 - val_accuracy: 0.5767 - val_auc: 0.8418 - val_loss: 0.0758 - val_precision: 0.5407 - val_recall: 0.9894 - learning_rate: 6.2500e-05\n",
            "Epoch 46/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.7167 - auc: 0.8099 - loss: 0.0697 - precision: 0.6827 - recall: 0.9053\n",
            "Epoch 46: val_auc improved from 0.85050 to 0.85610, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - accuracy: 0.6957 - auc: 0.8178 - loss: 0.0681 - precision: 0.6367 - recall: 0.9114 - val_accuracy: 0.5820 - val_auc: 0.8561 - val_loss: 0.0737 - val_precision: 0.5439 - val_recall: 0.9894 - learning_rate: 6.2500e-05\n",
            "Epoch 47/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.7287 - auc: 0.8617 - loss: 0.0641 - precision: 0.6608 - recall: 0.9456\n",
            "Epoch 47: val_auc did not improve from 0.85610\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 0.7243 - auc: 0.8593 - loss: 0.0641 - precision: 0.6554 - recall: 0.9457 - val_accuracy: 0.5820 - val_auc: 0.8263 - val_loss: 0.0763 - val_precision: 0.5439 - val_recall: 0.9894 - learning_rate: 6.2500e-05\n",
            "Epoch 48/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.7349 - auc: 0.8500 - loss: 0.0642 - precision: 0.6551 - recall: 0.9366\n",
            "Epoch 48: val_auc did not improve from 0.85610\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - accuracy: 0.7300 - auc: 0.8477 - loss: 0.0642 - precision: 0.6613 - recall: 0.9429 - val_accuracy: 0.5820 - val_auc: 0.7010 - val_loss: 0.0846 - val_precision: 0.5439 - val_recall: 0.9894 - learning_rate: 6.2500e-05\n",
            "Epoch 49/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.6919 - auc: 0.8128 - loss: 0.0668 - precision: 0.6293 - recall: 0.8932\n",
            "Epoch 49: val_auc did not improve from 0.85610\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 0.7057 - auc: 0.8332 - loss: 0.0652 - precision: 0.6417 - recall: 0.9314 - val_accuracy: 0.5767 - val_auc: 0.6901 - val_loss: 0.0843 - val_precision: 0.5407 - val_recall: 0.9894 - learning_rate: 6.2500e-05\n",
            "Epoch 50/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.6909 - auc: 0.8423 - loss: 0.0642 - precision: 0.6422 - recall: 0.9271\n",
            "Epoch 50: val_auc did not improve from 0.85610\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - accuracy: 0.6871 - auc: 0.8388 - loss: 0.0649 - precision: 0.6282 - recall: 0.9171 - val_accuracy: 0.5873 - val_auc: 0.7750 - val_loss: 0.0821 - val_precision: 0.5465 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Restoring model weights from the end of the best epoch: 46.\n",
            "\n",
            "======================================================================\n",
            "THRESHOLD OPTIMIZATION & EVALUATION\n",
            "======================================================================\n",
            "\n",
            "Optimal threshold: 0.6458 (default=0.5)\n",
            "  At this threshold: TPR=0.8298, FPR=0.1263\n",
            "\n",
            "Results:\n",
            "  AUC-ROC: 0.8586\n",
            "  Accuracy (default threshold=0.5): 0.5820 (58.20%)\n",
            "  Accuracy (optimal threshold=0.6458): 0.8519 (85.19%)\n",
            "\n",
            "With optimal threshold:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Non-Planet     0.8384    0.8737    0.8557        95\n",
            "      Planet     0.8667    0.8298    0.8478        94\n",
            "\n",
            "    accuracy                         0.8519       189\n",
            "   macro avg     0.8525    0.8517    0.8517       189\n",
            "weighted avg     0.8525    0.8519    0.8518       189\n",
            "\n",
            "\n",
            "Prediction distribution (optimal threshold):\n",
            "  Predicted 0: 99\n",
            "  Predicted 1: 90\n",
            "True distribution:\n",
            "  True 0: 95\n",
            "  True 1: 94\n",
            "\n",
            "Confusion matrix (optimal threshold):\n",
            "[[83 12]\n",
            " [16 78]]\n",
            "Precision (optimal threshold): 0.8667\n",
            "\n",
            "======================================================================\n",
            "VISUALIZATIONS\n",
            "======================================================================\n",
            "Saved: confusion_matrix_final.png\n",
            "Saved: training_history_final.png\n",
            "\n",
            "======================================================================\n",
            "PLOTTING LIGHTCURVES WITH PREDICTIONS (n=6)\n",
            "======================================================================\n",
            "Saved: sample_lightcurves_predictions.png\n",
            "\n",
            "======================================================================\n",
            "TRAINING CONFIGURATION: CNN_config1\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "TRAINING\n",
            "======================================================================\n",
            "Epoch 1/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5151 - auc: 0.5182 - loss: 0.2328 - precision: 0.5149 - recall: 0.6097\n",
            "Epoch 1: val_auc improved from None to 0.54530, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.5157 - auc: 0.5134 - loss: 0.2260 - precision: 0.5099 - recall: 0.8114 - val_accuracy: 0.5397 - val_auc: 0.5453 - val_loss: 0.2116 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5435 - auc: 0.4608 - loss: 0.2105 - precision: 0.5314 - recall: 0.9545\n",
            "Epoch 2: val_auc did not improve from 0.54530\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5386 - auc: 0.4802 - loss: 0.2069 - precision: 0.5209 - recall: 0.9629 - val_accuracy: 0.5291 - val_auc: 0.5168 - val_loss: 0.1992 - val_precision: 0.5137 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5168 - auc: 0.5167 - loss: 0.1943 - precision: 0.5125 - recall: 0.9875\n",
            "Epoch 3: val_auc did not improve from 0.54530\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5143 - auc: 0.5403 - loss: 0.1911 - precision: 0.5074 - recall: 0.9857 - val_accuracy: 0.5397 - val_auc: 0.5431 - val_loss: 0.1873 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5238 - auc: 0.5722 - loss: 0.1796 - precision: 0.5017 - recall: 0.9851\n",
            "Epoch 4: val_auc improved from 0.54530 to 0.54826, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5486 - auc: 0.5607 - loss: 0.1774 - precision: 0.5259 - recall: 0.9857 - val_accuracy: 0.5397 - val_auc: 0.5483 - val_loss: 0.1774 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5278 - auc: 0.6108 - loss: 0.1698 - precision: 0.5115 - recall: 0.9643\n",
            "Epoch 5: val_auc did not improve from 0.54826\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5329 - auc: 0.6007 - loss: 0.1701 - precision: 0.5175 - recall: 0.9743 - val_accuracy: 0.5397 - val_auc: 0.5474 - val_loss: 0.1685 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5249 - auc: 0.5431 - loss: 0.1611 - precision: 0.5116 - recall: 0.9927\n",
            "Epoch 6: val_auc improved from 0.54826 to 0.55263, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5257 - auc: 0.5695 - loss: 0.1587 - precision: 0.5133 - recall: 0.9914 - val_accuracy: 0.5397 - val_auc: 0.5526 - val_loss: 0.1606 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5326 - auc: 0.6124 - loss: 0.1513 - precision: 0.5053 - recall: 0.9870\n",
            "Epoch 7: val_auc did not improve from 0.55263\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.5457 - auc: 0.6019 - loss: 0.1498 - precision: 0.5242 - recall: 0.9886 - val_accuracy: 0.5397 - val_auc: 0.5522 - val_loss: 0.1533 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5264 - auc: 0.6582 - loss: 0.1438 - precision: 0.5101 - recall: 0.9963\n",
            "Epoch 8: val_auc did not improve from 0.55263\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5414 - auc: 0.6704 - loss: 0.1420 - precision: 0.5217 - recall: 0.9943 - val_accuracy: 0.5397 - val_auc: 0.5522 - val_loss: 0.1469 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5382 - auc: 0.6651 - loss: 0.1393 - precision: 0.5221 - recall: 0.9893\n",
            "Epoch 9: val_auc improved from 0.55263 to 0.55789, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5343 - auc: 0.6307 - loss: 0.1380 - precision: 0.5179 - recall: 0.9914 - val_accuracy: 0.5450 - val_auc: 0.5579 - val_loss: 0.1413 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5321 - auc: 0.6326 - loss: 0.1330 - precision: 0.5136 - recall: 0.9728\n",
            "Epoch 10: val_auc improved from 0.55789 to 0.66114, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5471 - auc: 0.6439 - loss: 0.1315 - precision: 0.5253 - recall: 0.9771 - val_accuracy: 0.5450 - val_auc: 0.6611 - val_loss: 0.1364 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5769 - auc: 0.6622 - loss: 0.1266 - precision: 0.5683 - recall: 0.9884\n",
            "Epoch 11: val_auc did not improve from 0.66114\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5386 - auc: 0.6545 - loss: 0.1258 - precision: 0.5202 - recall: 0.9943 - val_accuracy: 0.5450 - val_auc: 0.5717 - val_loss: 0.1312 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5262 - auc: 0.7085 - loss: 0.1214 - precision: 0.5126 - recall: 0.9906\n",
            "Epoch 12: val_auc did not improve from 0.66114\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5400 - auc: 0.6991 - loss: 0.1208 - precision: 0.5211 - recall: 0.9857 - val_accuracy: 0.5450 - val_auc: 0.5955 - val_loss: 0.1267 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5149 - auc: 0.6661 - loss: 0.1195 - precision: 0.5040 - recall: 0.9821\n",
            "Epoch 13: val_auc did not improve from 0.66114\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.5357 - auc: 0.6626 - loss: 0.1179 - precision: 0.5186 - recall: 0.9943 - val_accuracy: 0.5450 - val_auc: 0.5728 - val_loss: 0.1233 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5184 - auc: 0.6841 - loss: 0.1182 - precision: 0.5034 - recall: 0.9898\n",
            "Epoch 14: val_auc did not improve from 0.66114\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5300 - auc: 0.6973 - loss: 0.1152 - precision: 0.5156 - recall: 0.9943 - val_accuracy: 0.5450 - val_auc: 0.5916 - val_loss: 0.1187 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5081 - auc: 0.6598 - loss: 0.1111 - precision: 0.4919 - recall: 0.9921\n",
            "Epoch 15: val_auc improved from 0.66114 to 0.73382, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5314 - auc: 0.6712 - loss: 0.1102 - precision: 0.5164 - recall: 0.9886 - val_accuracy: 0.5503 - val_auc: 0.7338 - val_loss: 0.1159 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5187 - auc: 0.6826 - loss: 0.1078 - precision: 0.5021 - recall: 0.9970\n",
            "Epoch 16: val_auc improved from 0.73382 to 0.77100, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5429 - auc: 0.6804 - loss: 0.1069 - precision: 0.5225 - recall: 0.9943 - val_accuracy: 0.5503 - val_auc: 0.7710 - val_loss: 0.1126 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5357 - auc: 0.6989 - loss: 0.1039 - precision: 0.5170 - recall: 0.9792\n",
            "Epoch 17: val_auc did not improve from 0.77100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5443 - auc: 0.6916 - loss: 0.1040 - precision: 0.5237 - recall: 0.9800 - val_accuracy: 0.5503 - val_auc: 0.6596 - val_loss: 0.1103 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5523 - auc: 0.7103 - loss: 0.1012 - precision: 0.5365 - recall: 0.9915\n",
            "Epoch 18: val_auc improved from 0.77100 to 0.79737, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5314 - auc: 0.6990 - loss: 0.1013 - precision: 0.5164 - recall: 0.9886 - val_accuracy: 0.5503 - val_auc: 0.7974 - val_loss: 0.1074 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5741 - auc: 0.7511 - loss: 0.0969 - precision: 0.5514 - recall: 0.9952\n",
            "Epoch 19: val_auc did not improve from 0.79737\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5429 - auc: 0.7185 - loss: 0.0983 - precision: 0.5227 - recall: 0.9886 - val_accuracy: 0.5503 - val_auc: 0.6896 - val_loss: 0.1055 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5178 - auc: 0.7302 - loss: 0.0970 - precision: 0.4963 - recall: 0.9986\n",
            "Epoch 20: val_auc did not improve from 0.79737\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5414 - auc: 0.7175 - loss: 0.0965 - precision: 0.5217 - recall: 0.9971 - val_accuracy: 0.5503 - val_auc: 0.6816 - val_loss: 0.1022 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5095 - auc: 0.6391 - loss: 0.0968 - precision: 0.4837 - recall: 0.9901\n",
            "Epoch 21: val_auc did not improve from 0.79737\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5443 - auc: 0.6644 - loss: 0.0950 - precision: 0.5235 - recall: 0.9857 - val_accuracy: 0.5503 - val_auc: 0.7814 - val_loss: 0.0988 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5117 - auc: 0.7166 - loss: 0.0928 - precision: 0.5000 - recall: 0.9807\n",
            "Epoch 22: val_auc did not improve from 0.79737\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5414 - auc: 0.7353 - loss: 0.0917 - precision: 0.5219 - recall: 0.9857 - val_accuracy: 0.5503 - val_auc: 0.7917 - val_loss: 0.0955 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5448 - auc: 0.7409 - loss: 0.0905 - precision: 0.5274 - recall: 0.9853\n",
            "Epoch 23: val_auc did not improve from 0.79737\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5443 - auc: 0.7086 - loss: 0.0913 - precision: 0.5234 - recall: 0.9886 - val_accuracy: 0.5503 - val_auc: 0.7707 - val_loss: 0.0941 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5650 - auc: 0.7416 - loss: 0.0870 - precision: 0.5491 - recall: 0.9956\n",
            "Epoch 24: val_auc improved from 0.79737 to 0.83684, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5443 - auc: 0.7100 - loss: 0.0880 - precision: 0.5234 - recall: 0.9914 - val_accuracy: 0.5503 - val_auc: 0.8368 - val_loss: 0.0942 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5634 - auc: 0.7364 - loss: 0.0857 - precision: 0.5474 - recall: 0.9973\n",
            "Epoch 25: val_auc did not improve from 0.83684\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5386 - auc: 0.7400 - loss: 0.0863 - precision: 0.5201 - recall: 0.9971 - val_accuracy: 0.5503 - val_auc: 0.8321 - val_loss: 0.0914 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5433 - auc: 0.7320 - loss: 0.0847 - precision: 0.5211 - recall: 0.9938\n",
            "Epoch 26: val_auc did not improve from 0.83684\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5543 - auc: 0.7002 - loss: 0.0855 - precision: 0.5291 - recall: 0.9857 - val_accuracy: 0.5503 - val_auc: 0.8145 - val_loss: 0.0881 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5347 - auc: 0.7602 - loss: 0.0820 - precision: 0.5131 - recall: 0.9930\n",
            "Epoch 27: val_auc did not improve from 0.83684\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5429 - auc: 0.7439 - loss: 0.0824 - precision: 0.5227 - recall: 0.9886 - val_accuracy: 0.5503 - val_auc: 0.8100 - val_loss: 0.0880 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5180 - auc: 0.7125 - loss: 0.0826 - precision: 0.4977 - recall: 0.9928\n",
            "Epoch 28: val_auc did not improve from 0.83684\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.5457 - auc: 0.7418 - loss: 0.0812 - precision: 0.5242 - recall: 0.9914 - val_accuracy: 0.5556 - val_auc: 0.8246 - val_loss: 0.0838 - val_precision: 0.5281 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5530 - auc: 0.7745 - loss: 0.0806 - precision: 0.5334 - recall: 0.9813\n",
            "Epoch 29: val_auc improved from 0.83684 to 0.85162, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.5457 - auc: 0.7541 - loss: 0.0805 - precision: 0.5242 - recall: 0.9886 - val_accuracy: 0.5608 - val_auc: 0.8516 - val_loss: 0.0848 - val_precision: 0.5311 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5635 - auc: 0.7213 - loss: 0.0790 - precision: 0.5428 - recall: 0.9919\n",
            "Epoch 30: val_auc did not improve from 0.85162\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5557 - auc: 0.7199 - loss: 0.0787 - precision: 0.5300 - recall: 0.9857 - val_accuracy: 0.5608 - val_auc: 0.8319 - val_loss: 0.0805 - val_precision: 0.5311 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5825 - auc: 0.7776 - loss: 0.0755 - precision: 0.5612 - recall: 1.0000\n",
            "Epoch 31: val_auc did not improve from 0.85162\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5500 - auc: 0.7619 - loss: 0.0760 - precision: 0.5264 - recall: 0.9971 - val_accuracy: 0.5608 - val_auc: 0.8469 - val_loss: 0.0778 - val_precision: 0.5311 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5877 - auc: 0.7716 - loss: 0.0733 - precision: 0.5638 - recall: 0.9955\n",
            "Epoch 32: val_auc improved from 0.85162 to 0.86792, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5600 - auc: 0.7507 - loss: 0.0752 - precision: 0.5324 - recall: 0.9857 - val_accuracy: 0.5608 - val_auc: 0.8679 - val_loss: 0.0788 - val_precision: 0.5311 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5803 - auc: 0.8077 - loss: 0.0716 - precision: 0.5348 - recall: 0.9906\n",
            "Epoch 33: val_auc did not improve from 0.86792\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5829 - auc: 0.7690 - loss: 0.0738 - precision: 0.5457 - recall: 0.9886 - val_accuracy: 0.5608 - val_auc: 0.8409 - val_loss: 0.0753 - val_precision: 0.5311 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5555 - auc: 0.7204 - loss: 0.0749 - precision: 0.5277 - recall: 0.9982\n",
            "Epoch 34: val_auc improved from 0.86792 to 0.87934, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.5586 - auc: 0.7392 - loss: 0.0734 - precision: 0.5312 - recall: 0.9971 - val_accuracy: 0.5608 - val_auc: 0.8793 - val_loss: 0.0781 - val_precision: 0.5311 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5784 - auc: 0.7649 - loss: 0.0723 - precision: 0.5338 - recall: 0.9911\n",
            "Epoch 35: val_auc did not improve from 0.87934\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.5929 - auc: 0.7603 - loss: 0.0719 - precision: 0.5518 - recall: 0.9886 - val_accuracy: 0.5608 - val_auc: 0.8344 - val_loss: 0.0732 - val_precision: 0.5311 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5803 - auc: 0.8067 - loss: 0.0682 - precision: 0.5462 - recall: 0.9905\n",
            "Epoch 36: val_auc did not improve from 0.87934\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.5786 - auc: 0.7695 - loss: 0.0700 - precision: 0.5433 - recall: 0.9857 - val_accuracy: 0.5608 - val_auc: 0.8612 - val_loss: 0.0753 - val_precision: 0.5311 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5646 - auc: 0.7835 - loss: 0.0690 - precision: 0.5316 - recall: 0.9885\n",
            "Epoch 37: val_auc did not improve from 0.87934\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5743 - auc: 0.7681 - loss: 0.0696 - precision: 0.5409 - recall: 0.9829 - val_accuracy: 0.5608 - val_auc: 0.8601 - val_loss: 0.0715 - val_precision: 0.5311 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5390 - auc: 0.7804 - loss: 0.0681 - precision: 0.5077 - recall: 0.9886\n",
            "Epoch 38: val_auc did not improve from 0.87934\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5757 - auc: 0.7317 - loss: 0.0703 - precision: 0.5424 - recall: 0.9686 - val_accuracy: 0.5608 - val_auc: 0.8663 - val_loss: 0.0694 - val_precision: 0.5311 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5764 - auc: 0.7765 - loss: 0.0671 - precision: 0.5490 - recall: 0.9952\n",
            "Epoch 39: val_auc did not improve from 0.87934\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5829 - auc: 0.7701 - loss: 0.0669 - precision: 0.5459 - recall: 0.9857 - val_accuracy: 0.5503 - val_auc: 0.8761 - val_loss: 0.0699 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5685 - auc: 0.7863 - loss: 0.0663 - precision: 0.5361 - recall: 0.9554\n",
            "Epoch 40: val_auc did not improve from 0.87934\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5700 - auc: 0.7681 - loss: 0.0664 - precision: 0.5387 - recall: 0.9743 - val_accuracy: 0.5556 - val_auc: 0.8393 - val_loss: 0.0678 - val_precision: 0.5284 - val_recall: 0.9894 - learning_rate: 5.0000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5733 - auc: 0.7582 - loss: 0.0661 - precision: 0.5398 - recall: 0.9861\n",
            "Epoch 41: val_auc did not improve from 0.87934\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.5800 - auc: 0.7737 - loss: 0.0656 - precision: 0.5446 - recall: 0.9771 - val_accuracy: 0.5608 - val_auc: 0.8649 - val_loss: 0.0674 - val_precision: 0.5314 - val_recall: 0.9894 - learning_rate: 5.0000e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5818 - auc: 0.7441 - loss: 0.0665 - precision: 0.5544 - recall: 0.9853\n",
            "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 42: val_auc did not improve from 0.87934\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5757 - auc: 0.7729 - loss: 0.0645 - precision: 0.5416 - recall: 0.9857 - val_accuracy: 0.5661 - val_auc: 0.8419 - val_loss: 0.0673 - val_precision: 0.5345 - val_recall: 0.9894 - learning_rate: 5.0000e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5941 - auc: 0.8015 - loss: 0.0636 - precision: 0.5556 - recall: 0.9735\n",
            "Epoch 43: val_auc did not improve from 0.87934\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.6057 - auc: 0.7880 - loss: 0.0630 - precision: 0.5605 - recall: 0.9800 - val_accuracy: 0.5661 - val_auc: 0.8372 - val_loss: 0.0665 - val_precision: 0.5345 - val_recall: 0.9894 - learning_rate: 2.5000e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5664 - auc: 0.7555 - loss: 0.0653 - precision: 0.5401 - recall: 0.9738\n",
            "Epoch 44: val_auc did not improve from 0.87934\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5857 - auc: 0.7571 - loss: 0.0652 - precision: 0.5484 - recall: 0.9714 - val_accuracy: 0.5661 - val_auc: 0.8691 - val_loss: 0.0673 - val_precision: 0.5345 - val_recall: 0.9894 - learning_rate: 2.5000e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6093 - auc: 0.7934 - loss: 0.0625 - precision: 0.5668 - recall: 0.9791\n",
            "Epoch 45: val_auc did not improve from 0.87934\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.6014 - auc: 0.7735 - loss: 0.0634 - precision: 0.5585 - recall: 0.9686 - val_accuracy: 0.5661 - val_auc: 0.8512 - val_loss: 0.0658 - val_precision: 0.5345 - val_recall: 0.9894 - learning_rate: 2.5000e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5805 - auc: 0.8216 - loss: 0.0618 - precision: 0.5526 - recall: 0.9778\n",
            "Epoch 46: val_auc did not improve from 0.87934\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5614 - auc: 0.7928 - loss: 0.0625 - precision: 0.5334 - recall: 0.9800 - val_accuracy: 0.5661 - val_auc: 0.8362 - val_loss: 0.0657 - val_precision: 0.5345 - val_recall: 0.9894 - learning_rate: 2.5000e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5819 - auc: 0.7726 - loss: 0.0633 - precision: 0.5317 - recall: 0.9681\n",
            "Epoch 47: val_auc did not improve from 0.87934\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5900 - auc: 0.7726 - loss: 0.0630 - precision: 0.5512 - recall: 0.9686 - val_accuracy: 0.5661 - val_auc: 0.8070 - val_loss: 0.0653 - val_precision: 0.5345 - val_recall: 0.9894 - learning_rate: 2.5000e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5581 - auc: 0.7846 - loss: 0.0620 - precision: 0.5200 - recall: 0.9645\n",
            "Epoch 48: val_auc did not improve from 0.87934\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.6014 - auc: 0.7844 - loss: 0.0615 - precision: 0.5589 - recall: 0.9629 - val_accuracy: 0.5661 - val_auc: 0.8086 - val_loss: 0.0648 - val_precision: 0.5345 - val_recall: 0.9894 - learning_rate: 2.5000e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6111 - auc: 0.7968 - loss: 0.0606 - precision: 0.5599 - recall: 0.9799\n",
            "Epoch 49: val_auc did not improve from 0.87934\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.5900 - auc: 0.8006 - loss: 0.0605 - precision: 0.5504 - recall: 0.9829 - val_accuracy: 0.5661 - val_auc: 0.8548 - val_loss: 0.0642 - val_precision: 0.5345 - val_recall: 0.9894 - learning_rate: 2.5000e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5679 - auc: 0.7766 - loss: 0.0623 - precision: 0.5374 - recall: 0.9606\n",
            "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 50: val_auc did not improve from 0.87934\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.6100 - auc: 0.7781 - loss: 0.0616 - precision: 0.5647 - recall: 0.9600 - val_accuracy: 0.5820 - val_auc: 0.8766 - val_loss: 0.0654 - val_precision: 0.5439 - val_recall: 0.9894 - learning_rate: 2.5000e-04\n",
            "Restoring model weights from the end of the best epoch: 34.\n",
            "\n",
            "======================================================================\n",
            "THRESHOLD OPTIMIZATION & EVALUATION\n",
            "======================================================================\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x723c1da63910> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "\n",
            "Optimal threshold: 0.5168 (default=0.5)\n",
            "  At this threshold: TPR=0.9149, FPR=0.2211\n",
            "\n",
            "Results:\n",
            "  AUC-ROC: 0.8842\n",
            "  Accuracy (default threshold=0.5): 0.5608 (56.08%)\n",
            "  Accuracy (optimal threshold=0.5168): 0.8466 (84.66%)\n",
            "\n",
            "With optimal threshold:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Non-Planet     0.9024    0.7789    0.8362        95\n",
            "      Planet     0.8037    0.9149    0.8557        94\n",
            "\n",
            "    accuracy                         0.8466       189\n",
            "   macro avg     0.8531    0.8469    0.8459       189\n",
            "weighted avg     0.8533    0.8466    0.8459       189\n",
            "\n",
            "\n",
            "Prediction distribution (optimal threshold):\n",
            "  Predicted 0: 82\n",
            "  Predicted 1: 107\n",
            "True distribution:\n",
            "  True 0: 95\n",
            "  True 1: 94\n",
            "\n",
            "Confusion matrix (optimal threshold):\n",
            "[[74 21]\n",
            " [ 8 86]]\n",
            "Precision (optimal threshold): 0.8037\n",
            "\n",
            "======================================================================\n",
            "VISUALIZATIONS\n",
            "======================================================================\n",
            "Saved: confusion_matrix_final.png\n",
            "Saved: training_history_final.png\n",
            "\n",
            "======================================================================\n",
            "PLOTTING LIGHTCURVES WITH PREDICTIONS (n=6)\n",
            "======================================================================\n",
            "Saved: sample_lightcurves_predictions.png\n",
            "\n",
            "======================================================================\n",
            "TRAINING CONFIGURATION: CNN_config2\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "TRAINING\n",
            "======================================================================\n",
            "Epoch 1/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.5018 - auc: 0.4658 - loss: 0.5171 - precision: 0.4925 - recall: 0.7172\n",
            "Epoch 1: val_auc improved from None to 0.54037, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 128ms/step - accuracy: 0.4971 - auc: 0.4755 - loss: 0.5060 - precision: 0.4983 - recall: 0.8600 - val_accuracy: 0.5185 - val_auc: 0.5404 - val_loss: 0.4802 - val_precision: 0.5081 - val_recall: 1.0000 - learning_rate: 3.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.4955 - auc: 0.5143 - loss: 0.4846 - precision: 0.4945 - recall: 0.9841 \n",
            "Epoch 2: val_auc did not improve from 0.54037\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.5100 - auc: 0.5412 - loss: 0.4707 - precision: 0.5052 - recall: 0.9800 - val_accuracy: 0.5397 - val_auc: 0.5363 - val_loss: 0.4535 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 3.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.5336 - auc: 0.6080 - loss: 0.4464 - precision: 0.5196 - recall: 0.9764\n",
            "Epoch 3: val_auc did not improve from 0.54037\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 117ms/step - accuracy: 0.5300 - auc: 0.5994 - loss: 0.4403 - precision: 0.5158 - recall: 0.9771 - val_accuracy: 0.5397 - val_auc: 0.4342 - val_loss: 0.4305 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 3.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.5336 - auc: 0.6355 - loss: 0.4198 - precision: 0.5066 - recall: 0.9886\n",
            "Epoch 4: val_auc did not improve from 0.54037\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.5486 - auc: 0.6146 - loss: 0.4169 - precision: 0.5262 - recall: 0.9771 - val_accuracy: 0.5397 - val_auc: 0.5267 - val_loss: 0.4072 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 3.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.5168 - auc: 0.6636 - loss: 0.4019 - precision: 0.5014 - recall: 0.9965\n",
            "Epoch 5: val_auc did not improve from 0.54037\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 117ms/step - accuracy: 0.5414 - auc: 0.6490 - loss: 0.3973 - precision: 0.5219 - recall: 0.9886 - val_accuracy: 0.5397 - val_auc: 0.5179 - val_loss: 0.3875 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 3.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.5682 - auc: 0.6650 - loss: 0.3780 - precision: 0.5503 - recall: 0.9758\n",
            "Epoch 6: val_auc improved from 0.54037 to 0.55442, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - accuracy: 0.5343 - auc: 0.6927 - loss: 0.3732 - precision: 0.5181 - recall: 0.9800 - val_accuracy: 0.5450 - val_auc: 0.5544 - val_loss: 0.3738 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 3.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.5519 - auc: 0.6723 - loss: 0.3634 - precision: 0.5355 - recall: 0.9845\n",
            "Epoch 7: val_auc did not improve from 0.55442\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 0.5586 - auc: 0.6677 - loss: 0.3621 - precision: 0.5318 - recall: 0.9800 - val_accuracy: 0.5450 - val_auc: 0.5472 - val_loss: 0.3574 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 3.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.5928 - auc: 0.6890 - loss: 0.3468 - precision: 0.5721 - recall: 0.9736\n",
            "Epoch 8: val_auc improved from 0.55442 to 0.77189, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - accuracy: 0.5514 - auc: 0.6653 - loss: 0.3451 - precision: 0.5280 - recall: 0.9714 - val_accuracy: 0.5450 - val_auc: 0.7719 - val_loss: 0.3442 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 3.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.5593 - auc: 0.7361 - loss: 0.3314 - precision: 0.5250 - recall: 0.9706\n",
            "Epoch 9: val_auc did not improve from 0.77189\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - accuracy: 0.5600 - auc: 0.7167 - loss: 0.3314 - precision: 0.5332 - recall: 0.9629 - val_accuracy: 0.5503 - val_auc: 0.7338 - val_loss: 0.3314 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 3.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.5423 - auc: 0.7266 - loss: 0.3191 - precision: 0.5213 - recall: 0.9922\n",
            "Epoch 10: val_auc did not improve from 0.77189\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - accuracy: 0.5400 - auc: 0.6994 - loss: 0.3194 - precision: 0.5214 - recall: 0.9743 - val_accuracy: 0.5608 - val_auc: 0.5244 - val_loss: 0.3215 - val_precision: 0.5314 - val_recall: 0.9894 - learning_rate: 3.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.5524 - auc: 0.6896 - loss: 0.3087 - precision: 0.5352 - recall: 0.9682\n",
            "Epoch 11: val_auc did not improve from 0.77189\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - accuracy: 0.5514 - auc: 0.7106 - loss: 0.3059 - precision: 0.5283 - recall: 0.9600 - val_accuracy: 0.5026 - val_auc: 0.4414 - val_loss: 0.3214 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 3.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.5492 - auc: 0.7230 - loss: 0.2944 - precision: 0.5277 - recall: 0.9855\n",
            "Epoch 12: val_auc did not improve from 0.77189\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.5643 - auc: 0.7337 - loss: 0.2911 - precision: 0.5350 - recall: 0.9829 - val_accuracy: 0.5344 - val_auc: 0.5539 - val_loss: 0.3071 - val_precision: 0.5195 - val_recall: 0.8511 - learning_rate: 3.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.5602 - auc: 0.7194 - loss: 0.2870 - precision: 0.5340 - recall: 0.9556\n",
            "Epoch 13: val_auc did not improve from 0.77189\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - accuracy: 0.5871 - auc: 0.7075 - loss: 0.2857 - precision: 0.5501 - recall: 0.9571 - val_accuracy: 0.5026 - val_auc: 0.5795 - val_loss: 0.3232 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 3.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.6118 - auc: 0.7735 - loss: 0.2749 - precision: 0.5708 - recall: 0.9482\n",
            "Epoch 14: val_auc did not improve from 0.77189\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.5700 - auc: 0.7259 - loss: 0.2762 - precision: 0.5388 - recall: 0.9714 - val_accuracy: 0.5026 - val_auc: 0.6365 - val_loss: 0.3044 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 3.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.6195 - auc: 0.7515 - loss: 0.2664 - precision: 0.5627 - recall: 0.9488\n",
            "Epoch 15: val_auc did not improve from 0.77189\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - accuracy: 0.6157 - auc: 0.7317 - loss: 0.2638 - precision: 0.5690 - recall: 0.9543 - val_accuracy: 0.5026 - val_auc: 0.4894 - val_loss: 0.3115 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 3.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.6094 - auc: 0.7418 - loss: 0.2577 - precision: 0.5750 - recall: 0.9674\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
            "\n",
            "Epoch 16: val_auc did not improve from 0.77189\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.5829 - auc: 0.7657 - loss: 0.2545 - precision: 0.5466 - recall: 0.9714 - val_accuracy: 0.5026 - val_auc: 0.5357 - val_loss: 0.2931 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 3.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.6038 - auc: 0.7719 - loss: 0.2480 - precision: 0.5617 - recall: 0.9731\n",
            "Epoch 17: val_auc did not improve from 0.77189\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - accuracy: 0.6129 - auc: 0.7705 - loss: 0.2480 - precision: 0.5666 - recall: 0.9600 - val_accuracy: 0.5079 - val_auc: 0.5862 - val_loss: 0.2819 - val_precision: 1.0000 - val_recall: 0.0106 - learning_rate: 1.5000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.5827 - auc: 0.7925 - loss: 0.2437 - precision: 0.5371 - recall: 0.9682\n",
            "Epoch 18: val_auc did not improve from 0.77189\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - accuracy: 0.5886 - auc: 0.7743 - loss: 0.2442 - precision: 0.5498 - recall: 0.9771 - val_accuracy: 0.5132 - val_auc: 0.6188 - val_loss: 0.2723 - val_precision: 0.7500 - val_recall: 0.0319 - learning_rate: 1.5000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.6056 - auc: 0.7657 - loss: 0.2449 - precision: 0.5566 - recall: 0.9828\n",
            "Epoch 19: val_auc did not improve from 0.77189\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - accuracy: 0.5986 - auc: 0.7741 - loss: 0.2434 - precision: 0.5563 - recall: 0.9743 - val_accuracy: 0.5132 - val_auc: 0.6139 - val_loss: 0.2711 - val_precision: 1.0000 - val_recall: 0.0213 - learning_rate: 1.5000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.6162 - auc: 0.7310 - loss: 0.2427 - precision: 0.5844 - recall: 0.9612\n",
            "Epoch 20: val_auc did not improve from 0.77189\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - accuracy: 0.5971 - auc: 0.7592 - loss: 0.2382 - precision: 0.5559 - recall: 0.9657 - val_accuracy: 0.5132 - val_auc: 0.5354 - val_loss: 0.2699 - val_precision: 1.0000 - val_recall: 0.0213 - learning_rate: 1.5000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.6134 - auc: 0.7094 - loss: 0.2394 - precision: 0.5915 - recall: 0.9220\n",
            "Epoch 21: val_auc did not improve from 0.77189\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - accuracy: 0.5929 - auc: 0.7392 - loss: 0.2370 - precision: 0.5548 - recall: 0.9400 - val_accuracy: 0.5132 - val_auc: 0.6373 - val_loss: 0.2666 - val_precision: 1.0000 - val_recall: 0.0213 - learning_rate: 1.5000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.6725 - auc: 0.7927 - loss: 0.2321 - precision: 0.6190 - recall: 0.8690\n",
            "Epoch 22: val_auc did not improve from 0.77189\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - accuracy: 0.6586 - auc: 0.7822 - loss: 0.2301 - precision: 0.6049 - recall: 0.9143 - val_accuracy: 0.5291 - val_auc: 0.6015 - val_loss: 0.2467 - val_precision: 0.5161 - val_recall: 0.8511 - learning_rate: 1.5000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.5917 - auc: 0.7542 - loss: 0.2304 - precision: 0.5518 - recall: 0.9839\n",
            "Epoch 23: val_auc did not improve from 0.77189\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - accuracy: 0.6143 - auc: 0.7686 - loss: 0.2272 - precision: 0.5669 - recall: 0.9686 - val_accuracy: 0.5079 - val_auc: 0.6002 - val_loss: 0.2473 - val_precision: 0.5037 - val_recall: 0.7234 - learning_rate: 1.5000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.6437 - auc: 0.7897 - loss: 0.2221 - precision: 0.5965 - recall: 0.9741\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
            "\n",
            "Epoch 24: val_auc did not improve from 0.77189\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.6071 - auc: 0.7798 - loss: 0.2225 - precision: 0.5614 - recall: 0.9800 - val_accuracy: 0.5450 - val_auc: 0.5907 - val_loss: 0.2376 - val_precision: 0.5250 - val_recall: 0.8936 - learning_rate: 1.5000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.6439 - auc: 0.7838 - loss: 0.2201 - precision: 0.6005 - recall: 0.9391\n",
            "Epoch 25: val_auc did not improve from 0.77189\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - accuracy: 0.6271 - auc: 0.7769 - loss: 0.2205 - precision: 0.5788 - recall: 0.9343 - val_accuracy: 0.5556 - val_auc: 0.5867 - val_loss: 0.2323 - val_precision: 0.5305 - val_recall: 0.9255 - learning_rate: 7.5000e-05\n",
            "Epoch 26/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.6336 - auc: 0.8213 - loss: 0.2163 - precision: 0.5960 - recall: 0.9516\n",
            "Epoch 26: val_auc did not improve from 0.77189\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - accuracy: 0.6057 - auc: 0.8116 - loss: 0.2168 - precision: 0.5611 - recall: 0.9714 - val_accuracy: 0.5608 - val_auc: 0.6764 - val_loss: 0.2310 - val_precision: 0.5333 - val_recall: 0.9362 - learning_rate: 7.5000e-05\n",
            "Epoch 27/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.6903 - auc: 0.7997 - loss: 0.2173 - precision: 0.6232 - recall: 0.9456\n",
            "Epoch 27: val_auc did not improve from 0.77189\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 0.6586 - auc: 0.7802 - loss: 0.2190 - precision: 0.6022 - recall: 0.9343 - val_accuracy: 0.5661 - val_auc: 0.6543 - val_loss: 0.2263 - val_precision: 0.5361 - val_recall: 0.9468 - learning_rate: 7.5000e-05\n",
            "Epoch 28/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.6118 - auc: 0.7957 - loss: 0.2170 - precision: 0.5579 - recall: 0.9533\n",
            "Epoch 28: val_auc did not improve from 0.77189\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - accuracy: 0.6357 - auc: 0.7823 - loss: 0.2168 - precision: 0.5835 - recall: 0.9486 - val_accuracy: 0.5767 - val_auc: 0.7018 - val_loss: 0.2219 - val_precision: 0.5407 - val_recall: 0.9894 - learning_rate: 7.5000e-05\n",
            "Epoch 28: early stopping\n",
            "Restoring model weights from the end of the best epoch: 8.\n",
            "\n",
            "======================================================================\n",
            "THRESHOLD OPTIMIZATION & EVALUATION\n",
            "======================================================================\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x723be2f56f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "\n",
            "Optimal threshold: 0.5374 (default=0.5)\n",
            "  At this threshold: TPR=0.8511, FPR=0.2211\n",
            "\n",
            "Results:\n",
            "  AUC-ROC: 0.8442\n",
            "  Accuracy (default threshold=0.5): 0.5450 (54.50%)\n",
            "  Accuracy (optimal threshold=0.5374): 0.8148 (81.48%)\n",
            "\n",
            "With optimal threshold:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Non-Planet     0.8409    0.7789    0.8087        95\n",
            "      Planet     0.7921    0.8511    0.8205        94\n",
            "\n",
            "    accuracy                         0.8148       189\n",
            "   macro avg     0.8165    0.8150    0.8146       189\n",
            "weighted avg     0.8166    0.8148    0.8146       189\n",
            "\n",
            "\n",
            "Prediction distribution (optimal threshold):\n",
            "  Predicted 0: 88\n",
            "  Predicted 1: 101\n",
            "True distribution:\n",
            "  True 0: 95\n",
            "  True 1: 94\n",
            "\n",
            "Confusion matrix (optimal threshold):\n",
            "[[74 21]\n",
            " [14 80]]\n",
            "Precision (optimal threshold): 0.7921\n",
            "\n",
            "======================================================================\n",
            "VISUALIZATIONS\n",
            "======================================================================\n",
            "Saved: confusion_matrix_final.png\n",
            "Saved: training_history_final.png\n",
            "\n",
            "======================================================================\n",
            "PLOTTING LIGHTCURVES WITH PREDICTIONS (n=6)\n",
            "======================================================================\n",
            "Saved: sample_lightcurves_predictions.png\n",
            "\n",
            "======================================================================\n",
            "TRAINING CONFIGURATION: CNN_config3\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "TRAINING\n",
            "======================================================================\n",
            "Epoch 1/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.4921 - auc: 0.4693 - loss: 0.4601 - precision: 0.4525 - recall: 0.6472\n",
            "Epoch 1: val_auc improved from None to 0.55941, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 0.5214 - auc: 0.4998 - loss: 0.4510 - precision: 0.5133 - recall: 0.8286 - val_accuracy: 0.5450 - val_auc: 0.5594 - val_loss: 0.4202 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5278 - auc: 0.4636 - loss: 0.4187 - precision: 0.5336 - recall: 0.8937\n",
            "Epoch 2: val_auc did not improve from 0.55941\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.5186 - auc: 0.5252 - loss: 0.4066 - precision: 0.5100 - recall: 0.9514 - val_accuracy: 0.5397 - val_auc: 0.5546 - val_loss: 0.3831 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5387 - auc: 0.5509 - loss: 0.3764 - precision: 0.5242 - recall: 0.9646\n",
            "Epoch 3: val_auc did not improve from 0.55941\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.5343 - auc: 0.5691 - loss: 0.3715 - precision: 0.5185 - recall: 0.9629 - val_accuracy: 0.5397 - val_auc: 0.5483 - val_loss: 0.3516 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5496 - auc: 0.6119 - loss: 0.3470 - precision: 0.5290 - recall: 0.9926\n",
            "Epoch 4: val_auc did not improve from 0.55941\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.5314 - auc: 0.6029 - loss: 0.3453 - precision: 0.5166 - recall: 0.9800 - val_accuracy: 0.5397 - val_auc: 0.5314 - val_loss: 0.3241 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5059 - auc: 0.5757 - loss: 0.3181 - precision: 0.4941 - recall: 0.9886\n",
            "Epoch 5: val_auc did not improve from 0.55941\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.5229 - auc: 0.5911 - loss: 0.3107 - precision: 0.5118 - recall: 0.9886 - val_accuracy: 0.5397 - val_auc: 0.5588 - val_loss: 0.3001 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5371 - auc: 0.5870 - loss: 0.2927 - precision: 0.5257 - recall: 0.9811\n",
            "Epoch 6: val_auc did not improve from 0.55941\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.5243 - auc: 0.5835 - loss: 0.2888 - precision: 0.5127 - recall: 0.9771 - val_accuracy: 0.5397 - val_auc: 0.5474 - val_loss: 0.2787 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5652 - auc: 0.5995 - loss: 0.2718 - precision: 0.5458 - recall: 0.9753\n",
            "Epoch 7: val_auc improved from 0.55941 to 0.58981, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.5443 - auc: 0.6155 - loss: 0.2682 - precision: 0.5237 - recall: 0.9800 - val_accuracy: 0.5132 - val_auc: 0.5898 - val_loss: 0.2597 - val_precision: 0.5054 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.4966 - auc: 0.5976 - loss: 0.2536 - precision: 0.4852 - recall: 0.9885\n",
            "Epoch 8: val_auc did not improve from 0.58981\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.5200 - auc: 0.5939 - loss: 0.2506 - precision: 0.5104 - recall: 0.9857 - val_accuracy: 0.5238 - val_auc: 0.5317 - val_loss: 0.2427 - val_precision: 0.5109 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5000 - auc: 0.6495 - loss: 0.2342 - precision: 0.4855 - recall: 0.9920\n",
            "Epoch 9: val_auc did not improve from 0.58981\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.5343 - auc: 0.6311 - loss: 0.2313 - precision: 0.5180 - recall: 0.9857 - val_accuracy: 0.5344 - val_auc: 0.5684 - val_loss: 0.2273 - val_precision: 0.5165 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5417 - auc: 0.6101 - loss: 0.2198 - precision: 0.5249 - recall: 0.9797\n",
            "Epoch 10: val_auc did not improve from 0.58981\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.5371 - auc: 0.6173 - loss: 0.2166 - precision: 0.5196 - recall: 0.9857 - val_accuracy: 0.5185 - val_auc: 0.5684 - val_loss: 0.2137 - val_precision: 0.5081 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5318 - auc: 0.6298 - loss: 0.2077 - precision: 0.5119 - recall: 0.9926\n",
            "Epoch 11: val_auc improved from 0.58981 to 0.65666, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.5257 - auc: 0.6406 - loss: 0.2045 - precision: 0.5133 - recall: 0.9914 - val_accuracy: 0.5132 - val_auc: 0.6567 - val_loss: 0.2013 - val_precision: 0.5054 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5492 - auc: 0.5629 - loss: 0.1943 - precision: 0.5330 - recall: 0.9974\n",
            "Epoch 12: val_auc did not improve from 0.65666\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.5300 - auc: 0.5974 - loss: 0.1915 - precision: 0.5156 - recall: 0.9914 - val_accuracy: 0.5344 - val_auc: 0.6279 - val_loss: 0.1899 - val_precision: 0.5165 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5519 - auc: 0.5866 - loss: 0.1830 - precision: 0.5320 - recall: 0.9906\n",
            "Epoch 13: val_auc did not improve from 0.65666\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5314 - auc: 0.5964 - loss: 0.1807 - precision: 0.5164 - recall: 0.9886 - val_accuracy: 0.5185 - val_auc: 0.5526 - val_loss: 0.1793 - val_precision: 0.5081 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5336 - auc: 0.6697 - loss: 0.1713 - precision: 0.5091 - recall: 0.9964\n",
            "Epoch 14: val_auc did not improve from 0.65666\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5371 - auc: 0.6549 - loss: 0.1695 - precision: 0.5193 - recall: 0.9971 - val_accuracy: 0.5397 - val_auc: 0.5574 - val_loss: 0.1696 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5381 - auc: 0.6445 - loss: 0.1621 - precision: 0.5160 - recall: 0.9900\n",
            "Epoch 15: val_auc did not improve from 0.65666\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.5386 - auc: 0.6550 - loss: 0.1601 - precision: 0.5204 - recall: 0.9857 - val_accuracy: 0.5397 - val_auc: 0.5859 - val_loss: 0.1608 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5478 - auc: 0.6159 - loss: 0.1542 - precision: 0.5287 - recall: 1.0000\n",
            "Epoch 16: val_auc did not improve from 0.65666\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.5443 - auc: 0.6296 - loss: 0.1521 - precision: 0.5232 - recall: 0.9971 - val_accuracy: 0.5397 - val_auc: 0.6100 - val_loss: 0.1521 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5246 - auc: 0.6498 - loss: 0.1470 - precision: 0.5131 - recall: 0.9891\n",
            "Epoch 17: val_auc did not improve from 0.65666\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.5271 - auc: 0.6257 - loss: 0.1453 - precision: 0.5142 - recall: 0.9857 - val_accuracy: 0.5397 - val_auc: 0.6045 - val_loss: 0.1445 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5243 - auc: 0.6479 - loss: 0.1391 - precision: 0.5146 - recall: 0.9930\n",
            "Epoch 18: val_auc improved from 0.65666 to 0.67878, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.5200 - auc: 0.6441 - loss: 0.1375 - precision: 0.5104 - recall: 0.9857 - val_accuracy: 0.5397 - val_auc: 0.6788 - val_loss: 0.1373 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5461 - auc: 0.6685 - loss: 0.1314 - precision: 0.5297 - recall: 1.0000\n",
            "Epoch 19: val_auc improved from 0.67878 to 0.78970, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.5329 - auc: 0.6503 - loss: 0.1305 - precision: 0.5170 - recall: 1.0000 - val_accuracy: 0.5397 - val_auc: 0.7897 - val_loss: 0.1307 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.4905 - auc: 0.6588 - loss: 0.1260 - precision: 0.4731 - recall: 0.9923\n",
            "Epoch 20: val_auc did not improve from 0.78970\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.5300 - auc: 0.6752 - loss: 0.1241 - precision: 0.5156 - recall: 0.9914 - val_accuracy: 0.5397 - val_auc: 0.6400 - val_loss: 0.1234 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5492 - auc: 0.6884 - loss: 0.1189 - precision: 0.5330 - recall: 1.0000\n",
            "Epoch 21: val_auc did not improve from 0.78970\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.5371 - auc: 0.6854 - loss: 0.1177 - precision: 0.5193 - recall: 1.0000 - val_accuracy: 0.5397 - val_auc: 0.6569 - val_loss: 0.1182 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5374 - auc: 0.7170 - loss: 0.1134 - precision: 0.5285 - recall: 0.9881\n",
            "Epoch 22: val_auc did not improve from 0.78970\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.5257 - auc: 0.7110 - loss: 0.1122 - precision: 0.5133 - recall: 0.9943 - val_accuracy: 0.5450 - val_auc: 0.7512 - val_loss: 0.1135 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5351 - auc: 0.7197 - loss: 0.1080 - precision: 0.5164 - recall: 0.9990\n",
            "Epoch 23: val_auc did not improve from 0.78970\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.5357 - auc: 0.6980 - loss: 0.1073 - precision: 0.5186 - recall: 0.9971 - val_accuracy: 0.5450 - val_auc: 0.7835 - val_loss: 0.1076 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5314 - auc: 0.6903 - loss: 0.1041 - precision: 0.5145 - recall: 0.9987\n",
            "Epoch 24: val_auc did not improve from 0.78970\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.5329 - auc: 0.6960 - loss: 0.1037 - precision: 0.5170 - recall: 0.9971 - val_accuracy: 0.5185 - val_auc: 0.7800 - val_loss: 0.1035 - val_precision: 0.5081 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5166 - auc: 0.7143 - loss: 0.0993 - precision: 0.5074 - recall: 0.9994\n",
            "Epoch 25: val_auc improved from 0.78970 to 0.83387, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5186 - auc: 0.7076 - loss: 0.0992 - precision: 0.5095 - recall: 0.9971 - val_accuracy: 0.5450 - val_auc: 0.8339 - val_loss: 0.0991 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5317 - auc: 0.6614 - loss: 0.0969 - precision: 0.5126 - recall: 0.9971\n",
            "Epoch 26: val_auc improved from 0.83387 to 0.83707, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.5300 - auc: 0.6750 - loss: 0.0960 - precision: 0.5156 - recall: 0.9914 - val_accuracy: 0.5397 - val_auc: 0.8371 - val_loss: 0.0938 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5084 - auc: 0.6805 - loss: 0.0921 - precision: 0.4944 - recall: 0.9975\n",
            "Epoch 27: val_auc improved from 0.83707 to 0.83903, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.5243 - auc: 0.6753 - loss: 0.0910 - precision: 0.5125 - recall: 0.9971 - val_accuracy: 0.5450 - val_auc: 0.8390 - val_loss: 0.0900 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5092 - auc: 0.6776 - loss: 0.0883 - precision: 0.4924 - recall: 0.9965\n",
            "Epoch 28: val_auc did not improve from 0.83903\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.5343 - auc: 0.6699 - loss: 0.0875 - precision: 0.5179 - recall: 0.9914 - val_accuracy: 0.5450 - val_auc: 0.8197 - val_loss: 0.0857 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5376 - auc: 0.6727 - loss: 0.0848 - precision: 0.5210 - recall: 0.9928\n",
            "Epoch 29: val_auc did not improve from 0.83903\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.5329 - auc: 0.7169 - loss: 0.0834 - precision: 0.5171 - recall: 0.9914 - val_accuracy: 0.5450 - val_auc: 0.7961 - val_loss: 0.0846 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5026 - auc: 0.6492 - loss: 0.0833 - precision: 0.4884 - recall: 0.9975\n",
            "Epoch 30: val_auc did not improve from 0.83903\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.5229 - auc: 0.6713 - loss: 0.0819 - precision: 0.5118 - recall: 0.9914 - val_accuracy: 0.5397 - val_auc: 0.8291 - val_loss: 0.0808 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5282 - auc: 0.7233 - loss: 0.0778 - precision: 0.5153 - recall: 0.9976\n",
            "Epoch 31: val_auc did not improve from 0.83903\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.5243 - auc: 0.7084 - loss: 0.0774 - precision: 0.5125 - recall: 0.9971 - val_accuracy: 0.5397 - val_auc: 0.8197 - val_loss: 0.0783 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5136 - auc: 0.7169 - loss: 0.0753 - precision: 0.4905 - recall: 0.9980\n",
            "Epoch 32: val_auc did not improve from 0.83903\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.5371 - auc: 0.7094 - loss: 0.0750 - precision: 0.5193 - recall: 0.9971 - val_accuracy: 0.5397 - val_auc: 0.8227 - val_loss: 0.0753 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5164 - auc: 0.6736 - loss: 0.0740 - precision: 0.5016 - recall: 1.0000\n",
            "Epoch 33: val_auc improved from 0.83903 to 0.85521, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.5314 - auc: 0.7009 - loss: 0.0725 - precision: 0.5162 - recall: 1.0000 - val_accuracy: 0.5397 - val_auc: 0.8552 - val_loss: 0.0717 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5365 - auc: 0.7310 - loss: 0.0693 - precision: 0.5192 - recall: 0.9986\n",
            "Epoch 34: val_auc did not improve from 0.85521\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.5257 - auc: 0.7247 - loss: 0.0694 - precision: 0.5133 - recall: 0.9943 - val_accuracy: 0.5397 - val_auc: 0.8418 - val_loss: 0.0700 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5523 - auc: 0.6914 - loss: 0.0675 - precision: 0.5339 - recall: 0.9968\n",
            "Epoch 35: val_auc did not improve from 0.85521\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.5300 - auc: 0.6847 - loss: 0.0675 - precision: 0.5156 - recall: 0.9943 - val_accuracy: 0.5450 - val_auc: 0.8418 - val_loss: 0.0676 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5367 - auc: 0.7059 - loss: 0.0654 - precision: 0.5159 - recall: 0.9942\n",
            "Epoch 36: val_auc did not improve from 0.85521\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.5314 - auc: 0.7049 - loss: 0.0653 - precision: 0.5164 - recall: 0.9914 - val_accuracy: 0.5291 - val_auc: 0.8417 - val_loss: 0.0642 - val_precision: 0.5137 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5066 - auc: 0.7110 - loss: 0.0639 - precision: 0.4920 - recall: 0.9993\n",
            "Epoch 37: val_auc did not improve from 0.85521\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.5243 - auc: 0.7182 - loss: 0.0632 - precision: 0.5125 - recall: 0.9971 - val_accuracy: 0.5397 - val_auc: 0.7943 - val_loss: 0.0624 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5273 - auc: 0.7049 - loss: 0.0617 - precision: 0.5111 - recall: 0.9978\n",
            "Epoch 38: val_auc improved from 0.85521 to 0.86209, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.5343 - auc: 0.7370 - loss: 0.0606 - precision: 0.5178 - recall: 0.9971 - val_accuracy: 0.5397 - val_auc: 0.8621 - val_loss: 0.0600 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5204 - auc: 0.7042 - loss: 0.0600 - precision: 0.5027 - recall: 0.9872\n",
            "Epoch 39: val_auc did not improve from 0.86209\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.5371 - auc: 0.7135 - loss: 0.0590 - precision: 0.5194 - recall: 0.9943 - val_accuracy: 0.5450 - val_auc: 0.8448 - val_loss: 0.0581 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5618 - auc: 0.7280 - loss: 0.0577 - precision: 0.5480 - recall: 0.9928\n",
            "Epoch 40: val_auc did not improve from 0.86209\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5343 - auc: 0.7404 - loss: 0.0573 - precision: 0.5179 - recall: 0.9943 - val_accuracy: 0.5397 - val_auc: 0.8255 - val_loss: 0.0588 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5273 - auc: 0.7391 - loss: 0.0558 - precision: 0.5110 - recall: 0.9993\n",
            "Epoch 41: val_auc did not improve from 0.86209\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.5300 - auc: 0.7313 - loss: 0.0554 - precision: 0.5155 - recall: 0.9971 - val_accuracy: 0.5450 - val_auc: 0.8466 - val_loss: 0.0560 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5246 - auc: 0.7068 - loss: 0.0546 - precision: 0.5072 - recall: 0.9991\n",
            "Epoch 42: val_auc did not improve from 0.86209\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.5386 - auc: 0.7060 - loss: 0.0542 - precision: 0.5201 - recall: 0.9971 - val_accuracy: 0.5397 - val_auc: 0.8419 - val_loss: 0.0545 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5281 - auc: 0.7170 - loss: 0.0534 - precision: 0.5114 - recall: 0.9986\n",
            "Epoch 43: val_auc did not improve from 0.86209\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5343 - auc: 0.7197 - loss: 0.0528 - precision: 0.5179 - recall: 0.9943 - val_accuracy: 0.5397 - val_auc: 0.8464 - val_loss: 0.0522 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5213 - auc: 0.7037 - loss: 0.0520 - precision: 0.5099 - recall: 0.9964\n",
            "Epoch 44: val_auc did not improve from 0.86209\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.5271 - auc: 0.7254 - loss: 0.0514 - precision: 0.5140 - recall: 0.9943 - val_accuracy: 0.5450 - val_auc: 0.8525 - val_loss: 0.0513 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5538 - auc: 0.6925 - loss: 0.0507 - precision: 0.5432 - recall: 0.9907\n",
            "Epoch 45: val_auc did not improve from 0.86209\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.5271 - auc: 0.6900 - loss: 0.0505 - precision: 0.5140 - recall: 0.9971 - val_accuracy: 0.5344 - val_auc: 0.8456 - val_loss: 0.0498 - val_precision: 0.5165 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5179 - auc: 0.6718 - loss: 0.0504 - precision: 0.4970 - recall: 0.9904\n",
            "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 46: val_auc did not improve from 0.86209\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.5386 - auc: 0.6734 - loss: 0.0499 - precision: 0.5202 - recall: 0.9914 - val_accuracy: 0.5344 - val_auc: 0.8377 - val_loss: 0.0486 - val_precision: 0.5165 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5343 - auc: 0.7076 - loss: 0.0485 - precision: 0.5158 - recall: 0.9976\n",
            "Epoch 47: val_auc did not improve from 0.86209\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.5357 - auc: 0.7087 - loss: 0.0483 - precision: 0.5186 - recall: 0.9971 - val_accuracy: 0.5397 - val_auc: 0.8160 - val_loss: 0.0483 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5353 - auc: 0.6242 - loss: 0.0495 - precision: 0.5149 - recall: 0.9882\n",
            "Epoch 48: val_auc did not improve from 0.86209\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.5343 - auc: 0.6743 - loss: 0.0483 - precision: 0.5178 - recall: 0.9971 - val_accuracy: 0.5450 - val_auc: 0.8272 - val_loss: 0.0474 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5265 - auc: 0.7135 - loss: 0.0480 - precision: 0.5062 - recall: 0.9912\n",
            "Epoch 49: val_auc did not improve from 0.86209\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.5429 - auc: 0.7276 - loss: 0.0469 - precision: 0.5226 - recall: 0.9914 - val_accuracy: 0.5450 - val_auc: 0.8114 - val_loss: 0.0471 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5201 - auc: 0.7372 - loss: 0.0464 - precision: 0.5003 - recall: 0.9921\n",
            "Epoch 50: val_auc did not improve from 0.86209\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.5386 - auc: 0.7284 - loss: 0.0462 - precision: 0.5201 - recall: 0.9971 - val_accuracy: 0.5450 - val_auc: 0.8578 - val_loss: 0.0461 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Restoring model weights from the end of the best epoch: 38.\n",
            "\n",
            "======================================================================\n",
            "THRESHOLD OPTIMIZATION & EVALUATION\n",
            "======================================================================\n",
            "\n",
            "Optimal threshold: 0.5764 (default=0.5)\n",
            "  At this threshold: TPR=0.8723, FPR=0.2211\n",
            "\n",
            "Results:\n",
            "  AUC-ROC: 0.8731\n",
            "  Accuracy (default threshold=0.5): 0.5397 (53.97%)\n",
            "  Accuracy (optimal threshold=0.5764): 0.8254 (82.54%)\n",
            "\n",
            "With optimal threshold:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Non-Planet     0.8605    0.7789    0.8177        95\n",
            "      Planet     0.7961    0.8723    0.8325        94\n",
            "\n",
            "    accuracy                         0.8254       189\n",
            "   macro avg     0.8283    0.8256    0.8251       189\n",
            "weighted avg     0.8285    0.8254    0.8250       189\n",
            "\n",
            "\n",
            "Prediction distribution (optimal threshold):\n",
            "  Predicted 0: 86\n",
            "  Predicted 1: 103\n",
            "True distribution:\n",
            "  True 0: 95\n",
            "  True 1: 94\n",
            "\n",
            "Confusion matrix (optimal threshold):\n",
            "[[74 21]\n",
            " [12 82]]\n",
            "Precision (optimal threshold): 0.7961\n",
            "\n",
            "======================================================================\n",
            "VISUALIZATIONS\n",
            "======================================================================\n",
            "Saved: confusion_matrix_final.png\n",
            "Saved: training_history_final.png\n",
            "\n",
            "======================================================================\n",
            "PLOTTING LIGHTCURVES WITH PREDICTIONS (n=6)\n",
            "======================================================================\n",
            "Saved: sample_lightcurves_predictions.png\n"
          ]
        }
      ],
      "source": [
        "#task F\n",
        "from sklearn.metrics import confusion_matrix, precision_score\n",
        "\n",
        "EPOCHS = 50   # you can increase if you have time/GPU\n",
        "\n",
        "configs = [\n",
        "    (\"CNN_default\",    build_simple_cnn),\n",
        "    (\"CNN_config1\",    build_cnn_config1),\n",
        "    (\"CNN_config2\",    build_cnn_config2),\n",
        "    (\"CNN_config3\",    build_cnn_config3),\n",
        "]\n",
        "\n",
        "all_results = []\n",
        "\n",
        "for name, builder in configs:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"TRAINING CONFIGURATION: {name}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # 1) build model\n",
        "    model = builder(n_bins=N_BINS)\n",
        "\n",
        "    # 2) train\n",
        "    history = train_model(model, X_train, y_train, X_test, y_test, epochs=EPOCHS)\n",
        "\n",
        "    # 3) evaluate with optimal threshold (returns y_pred for that threshold)\n",
        "    y_pred_opt, y_proba_test, best_thresh = evaluate_with_optimal_threshold(\n",
        "        model, X_test, y_test\n",
        "    )\n",
        "\n",
        "    # 4) confusion matrix + precision at this optimal threshold\n",
        "    cm = confusion_matrix(y_test, y_pred_opt)\n",
        "    precision = precision_score(y_test, y_pred_opt, zero_division=0)\n",
        "\n",
        "    print(\"\\nConfusion matrix (optimal threshold):\")\n",
        "    print(cm)\n",
        "    print(f\"Precision (optimal threshold): {precision:.4f}\")\n",
        "\n",
        "    # Save for the text report\n",
        "    all_results.append((name, best_thresh, cm, precision))\n",
        "\n",
        "    # (Optional) save plots for this config\n",
        "    plot_all(\n",
        "        y_test, y_pred_opt, y_proba_test, history,\n",
        "        metadata_test, X_test, best_thresh,\n",
        "        X_test_orig=X_test_orig, X_err_test=X_err_test, scaler=scaler\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "9d20cabc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "TRAINING\n",
            "======================================================================\n",
            "Epoch 1/200\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5161 - auc: 0.7133 - loss: 0.0599 - precision: 0.5012 - recall: 0.9942\n",
            "Epoch 1: val_auc improved from None to 0.85705, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5257 - auc: 0.7141 - loss: 0.0599 - precision: 0.5133 - recall: 0.9914 - val_accuracy: 0.5397 - val_auc: 0.8571 - val_loss: 0.0590 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5512 - auc: 0.7304 - loss: 0.0583 - precision: 0.5389 - recall: 0.9894\n",
            "Epoch 2: val_auc did not improve from 0.85705\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5329 - auc: 0.7260 - loss: 0.0583 - precision: 0.5171 - recall: 0.9943 - val_accuracy: 0.5397 - val_auc: 0.8558 - val_loss: 0.0579 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5387 - auc: 0.7081 - loss: 0.0578 - precision: 0.5216 - recall: 0.9996\n",
            "Epoch 3: val_auc improved from 0.85705 to 0.85795, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5357 - auc: 0.7105 - loss: 0.0576 - precision: 0.5186 - recall: 0.9971 - val_accuracy: 0.5450 - val_auc: 0.8580 - val_loss: 0.0568 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5118 - auc: 0.7268 - loss: 0.0567 - precision: 0.4865 - recall: 0.9947\n",
            "Epoch 4: val_auc did not improve from 0.85795\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.5386 - auc: 0.7034 - loss: 0.0567 - precision: 0.5202 - recall: 0.9914 - val_accuracy: 0.5450 - val_auc: 0.8420 - val_loss: 0.0561 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5505 - auc: 0.7562 - loss: 0.0548 - precision: 0.5296 - recall: 0.9952\n",
            "Epoch 5: val_auc did not improve from 0.85795\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5386 - auc: 0.7355 - loss: 0.0549 - precision: 0.5202 - recall: 0.9943 - val_accuracy: 0.5450 - val_auc: 0.8508 - val_loss: 0.0549 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5178 - auc: 0.7605 - loss: 0.0540 - precision: 0.5020 - recall: 0.9908\n",
            "Epoch 6: val_auc did not improve from 0.85795\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.5314 - auc: 0.7269 - loss: 0.0544 - precision: 0.5164 - recall: 0.9886 - val_accuracy: 0.5450 - val_auc: 0.8501 - val_loss: 0.0545 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5496 - auc: 0.7169 - loss: 0.0537 - precision: 0.5310 - recall: 0.9987\n",
            "Epoch 7: val_auc did not improve from 0.85795\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.5357 - auc: 0.7148 - loss: 0.0537 - precision: 0.5186 - recall: 0.9971 - val_accuracy: 0.5450 - val_auc: 0.8438 - val_loss: 0.0546 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.5087 - auc: 0.7571 - loss: 0.0525 - precision: 0.4943 - recall: 0.9968\n",
            "Epoch 8: val_auc improved from 0.85795 to 0.86120, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.5271 - auc: 0.7439 - loss: 0.0525 - precision: 0.5140 - recall: 0.9971 - val_accuracy: 0.5397 - val_auc: 0.8612 - val_loss: 0.0523 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.5008 - auc: 0.7270 - loss: 0.0520 - precision: 0.4773 - recall: 1.0000\n",
            "Epoch 9: val_auc did not improve from 0.86120\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.5371 - auc: 0.7083 - loss: 0.0520 - precision: 0.5193 - recall: 1.0000 - val_accuracy: 0.5450 - val_auc: 0.8570 - val_loss: 0.0514 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5011 - auc: 0.7293 - loss: 0.0513 - precision: 0.4857 - recall: 0.9930\n",
            "Epoch 10: val_auc improved from 0.86120 to 0.86411, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.5300 - auc: 0.7429 - loss: 0.0511 - precision: 0.5156 - recall: 0.9914 - val_accuracy: 0.5450 - val_auc: 0.8641 - val_loss: 0.0507 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5568 - auc: 0.7079 - loss: 0.0514 - precision: 0.5469 - recall: 0.9927\n",
            "Epoch 11: val_auc did not improve from 0.86411\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.5314 - auc: 0.7307 - loss: 0.0501 - precision: 0.5163 - recall: 0.9943 - val_accuracy: 0.5397 - val_auc: 0.8616 - val_loss: 0.0497 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5146 - auc: 0.7670 - loss: 0.0491 - precision: 0.4957 - recall: 0.9879\n",
            "Epoch 12: val_auc did not improve from 0.86411\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5386 - auc: 0.7452 - loss: 0.0495 - precision: 0.5202 - recall: 0.9914 - val_accuracy: 0.5450 - val_auc: 0.8578 - val_loss: 0.0489 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5510 - auc: 0.7030 - loss: 0.0489 - precision: 0.5351 - recall: 0.9941\n",
            "Epoch 13: val_auc did not improve from 0.86411\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5386 - auc: 0.7200 - loss: 0.0485 - precision: 0.5201 - recall: 0.9971 - val_accuracy: 0.5450 - val_auc: 0.8529 - val_loss: 0.0482 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5622 - auc: 0.7514 - loss: 0.0473 - precision: 0.5422 - recall: 0.9993\n",
            "Epoch 14: val_auc did not improve from 0.86411\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.5386 - auc: 0.7649 - loss: 0.0471 - precision: 0.5201 - recall: 0.9971 - val_accuracy: 0.5450 - val_auc: 0.8371 - val_loss: 0.0499 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5120 - auc: 0.6725 - loss: 0.0485 - precision: 0.4902 - recall: 0.9880\n",
            "Epoch 15: val_auc did not improve from 0.86411\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5386 - auc: 0.7154 - loss: 0.0474 - precision: 0.5202 - recall: 0.9943 - val_accuracy: 0.5450 - val_auc: 0.8527 - val_loss: 0.0467 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5915 - auc: 0.7329 - loss: 0.0461 - precision: 0.5749 - recall: 0.9950\n",
            "Epoch 16: val_auc did not improve from 0.86411\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.5386 - auc: 0.7114 - loss: 0.0472 - precision: 0.5202 - recall: 0.9914 - val_accuracy: 0.5450 - val_auc: 0.8630 - val_loss: 0.0465 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5038 - auc: 0.7203 - loss: 0.0467 - precision: 0.4897 - recall: 0.9926\n",
            "Epoch 17: val_auc did not improve from 0.86411\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.5286 - auc: 0.7290 - loss: 0.0463 - precision: 0.5149 - recall: 0.9886 - val_accuracy: 0.5397 - val_auc: 0.8374 - val_loss: 0.0460 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5374 - auc: 0.7443 - loss: 0.0455 - precision: 0.5226 - recall: 0.9916\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 18: val_auc did not improve from 0.86411\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.5286 - auc: 0.7359 - loss: 0.0457 - precision: 0.5148 - recall: 0.9943 - val_accuracy: 0.5397 - val_auc: 0.8261 - val_loss: 0.0458 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5062 - auc: 0.7569 - loss: 0.0448 - precision: 0.4887 - recall: 0.9978\n",
            "Epoch 19: val_auc did not improve from 0.86411\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.5314 - auc: 0.7476 - loss: 0.0447 - precision: 0.5163 - recall: 0.9971 - val_accuracy: 0.5397 - val_auc: 0.8521 - val_loss: 0.0446 - val_precision: 0.5193 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5370 - auc: 0.7264 - loss: 0.0444 - precision: 0.5230 - recall: 1.0000\n",
            "Epoch 20: val_auc did not improve from 0.86411\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.5371 - auc: 0.7095 - loss: 0.0446 - precision: 0.5193 - recall: 1.0000 - val_accuracy: 0.5450 - val_auc: 0.8627 - val_loss: 0.0442 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5334 - auc: 0.7639 - loss: 0.0445 - precision: 0.5162 - recall: 0.9965\n",
            "Epoch 21: val_auc did not improve from 0.86411\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.5357 - auc: 0.7425 - loss: 0.0444 - precision: 0.5186 - recall: 0.9971 - val_accuracy: 0.5450 - val_auc: 0.8586 - val_loss: 0.0439 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5477 - auc: 0.7334 - loss: 0.0438 - precision: 0.5232 - recall: 1.0000\n",
            "Epoch 22: val_auc did not improve from 0.86411\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.5414 - auc: 0.7449 - loss: 0.0436 - precision: 0.5216 - recall: 1.0000 - val_accuracy: 0.5450 - val_auc: 0.8578 - val_loss: 0.0436 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5525 - auc: 0.7327 - loss: 0.0434 - precision: 0.5329 - recall: 0.9969\n",
            "Epoch 23: val_auc did not improve from 0.86411\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.5386 - auc: 0.7286 - loss: 0.0435 - precision: 0.5202 - recall: 0.9914 - val_accuracy: 0.5450 - val_auc: 0.8641 - val_loss: 0.0434 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5734 - auc: 0.7308 - loss: 0.0435 - precision: 0.5595 - recall: 0.9988\n",
            "Epoch 24: val_auc did not improve from 0.86411\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.5386 - auc: 0.7360 - loss: 0.0433 - precision: 0.5201 - recall: 0.9971 - val_accuracy: 0.5450 - val_auc: 0.8631 - val_loss: 0.0432 - val_precision: 0.5222 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5145 - auc: 0.7602 - loss: 0.0422 - precision: 0.4919 - recall: 0.9959\n",
            "Epoch 25: val_auc improved from 0.86411 to 0.86534, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.5429 - auc: 0.7232 - loss: 0.0430 - precision: 0.5225 - recall: 0.9943 - val_accuracy: 0.5503 - val_auc: 0.8653 - val_loss: 0.0432 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5570 - auc: 0.7107 - loss: 0.0431 - precision: 0.5380 - recall: 0.9904\n",
            "Epoch 26: val_auc did not improve from 0.86534\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.5429 - auc: 0.7325 - loss: 0.0427 - precision: 0.5226 - recall: 0.9914 - val_accuracy: 0.5503 - val_auc: 0.8642 - val_loss: 0.0428 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5288 - auc: 0.7559 - loss: 0.0423 - precision: 0.5076 - recall: 0.9944\n",
            "Epoch 27: val_auc did not improve from 0.86534\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.5429 - auc: 0.7464 - loss: 0.0424 - precision: 0.5225 - recall: 0.9943 - val_accuracy: 0.5503 - val_auc: 0.8566 - val_loss: 0.0423 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5492 - auc: 0.7816 - loss: 0.0416 - precision: 0.5314 - recall: 0.9878\n",
            "Epoch 28: val_auc did not improve from 0.86534\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.5371 - auc: 0.7578 - loss: 0.0419 - precision: 0.5194 - recall: 0.9943 - val_accuracy: 0.5503 - val_auc: 0.8328 - val_loss: 0.0426 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5423 - auc: 0.7194 - loss: 0.0423 - precision: 0.5137 - recall: 0.9936\n",
            "Epoch 29: val_auc did not improve from 0.86534\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5414 - auc: 0.7256 - loss: 0.0421 - precision: 0.5217 - recall: 0.9943 - val_accuracy: 0.5503 - val_auc: 0.8477 - val_loss: 0.0421 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5162 - auc: 0.7421 - loss: 0.0423 - precision: 0.5012 - recall: 0.9934\n",
            "Epoch 30: val_auc did not improve from 0.86534\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.5300 - auc: 0.7260 - loss: 0.0422 - precision: 0.5156 - recall: 0.9943 - val_accuracy: 0.5503 - val_auc: 0.8587 - val_loss: 0.0415 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5186 - auc: 0.7491 - loss: 0.0416 - precision: 0.5003 - recall: 0.9917\n",
            "Epoch 31: val_auc did not improve from 0.86534\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5357 - auc: 0.7434 - loss: 0.0413 - precision: 0.5186 - recall: 0.9971 - val_accuracy: 0.5503 - val_auc: 0.8547 - val_loss: 0.0413 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5251 - auc: 0.7881 - loss: 0.0403 - precision: 0.5105 - recall: 0.9928\n",
            "Epoch 32: val_auc did not improve from 0.86534\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.5371 - auc: 0.7622 - loss: 0.0407 - precision: 0.5194 - recall: 0.9943 - val_accuracy: 0.5503 - val_auc: 0.8539 - val_loss: 0.0409 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5332 - auc: 0.7336 - loss: 0.0413 - precision: 0.5172 - recall: 0.9969\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 33: val_auc did not improve from 0.86534\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.5400 - auc: 0.7502 - loss: 0.0406 - precision: 0.5209 - recall: 0.9971 - val_accuracy: 0.5503 - val_auc: 0.8619 - val_loss: 0.0407 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5438 - auc: 0.7422 - loss: 0.0406 - precision: 0.5277 - recall: 0.9927\n",
            "Epoch 34: val_auc did not improve from 0.86534\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.5357 - auc: 0.7325 - loss: 0.0409 - precision: 0.5187 - recall: 0.9914 - val_accuracy: 0.5503 - val_auc: 0.8646 - val_loss: 0.0405 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 35/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.5406 - auc: 0.7462 - loss: 0.0404 - precision: 0.5245 - recall: 0.9915\n",
            "Epoch 35: val_auc did not improve from 0.86534\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5386 - auc: 0.7320 - loss: 0.0407 - precision: 0.5202 - recall: 0.9914 - val_accuracy: 0.5503 - val_auc: 0.8644 - val_loss: 0.0406 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 36/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5499 - auc: 0.7653 - loss: 0.0413 - precision: 0.5349 - recall: 0.9896\n",
            "Epoch 36: val_auc improved from 0.86534 to 0.86585, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5443 - auc: 0.7631 - loss: 0.0403 - precision: 0.5233 - recall: 0.9943 - val_accuracy: 0.5503 - val_auc: 0.8658 - val_loss: 0.0405 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 37/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5307 - auc: 0.7422 - loss: 0.0407 - precision: 0.5104 - recall: 0.9959\n",
            "Epoch 37: val_auc did not improve from 0.86585\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.5486 - auc: 0.7442 - loss: 0.0404 - precision: 0.5256 - recall: 0.9971 - val_accuracy: 0.5503 - val_auc: 0.8630 - val_loss: 0.0403 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 38/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5409 - auc: 0.7581 - loss: 0.0407 - precision: 0.5332 - recall: 0.9837\n",
            "Epoch 38: val_auc did not improve from 0.86585\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.5314 - auc: 0.7445 - loss: 0.0405 - precision: 0.5164 - recall: 0.9914 - val_accuracy: 0.5503 - val_auc: 0.8521 - val_loss: 0.0401 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 39/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5684 - auc: 0.7609 - loss: 0.0397 - precision: 0.5472 - recall: 0.9928\n",
            "Epoch 39: val_auc did not improve from 0.86585\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.5443 - auc: 0.7405 - loss: 0.0401 - precision: 0.5233 - recall: 0.9943 - val_accuracy: 0.5503 - val_auc: 0.8575 - val_loss: 0.0401 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 40/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5704 - auc: 0.7702 - loss: 0.0392 - precision: 0.5500 - recall: 0.9989\n",
            "Epoch 40: val_auc did not improve from 0.86585\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.5471 - auc: 0.7539 - loss: 0.0395 - precision: 0.5249 - recall: 0.9943 - val_accuracy: 0.5503 - val_auc: 0.8576 - val_loss: 0.0399 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 41/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5573 - auc: 0.7803 - loss: 0.0395 - precision: 0.5374 - recall: 0.9926\n",
            "Epoch 41: val_auc did not improve from 0.86585\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.5400 - auc: 0.7695 - loss: 0.0397 - precision: 0.5209 - recall: 0.9971 - val_accuracy: 0.5503 - val_auc: 0.8643 - val_loss: 0.0398 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 42/200\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5473 - auc: 0.7767 - loss: 0.0389 - precision: 0.5304 - recall: 1.0000\n",
            "Epoch 42: val_auc did not improve from 0.86585\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.5386 - auc: 0.7478 - loss: 0.0395 - precision: 0.5201 - recall: 1.0000 - val_accuracy: 0.5503 - val_auc: 0.8625 - val_loss: 0.0396 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 43/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5737 - auc: 0.7690 - loss: 0.0384 - precision: 0.5512 - recall: 0.9976\n",
            "Epoch 43: val_auc did not improve from 0.86585\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.5414 - auc: 0.7469 - loss: 0.0394 - precision: 0.5217 - recall: 0.9943 - val_accuracy: 0.5503 - val_auc: 0.8612 - val_loss: 0.0395 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 44/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5340 - auc: 0.7514 - loss: 0.0399 - precision: 0.5211 - recall: 0.9908\n",
            "Epoch 44: val_auc improved from 0.86585 to 0.86657, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.5414 - auc: 0.7652 - loss: 0.0392 - precision: 0.5217 - recall: 0.9943 - val_accuracy: 0.5503 - val_auc: 0.8666 - val_loss: 0.0394 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 45/200\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5409 - auc: 0.7376 - loss: 0.0397 - precision: 0.5222 - recall: 0.9888\n",
            "Epoch 45: val_auc improved from 0.86657 to 0.87088, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.5414 - auc: 0.7341 - loss: 0.0396 - precision: 0.5217 - recall: 0.9943 - val_accuracy: 0.5503 - val_auc: 0.8709 - val_loss: 0.0393 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 46/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5564 - auc: 0.7723 - loss: 0.0385 - precision: 0.5292 - recall: 0.9991\n",
            "Epoch 46: val_auc did not improve from 0.87088\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.5471 - auc: 0.7578 - loss: 0.0390 - precision: 0.5248 - recall: 0.9971 - val_accuracy: 0.5503 - val_auc: 0.8661 - val_loss: 0.0391 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 47/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5193 - auc: 0.7621 - loss: 0.0387 - precision: 0.4985 - recall: 0.9965\n",
            "Epoch 47: val_auc did not improve from 0.87088\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.5386 - auc: 0.7582 - loss: 0.0388 - precision: 0.5202 - recall: 0.9943 - val_accuracy: 0.5503 - val_auc: 0.8684 - val_loss: 0.0390 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 48/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5145 - auc: 0.7579 - loss: 0.0392 - precision: 0.4976 - recall: 0.9835\n",
            "Epoch 48: val_auc did not improve from 0.87088\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.5400 - auc: 0.7688 - loss: 0.0386 - precision: 0.5210 - recall: 0.9943 - val_accuracy: 0.5503 - val_auc: 0.8621 - val_loss: 0.0391 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 49/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5464 - auc: 0.7302 - loss: 0.0396 - precision: 0.5335 - recall: 0.9865\n",
            "Epoch 49: val_auc did not improve from 0.87088\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.5400 - auc: 0.7561 - loss: 0.0388 - precision: 0.5210 - recall: 0.9914 - val_accuracy: 0.5503 - val_auc: 0.8575 - val_loss: 0.0389 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 50/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.5183 - auc: 0.7651 - loss: 0.0386 - precision: 0.4958 - recall: 0.9984\n",
            "Epoch 50: val_auc did not improve from 0.87088\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5400 - auc: 0.7669 - loss: 0.0384 - precision: 0.5210 - recall: 0.9943 - val_accuracy: 0.5503 - val_auc: 0.8568 - val_loss: 0.0386 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 51/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5560 - auc: 0.7585 - loss: 0.0386 - precision: 0.5377 - recall: 0.9929\n",
            "Epoch 51: val_auc did not improve from 0.87088\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.5329 - auc: 0.7796 - loss: 0.0385 - precision: 0.5171 - recall: 0.9943 - val_accuracy: 0.5503 - val_auc: 0.8674 - val_loss: 0.0385 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 52/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5591 - auc: 0.7120 - loss: 0.0393 - precision: 0.5370 - recall: 0.9923\n",
            "Epoch 52: val_auc did not improve from 0.87088\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.5443 - auc: 0.7239 - loss: 0.0393 - precision: 0.5233 - recall: 0.9943 - val_accuracy: 0.5503 - val_auc: 0.8647 - val_loss: 0.0385 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 53/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.5522 - auc: 0.7883 - loss: 0.0374 - precision: 0.5302 - recall: 0.9973\n",
            "Epoch 53: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\n",
            "Epoch 53: val_auc did not improve from 0.87088\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.5471 - auc: 0.7928 - loss: 0.0373 - precision: 0.5249 - recall: 0.9943 - val_accuracy: 0.5503 - val_auc: 0.8627 - val_loss: 0.0383 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
            "Epoch 54/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5498 - auc: 0.7462 - loss: 0.0382 - precision: 0.5276 - recall: 0.9973\n",
            "Epoch 54: val_auc did not improve from 0.87088\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5400 - auc: 0.7436 - loss: 0.0384 - precision: 0.5210 - recall: 0.9943 - val_accuracy: 0.5503 - val_auc: 0.8668 - val_loss: 0.0382 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 55/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5734 - auc: 0.7617 - loss: 0.0375 - precision: 0.5510 - recall: 0.9964\n",
            "Epoch 55: val_auc did not improve from 0.87088\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.5429 - auc: 0.7557 - loss: 0.0379 - precision: 0.5225 - recall: 0.9943 - val_accuracy: 0.5503 - val_auc: 0.8651 - val_loss: 0.0383 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 56/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5388 - auc: 0.7583 - loss: 0.0386 - precision: 0.5125 - recall: 0.9962\n",
            "Epoch 56: val_auc did not improve from 0.87088\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.5414 - auc: 0.7643 - loss: 0.0382 - precision: 0.5217 - recall: 0.9943 - val_accuracy: 0.5503 - val_auc: 0.8680 - val_loss: 0.0382 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 57/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5478 - auc: 0.7708 - loss: 0.0383 - precision: 0.5318 - recall: 0.9824\n",
            "Epoch 57: val_auc improved from 0.87088 to 0.87156, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.5386 - auc: 0.7683 - loss: 0.0383 - precision: 0.5202 - recall: 0.9914 - val_accuracy: 0.5503 - val_auc: 0.8716 - val_loss: 0.0383 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 58/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5445 - auc: 0.7802 - loss: 0.0375 - precision: 0.5266 - recall: 0.9996\n",
            "Epoch 58: val_auc did not improve from 0.87156\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.5429 - auc: 0.7878 - loss: 0.0373 - precision: 0.5225 - recall: 0.9971 - val_accuracy: 0.5503 - val_auc: 0.8679 - val_loss: 0.0381 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 59/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5364 - auc: 0.7707 - loss: 0.0380 - precision: 0.5199 - recall: 0.9857\n",
            "Epoch 59: val_auc did not improve from 0.87156\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.5400 - auc: 0.7742 - loss: 0.0380 - precision: 0.5210 - recall: 0.9914 - val_accuracy: 0.5503 - val_auc: 0.8688 - val_loss: 0.0381 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 60/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5331 - auc: 0.7807 - loss: 0.0375 - precision: 0.5160 - recall: 1.0000\n",
            "Epoch 60: val_auc did not improve from 0.87156\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5471 - auc: 0.7576 - loss: 0.0377 - precision: 0.5247 - recall: 1.0000 - val_accuracy: 0.5503 - val_auc: 0.8630 - val_loss: 0.0382 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 61/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5681 - auc: 0.8125 - loss: 0.0363 - precision: 0.5498 - recall: 0.9969\n",
            "Epoch 61: val_auc improved from 0.87156 to 0.87279, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.5414 - auc: 0.7605 - loss: 0.0376 - precision: 0.5217 - recall: 0.9943 - val_accuracy: 0.5503 - val_auc: 0.8728 - val_loss: 0.0380 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 62/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5466 - auc: 0.7038 - loss: 0.0396 - precision: 0.5355 - recall: 0.9968\n",
            "Epoch 62: val_auc did not improve from 0.87279\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.5343 - auc: 0.7351 - loss: 0.0384 - precision: 0.5179 - recall: 0.9943 - val_accuracy: 0.5503 - val_auc: 0.8639 - val_loss: 0.0378 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 63/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5401 - auc: 0.7404 - loss: 0.0384 - precision: 0.5201 - recall: 0.9876\n",
            "Epoch 63: val_auc did not improve from 0.87279\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.5429 - auc: 0.7494 - loss: 0.0378 - precision: 0.5225 - recall: 0.9943 - val_accuracy: 0.5503 - val_auc: 0.8627 - val_loss: 0.0377 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 64/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.5410 - auc: 0.7581 - loss: 0.0379 - precision: 0.5228 - recall: 0.9917\n",
            "Epoch 64: val_auc did not improve from 0.87279\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5414 - auc: 0.7547 - loss: 0.0377 - precision: 0.5217 - recall: 0.9943 - val_accuracy: 0.5503 - val_auc: 0.8693 - val_loss: 0.0377 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 65/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5618 - auc: 0.7594 - loss: 0.0374 - precision: 0.5369 - recall: 0.9922\n",
            "Epoch 65: val_auc did not improve from 0.87279\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5471 - auc: 0.7609 - loss: 0.0374 - precision: 0.5250 - recall: 0.9914 - val_accuracy: 0.5503 - val_auc: 0.8613 - val_loss: 0.0377 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 66/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5574 - auc: 0.7890 - loss: 0.0372 - precision: 0.5387 - recall: 0.9937\n",
            "Epoch 66: val_auc did not improve from 0.87279\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.5400 - auc: 0.7587 - loss: 0.0378 - precision: 0.5210 - recall: 0.9943 - val_accuracy: 0.5503 - val_auc: 0.8657 - val_loss: 0.0376 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 67/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5395 - auc: 0.7777 - loss: 0.0371 - precision: 0.5184 - recall: 0.9943\n",
            "Epoch 67: val_auc did not improve from 0.87279\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.5414 - auc: 0.7676 - loss: 0.0374 - precision: 0.5217 - recall: 0.9943 - val_accuracy: 0.5503 - val_auc: 0.8638 - val_loss: 0.0376 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 68/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5522 - auc: 0.7721 - loss: 0.0370 - precision: 0.5344 - recall: 0.9899\n",
            "Epoch 68: val_auc did not improve from 0.87279\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.5443 - auc: 0.7519 - loss: 0.0377 - precision: 0.5234 - recall: 0.9914 - val_accuracy: 0.5503 - val_auc: 0.8597 - val_loss: 0.0376 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 69/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5557 - auc: 0.7667 - loss: 0.0372 - precision: 0.5406 - recall: 0.9890\n",
            "Epoch 69: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\n",
            "Epoch 69: val_auc did not improve from 0.87279\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.5486 - auc: 0.7697 - loss: 0.0369 - precision: 0.5257 - recall: 0.9943 - val_accuracy: 0.5503 - val_auc: 0.8634 - val_loss: 0.0374 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
            "Epoch 70/200\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5443 - auc: 0.7636 - loss: 0.0371 - precision: 0.5238 - recall: 0.9981\n",
            "Epoch 70: val_auc did not improve from 0.87279\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5500 - auc: 0.7618 - loss: 0.0371 - precision: 0.5264 - recall: 0.9971 - val_accuracy: 0.5503 - val_auc: 0.8675 - val_loss: 0.0374 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 71/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5334 - auc: 0.8010 - loss: 0.0363 - precision: 0.5120 - recall: 0.9971\n",
            "Epoch 71: val_auc did not improve from 0.87279\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.5486 - auc: 0.7758 - loss: 0.0367 - precision: 0.5257 - recall: 0.9943 - val_accuracy: 0.5503 - val_auc: 0.8634 - val_loss: 0.0373 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 72/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5179 - auc: 0.7407 - loss: 0.0377 - precision: 0.4944 - recall: 0.9993\n",
            "Epoch 72: val_auc did not improve from 0.87279\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.5500 - auc: 0.7617 - loss: 0.0369 - precision: 0.5264 - recall: 0.9971 - val_accuracy: 0.5503 - val_auc: 0.8671 - val_loss: 0.0373 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 73/200\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5848 - auc: 0.7884 - loss: 0.0362 - precision: 0.5658 - recall: 0.9957\n",
            "Epoch 73: val_auc did not improve from 0.87279\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.5414 - auc: 0.7619 - loss: 0.0372 - precision: 0.5218 - recall: 0.9914 - val_accuracy: 0.5503 - val_auc: 0.8620 - val_loss: 0.0373 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 74/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5373 - auc: 0.7755 - loss: 0.0370 - precision: 0.5169 - recall: 0.9919\n",
            "Epoch 74: val_auc did not improve from 0.87279\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.5400 - auc: 0.7690 - loss: 0.0372 - precision: 0.5210 - recall: 0.9914 - val_accuracy: 0.5503 - val_auc: 0.8651 - val_loss: 0.0373 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 75/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5387 - auc: 0.7993 - loss: 0.0365 - precision: 0.5105 - recall: 0.9978\n",
            "Epoch 75: val_auc did not improve from 0.87279\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5414 - auc: 0.7788 - loss: 0.0369 - precision: 0.5217 - recall: 0.9971 - val_accuracy: 0.5503 - val_auc: 0.8643 - val_loss: 0.0372 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 76/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5660 - auc: 0.7274 - loss: 0.0377 - precision: 0.5455 - recall: 0.9976\n",
            "Epoch 76: val_auc did not improve from 0.87279\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.5457 - auc: 0.7438 - loss: 0.0376 - precision: 0.5240 - recall: 0.9971 - val_accuracy: 0.5503 - val_auc: 0.8607 - val_loss: 0.0372 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 77/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5540 - auc: 0.7542 - loss: 0.0370 - precision: 0.5336 - recall: 0.9986\n",
            "Epoch 77: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "\n",
            "Epoch 77: val_auc did not improve from 0.87279\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.5457 - auc: 0.7522 - loss: 0.0370 - precision: 0.5240 - recall: 0.9971 - val_accuracy: 0.5503 - val_auc: 0.8661 - val_loss: 0.0372 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 1.5625e-05\n",
            "Epoch 78/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5231 - auc: 0.7602 - loss: 0.0372 - precision: 0.4975 - recall: 0.9980\n",
            "Epoch 78: val_auc did not improve from 0.87279\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.5429 - auc: 0.7784 - loss: 0.0365 - precision: 0.5225 - recall: 0.9943 - val_accuracy: 0.5503 - val_auc: 0.8597 - val_loss: 0.0372 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 7.8125e-06\n",
            "Epoch 79/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.5320 - auc: 0.7659 - loss: 0.0379 - precision: 0.5197 - recall: 0.9781\n",
            "Epoch 79: val_auc did not improve from 0.87279\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5400 - auc: 0.7577 - loss: 0.0375 - precision: 0.5211 - recall: 0.9886 - val_accuracy: 0.5503 - val_auc: 0.8655 - val_loss: 0.0372 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 7.8125e-06\n",
            "Epoch 80/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.5542 - auc: 0.7880 - loss: 0.0367 - precision: 0.5359 - recall: 0.9955\n",
            "Epoch 80: val_auc did not improve from 0.87279\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.5414 - auc: 0.7721 - loss: 0.0372 - precision: 0.5218 - recall: 0.9914 - val_accuracy: 0.5503 - val_auc: 0.8648 - val_loss: 0.0371 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 7.8125e-06\n",
            "Epoch 81/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5275 - auc: 0.7692 - loss: 0.0371 - precision: 0.5042 - recall: 0.9981\n",
            "Epoch 81: val_auc did not improve from 0.87279\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.5457 - auc: 0.7701 - loss: 0.0369 - precision: 0.5240 - recall: 0.9971 - val_accuracy: 0.5503 - val_auc: 0.8661 - val_loss: 0.0371 - val_precision: 0.5251 - val_recall: 1.0000 - learning_rate: 7.8125e-06\n",
            "Epoch 81: early stopping\n",
            "Restoring model weights from the end of the best epoch: 61.\n"
          ]
        }
      ],
      "source": [
        "# 3) Train\n",
        "history = train_model(model, X_train, y_train, X_test, y_test, epochs=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "b0baecc6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "THRESHOLD OPTIMIZATION & EVALUATION\n",
            "======================================================================\n",
            "\n",
            "Optimal threshold: 0.5661 (default=0.5)\n",
            "  At this threshold: TPR=0.8511, FPR=0.2316\n",
            "\n",
            "Results:\n",
            "  AUC-ROC: 0.8709\n",
            "  Accuracy (default threshold=0.5): 0.5503 (55.03%)\n",
            "  Accuracy (optimal threshold=0.5661): 0.8095 (80.95%)\n",
            "\n",
            "With optimal threshold:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Non-Planet     0.8391    0.7684    0.8022        95\n",
            "      Planet     0.7843    0.8511    0.8163        94\n",
            "\n",
            "    accuracy                         0.8095       189\n",
            "   macro avg     0.8117    0.8097    0.8093       189\n",
            "weighted avg     0.8118    0.8095    0.8092       189\n",
            "\n",
            "\n",
            "Prediction distribution (optimal threshold):\n",
            "  Predicted 0: 87\n",
            "  Predicted 1: 102\n",
            "True distribution:\n",
            "  True 0: 95\n",
            "  True 1: 94\n"
          ]
        }
      ],
      "source": [
        "# 4) Evaluate with optimal threshold\n",
        "y_pred, y_pred_proba, threshold = evaluate_with_optimal_threshold(model, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "a6e0f6da",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "VISUALIZATIONS\n",
            "======================================================================\n",
            "Saved: confusion_matrix_final.png\n",
            "Saved: training_history_final.png\n",
            "\n",
            "======================================================================\n",
            "PLOTTING LIGHTCURVES WITH PREDICTIONS (n=6)\n",
            "======================================================================\n",
            "Saved: sample_lightcurves_predictions.png\n",
            "\n",
            "======================================================================\n",
            "TRAINING COMPLETE!\n",
            "======================================================================\n",
            "\n",
            "Key improvements:\n",
            "  ✓ Perfectly balanced training data\n",
            "  ✓ Focal loss for hard examples\n",
            "  ✓ Optimal threshold selection\n",
            "  ✓ AUC-focused optimization\n",
            "\n",
            "Files:\n",
            "  - tess_model_final.keras\n",
            "  - best_model_final.keras\n",
            "  - optimal_threshold.npy\n",
            "  - confusion_matrix_final.png\n",
            "  - training_history_final.png\n",
            "  - sample_lightcurves_predictions.png\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# 5) Visualize & save artifacts\n",
        "plot_all(y_test, y_pred, y_pred_proba, history, metadata_test, X_test, threshold,\n",
        "         X_test_orig=X_test_orig, X_err_test=X_err_test, scaler=scaler)\n",
        "\n",
        "# Persist model and threshold\n",
        "model.save('tess_model_final.keras')\n",
        "np.save('optimal_threshold.npy', threshold)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nKey improvements:\")\n",
        "print(\"  ✓ Perfectly balanced training data\")\n",
        "print(\"  ✓ Focal loss for hard examples\")\n",
        "print(\"  ✓ Optimal threshold selection\")\n",
        "print(\"  ✓ AUC-focused optimization\")\n",
        "print(\"\\nFiles:\")\n",
        "print(\"  - tess_model_final.keras\")\n",
        "print(\"  - best_model_final.keras\")\n",
        "print(\"  - optimal_threshold.npy\")\n",
        "print(\"  - confusion_matrix_final.png\")\n",
        "print(\"  - training_history_final.png\")\n",
        "print(\"  - sample_lightcurves_predictions.png\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "797e9d45",
      "metadata": {},
      "source": [
        "## 11. (Optional) One-Click: Run Everything\n",
        "\n",
        "This cell wraps all steps into a single function for convenience.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "42f938a4",
      "metadata": {},
      "outputs": [],
      "source": [
        "def main():\n",
        "    X_train, X_test, y_train, y_test, metadata_test, X_test_orig, X_err_test, scaler = load_data(\n",
        "        csv_path=CSV_PATH, n_bins=N_BINS\n",
        "    )\n",
        "    model = build_simple_cnn(n_bins=N_BINS)\n",
        "    history = train_model(model, X_train, y_train, X_test, y_test, epochs=200)\n",
        "    y_pred, y_pred_proba, threshold = evaluate_with_optimal_threshold(model, X_test, y_test)\n",
        "    plot_all(y_test, y_pred, y_pred_proba, history, metadata_test, X_test, threshold,\n",
        "             X_test_orig=X_test_orig, X_err_test=X_err_test, scaler=scaler)\n",
        "    model.save('tess_model_final.keras')\n",
        "    np.save('optimal_threshold.npy', threshold)\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"TRAINING COMPLETE!\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nKey improvements:\")\n",
        "    print(\"  ✓ Perfectly balanced training data\")\n",
        "    print(\"  ✓ Focal loss for hard examples\")\n",
        "    print(\"  ✓ Optimal threshold selection\")\n",
        "    print(\"  ✓ AUC-focused optimization\")\n",
        "    print(\"\\nFiles:\")\n",
        "    print(\"  - tess_model_final.keras\")\n",
        "    print(\"  - best_model_final.keras\")\n",
        "    print(\"  - optimal_threshold.npy\")\n",
        "    print(\"  - confusion_matrix_final.png\")\n",
        "    print(\"  - training_history_final.png\")\n",
        "    print(\"  - sample_lightcurves_predictions.png\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "# Uncomment to run end-to-end:\n",
        "# main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "58d6d86f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Report written to report_cnn_assignment2_taskF.txt\n"
          ]
        }
      ],
      "source": [
        "#task F\n",
        "report_path = \"report_cnn_assignment2_taskF.txt\"\n",
        "\n",
        "with open(report_path, \"w\") as f:\n",
        "    f.write(\"Assignment 2 – Task F: CNN configurations on tess_data.csv\\n\")\n",
        "    f.write(\"----------------------------------------------------------\\n\\n\")\n",
        "    for name, thresh, cm, prec in all_results:\n",
        "        f.write(f\"Model: {name}\\n\")\n",
        "        f.write(f\"Optimal threshold: {thresh:.4f}\\n\")\n",
        "        f.write(\"Confusion matrix (rows: true [0,1], cols: predicted [0,1]):\\n\")\n",
        "        f.write(str(cm) + \"\\n\")\n",
        "        f.write(f\"Precision (optimal threshold): {prec:.4f}\\n\")\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "print(f\"Report written to {report_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Interpreting Results & Next Steps\n",
        "\n",
        "- **AUC-ROC** is the primary score during training. Inspect training curves to ensure you’re not overfitting.  \n",
        "- **Confusion matrix** with counts and percentages helps quantify trade-offs at the **optimal threshold**.  \n",
        "- **False positives** vs **false negatives**: use domain needs to decide how to tune `alpha`/`gamma` in focal loss or to move the threshold.\n",
        "\n",
        "**Ideas to try next**\n",
        "\n",
        "- Add **class-dependent augmentations** (e.g., transit-like dips for positives).  \n",
        "- Calibrate probabilities (e.g., **Platt scaling**, **isotonic regression**) for better decision thresholds.  \n",
        "- Incorporate additional channels (centroid motion, background, etc.) into a **multi-input** model.  \n",
        "- Use **cross-validation** on the training set to measure variability across folds.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### Appendix: Notes on Data Schema\n",
        "\n",
        "- Ensure your CSV contains **exactly** `n_bins` columns named `flux_0000 .. flux_{n_bins-1:04d}` and matching `flux_err_*` columns.\n",
        "- Metadata columns are optional for training but used for prettier plots.\n",
        "\n",
        "### Troubleshooting\n",
        "\n",
        "- `ValueError: columns not found`: your CSV headers don’t match the expected names. Check `n_bins` and column prefixes.  \n",
        "- `CUDA out of memory`: reduce `batch_size`, or limit GPU memory; try the provided GPU memory-growth snippet.  \n",
        "- `AUC not improving`: try a bigger `samples_per_class`, more dropout, or adjust `gamma`/`alpha`.\n",
        "\n",
        "---\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Final_TESS_Transit_Classification.ipynb"
    },
    "kernelspec": {
      "display_name": "comp_astro_25",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
